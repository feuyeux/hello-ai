<!-- markdownlint-disable MD033 MD036 -->

# LLM-Agent-UMF

基于LLM的代理统一建模框架，用于无缝集成多个主动/被动核心代理

<https://arxiv.org/html/2409.11393> 地中海理工学院，南地中海大学

- Amine B. Hassouna

- Hana Chaari
- Ines Belhaj

2024 年 9 月 17 日 

## 摘要

基于大型语言模型(LLM)的代理工具的集成，克服了独立LLM和传统代理有限能力的困难。然而，这些技术结合以及在一些最新技术中提出的增强功能遵循了非统一的软件架构，导致缺乏模块化。实际上，它们主要关注功能，忽略了代理中组件边界的定义。这在研究人员之间造成了术语和架构上的模糊不清，我们通过提出一个统一框架来解决这个问题，该框架为LLM基础代理的开发奠定了清晰的基础，从功能和软件架构的角度来看都是如此。我们的框架，LLM-Agent-UMF(LLM-based Agent Unified Modeling Framework, 基于LLM的代理统一建模框架)，明确区分了代理的不同组件，将LLM和工具与新引入的元素：核心代理分开，核心代理扮演代理的中央协调者的角色，包括五个模块：**规划(planning)**、**记忆(memory)**、**档案(profile)**、**行动(action)**和**安全(security)**——后者在以前的工作中经常被忽视。核心代理内部结构的差异使我们将它们分类为被动和主动类型。基于此，我们提出了不同的多核代理架构，结合了各种独立代理的独特特性。为了评估目的，我们将这个框架应用于一些最新的代理，从而展示了它与它们的功能的一致性，并澄清了被忽视的架构方面。此外，我们通过将独特的代理集成到混合主动/被动核心代理系统中，对我们提出的四种架构进行了彻底的评估。这项分析提供了对潜在改进的清晰洞察，并突出了特定代理组合所涉及的挑战。

**Keywords**

- LLM-based agents(基于大型语言模型的代理)
- software architecture(软件架构)
- modularity(模块化)
- security(安全)
- classification(分类)
- taxonomy(分类法)
- core-agent(核心代理)

## 1 介绍

大型语言模型(LLMs)在诸如语言建模、文本生成、问答、情感分析、自然语言理解和常识推理等任务中表现出色。然而，单独的LLMs缺乏其他技能，例如访问外部知识、信息检索、数学推理、代码评估等。这些功能上的不足可以通过AI代理利用外部工具和人类反馈来管理。自主代理是一个与环境互动、感知环境并在一段时间内根据特定议程对其采取行动的系统。代理有不同的类别，但本文将专注于基于LLM的代理，通过结合LLMs和自主代理的能力，可以实现广泛的任务。

事实上，基于LLM的代理由于几个原因已经成为AI代理领域的主导。首先是前面讨论的从LLMs继承的多功能集合。其次，LLMs被视为通向人工通用智能(AGI)的潜在垫脚石，为开发能够适应不同场景的通用AI代理提供了希望。最后，由LLMs驱动的更自然的对话界面的转变正在改变人类与代理的互动方式，实现了无缝和直观的互动。

理解这些代理的潜力并改进它们需要深入理解它们的结构。在基于LLM的代理中，除了处理推理的LLM外，还有其他组件负责执行任务、确保代理的安全和处理其记忆。但仅仅确定现有功能对开发人员和研究人员来说是不够的。为了全面概述这些代理，调查提出了一个全面的框架，包括四个主要模块，将在下一节中详细讨论。尽管它提供了对代理中每个模块功能的宝贵见解，但它忽略了从软件架构角度对它们的划分。这种视角对于开发人员建立共同的基础架构至关重要，对于研究人员改进也至关重要。我们对最新基于LLM的代理的分析揭示了常见的限制：实现的复杂性，导致结构不明确和模糊的软件架构；缺乏模块化和可组合性，使组件无法被其他基于代理的解决方案重用；以及维护困难和对现有代理引入改进的难度。这些问题源于缺乏一个清晰的框架，该框架强调代理的架构视角与其功能一样重要。

我们提出的基于LLM的代理统一建模框架(LLM-Agent-UMF)，强调在LLM基础代理中每个组件的明确划分，从架构和功能角度定义它们在指定边界内的交互。除了LLMs，我们还在代理中引入了一个新的单元：核心代理，我们将其分类为两种类型：主动和被动核心代理。这一提议增加了每个组件能力的清晰度，并描述了代理内部模块之间的动态交互。因此，我们减轻了架构的复杂性，提高了组件的可重用性，促进了从多代理系统向多核心代理的转变。

在评估部分，我们强调了我们的框架提供的优势，从解决术语模糊不清到引入增强模块，如安全模块。为了验证我们框架的可靠性，我们将其应用于现有解决方案，并确定了每个代理中的模块。这种方法使我们能够评估合并一个代理与另一个代理的可行性和要求，最终目标是创建一个能力完全增强的代理。

与以前的工作相比，本文的5个主要贡献可以总结如下：

1. 引入了一个新的术语—核心代理，作为基于LLM的代理中的结构子组件，以提高模块化并促进代理和LLM技术领域研究人员和贡献者之间更有效和精确的沟通。
2. 通过适配[4]中建议的框架来模拟核心代理的内部结构，该框架最初是为了从抽象的功能角度描述整个代理。
3. 通过在核心代理中增加安全模块并引入其他模块中的新方法来改进我们的建模框架。
4. 将核心代理分类为主动(active)核心代理和被动(passive)核心代理，解释它们的差异和相似之处，并突出它们的独特优势。
5. 最后，引入了各种多核心代理架构，强调混合一主动多被动核心代理架构是LLM基础代理的最佳设置。

本文的其余部分组织如下：

- 第2节：涵盖了基于LLM的代理的背景，并回顾了相关最新技术。
- 第3节：介绍了我们的基于LLM的代理统一建模框架和可能的架构。
- 第4节：评估了我们提出的代理设计的有效性，利用多个不同代理的能力。
- 第5节：总结了关键发现并讨论了未来的挑战。

## 2 相关工作

我们从基础概念开始。首先，工具增强型(Tool-augmented) LLM是自然语言处理(NLP)领域的重大进步，它结合了LLM的语言理解和生成能力以及与外部工具和API接口的能力。例如，[TALM](https://arxiv.org/pdf/2205.12255)引入了可以利用从信息检索到任务规划和执行的广泛功能的模型。

通过整合工具增强型LLMs，基于LLM的自主代理在NLP任务中表现出非凡的熟练度，包括推理、编程和文本生成，超过了其他类型的代理在这些领域的能力。此外，它们解决了单独LLMs的一些限制，如上下文长度限制和无法使用工具。这一发展在科学界标志着一个重大突破，解释了最近基于LLM的代理采用的激增。

不同学科的研究人员和实践者正在利用这些代理来解决复杂问题，并在游戏]和其他需要专业知识的专业领域推动创新。此外，将LLMs整合到科学研究中的趋势，即在化学领域，突显了它们的变革潜力，有望推动新的发现和应用。

在检查现有代理时，我们发现代理中缺少直接的安全措施或护栏，以确保敏感信息的保护和增强整体系统完整性。事实上，基于LLM的代理中的自主水平引发了关于道德使用、恶意数据、隐私和鲁棒性的显著关注。值得注意的是，一个关键风险涉及越狱，这可以通过实施更强大的监控和控制机制来减轻，在部署期间检测和响应越狱。此外，数据隐私在任何软件系统中都是一个持续的挑战，包括代理。为了解决这个问题，已经开发了各种方法来防范从提示中提取数据的尝试，例如利用隐私保护算法进行提示学习。这些发现促使我们强调这个经常被忽视的方面，并在我们的框架中包含安全措施。

除了安全保证外，AI系统的发展，特别是代理，必须遵守基本的软件开发原则，如模块化、可组合性和可维护性。这些原则增强了AI系统的灵活性、可扩展性和适应性，使它们能够有效地满足用户和业务不断变化的需求。

现有的代理不一定尊重这些原则，因为它们并不主要关注架构设计。这强调了架构框架作为基于LLM的代理蓝图的重要性，突出了它们在释放这些系统全部潜力中的关键作用。这些框架使得开发模块化、健壮、可扩展和互操作的设计成为可能。它们提供了必要的脚手架，以构建越来越有能力和可靠的代理，能够解决复杂的现实世界问题。

例如，论文探讨了基于LLM的智能代理，并指出了5个主要轴(axes)：**规划(Planning)**、**记忆(Memory)**、**反思(Rethinking)**、**环境(Environment)**和**行动(Action)**。尽管他们试图在LLMs、环境和工具之间划分界限，但他们没有定义代理的软件组件。同样，调查提出的框架确定了LLM驱动的自主代理的结构和应用，并突出了图1所示的四个关键模块：**档案模块(Profile module)**、**记忆模块(Memory module)**、**规划模块(Planning module)**和**行动模块(Action module)**。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9001.png" alt="基于LLM的代理框架" style="width:600px" align="left" />

图1 Framework proposed by survey [4] for LLM-based agents

**档案模块**用于划分LLM的不同角色。同时，**记忆模块**保留了内部日志，包括代理在其动态环境中过去的想法、行动和观察，包括与用户的互动。**规划模块**指导代理将总体任务分解为可管理的步骤或子任务，通过利用过去的行为在未来的计划中提高响应性。这些模块共同显著影响行动模块，该模块将代理的决策转化为具体的输出，利用外部工具扩展代理的能力。

虽然这个框架有效地解决了代理的功能，但它确实提出了一些改进的领域。首先，某些模块存在功能重叠，特别是规划和记忆模块之间反思活动的重叠。其次，记忆的定义含糊，将在第3.1节讨论，导致混淆，因为该术语用于表示没有明确区分的不同概念。最后，如图1所示，并没有明确说明LLM、工具、数据源和记忆是否是代理的一部分。这种对每个模块功能的模糊区分促进了软件开发人员之间的分裂，并导致不兼容和阻碍了可重用性。在下一节中，我们将介绍我们框架的主要组件，解释包含它们的理由，并强调它们如何解决其他工作中存在的问题。

## 3 基于LLM的Agent统一建模框架(LLM-Agent-UMF)

### 3.1 核心代理：LLM-based Agent的关键组件

许多工作旨在为构建基于LLM的代理建立一个明确定义的框架。例如，论文[15]提出了一个使用基于LLM的代理设计教育问题解决模拟的框架。作者强调，在设计过程中将AI代理与环境分开是很重要的。然而，该论文没有为代理的组件提供一个清晰的框架，这使得未来的工作难以识别具体的修改点或重用点。如果没有透明和详细的代理架构和组件交互的概述，就很难确定在哪里可以改变代理的行为，或者它的组件如何被重用和集成到其他系统中。

这个问题源于软件设计中缺乏模块化，可以通过坚持单一职责原则(SRP)来缓解。正如论文[16]所强调的，SRP在软件开发中至关重要，因为它在软件的不同级别上提供了粒度，无论是在代码还是功能方面。这种粒度有助于实现未来的改进，并增强可重用性的机会。此外，应用这一原则可以防止各种代码异味，确保代码的模块化，从而使从业者更容易管理和维护软件。

论文[17]试图在基于LLM的代理、它们使用的工具和它们周围的环境之间建立界限。虽然提出的基于LLM的代理系统提供了代理组件的抽象分离，但它并没有从软件工程的角度清楚地划分它们。理解统一代理中每个组件的理论贡献是有价值的；然而，从实际开发的角度来看，确定代理内部每个组件的位置、功能和角色是至关重要的。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9002.png" alt="核心代理作为基于LLM的代理的中心组件" style="width:600px" align="left" />

图2 The core-agent as the central component of LLM-based agents

通过对基于LLM的代理从软件角度进行深入分析，我们认识到基于LLM的代理是一个包括工具、LLMs和核心代理在内的各种组件的软件系统，这是我们新引入的术语。虽然核心代理不是一个新发明的组件，但它作为一个标签来表示以前在过去的框架或架构中隐含或未命名的现有功能元素。本质上，这个标签突出了它在这些系统中的关键作用。这个术语有助于通过识别基于LLM的代理的基本部分来澄清其结构。如图2所示，核心代理与环境互动，与语言模型合作做出决策，并通过可选地利用可用的工具将高层次目标转化为具体行动。

#### 1 核心代理(Core-Agent)

在这种架构中，核心代理作为关键的基石组件，充当自身与代理所有其他元素之间的关键接口。它促进这些不同部分之间的通信和协调，以确保整个系统的最佳功能。作为代理的执行者，核心代理将大型语言模型(LLM)制定的计划转化为可执行的步骤，可能利用工具，并与环境互动，为代理提供对外部世界的洞察。这些能力使核心代理能够作为控制器运行，确保精确和复杂的行动同步，从而实现无缝的互动和有效的信息共享。

核心代理的重要性由其与LLM的共生关系所强调，彼此增强对方的能力。LLM揭示了强大的**语言理解(language understanding)**、**认知(cognitive)**和**推理(reasoning)**能力，以及广泛的知识。然而，它缺乏**感知(perception)**和**行动(action)**组件，这些由核心代理提供，使代理能够直接与环境互动。这种合作扩大了代理可以解决的问题范围，有效地结合了LLM和核心代理的优势，以应对更广泛的挑战。

此外，核心代理作为控制器的存在减轻了代理的整体复杂性，特别是在多LLM设置中，它作为代理内的主要通信枢纽。因此，LLMs之间的信息流通过核心代理进行管理，简化了互动并确保了有效的协调。在通信方面，核心代理能够通过一个结构良好的管道与人类互动。然而，也存在核心代理可能不直接与人类沟通的情况。这种可变性取决于特定类型的核心代理，如第3.3节中详细说明的。

#### 2 LLM

LLM充当一个大脑实体，覆盖诸如自然语言理解和基于特定上下文的全面文本生成等认知任务。实际上，LLM可以与核心代理通信，而核心代理又可以与系统内的工具或数据源互动。考虑到代理可以表现为单模态或多模态，后者可以通过不同的任务特定的LLM来复制，如图2所示。这种区别促进了我们基于LLM的代理统一建模框架中的模块化，使它们开放于扩展和添加更多特定于领域的模型，而不必引入对整个系统架构的更改，更符合开放-封闭原则(OCP)。

#### 3 工具

在基于LLM的代理中，工具是重要的资产。它们可以采取各种形式，如辅助系统、软件应用程序甚至物理设备，以扩展和增强代理的能力。它们跨越了从基本API集成到为特定任务设计的复杂辅助系统的复杂性范围。在这种情况下，如果工具是独立系统并且能够实现一个完整的目标，则可以视为外部工具；如果它们与核心代理合作以实现代理目标范围内的任务，则可以视为内部工具。

总之，我们提出的基于LLM的代理的术语，包括核心代理作为其中央协调组件，旨在从软件角度增强描述这些系统的清晰度和一致性。核心代理的重要性强调了研究其内部结构的重要性。第3.2节重点介绍了核心代理内的不同模块以及它们如何协作，以利用可用的工具促进认知任务、决策制定和行动执行。

### 3.2 核心代理内部结构建模

人脑表现出显著的模块化，不同的区域和功能协调工作以促进认知过程、决策和行为。受这种有组织设计的启发，我们提出的框架旨在通过整合五个内部模块来模仿大脑的模块化结构：规划模块、记忆模块、档案模块、行动模块和安全模块。通过整合这些概念，核心代理作为中央协调器，控制不同组件之间的交互和信息流，如上一节所详述。

这种模块化框架有效地解决了可扩展性和可维护性的挑战。具体来说，它允许独立开发和集成新模块，而不会影响整个系统。事实上，这些模块可以单独替换或升级，便于添加新功能，并使框架更容易适应新的要求或技术。此外，模块化结构促进了代码的可重用性，因为各个模块可以在不同的代理或应用程序中共享，从而减少重复并增强一致性。

为了提供有力的比较并强调我们框架的新颖性，将其与现有方法一起检查是有益的。最近的一项调查引入了一个基于LLM的代理框架，包括四个关键模块：档案、记忆、规划和行动模块。有关此框架的全面概述，我们引导读者参阅“相关工作”部分。虽然这项调查提出的框架将基于LLM的代理视为一个整体系统，没有区分核心组件与其他实体，但我们针对核心代理的调整需要修改某些定义和模块结构，以适应LLM和核心代理之间的分离。值得注意的是，我们不得不重新定位这四个关键模块，使其在框架内的核心代理下运行，同时引入了我们新引入的面向安全模块。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9003.png" alt="核心代理的内部结构" style="width:800px" align="left" />

图3 The internal structure of a core-agent

#### 3.2.1 规划模块

在我们提出的框架中，规划模块是一个关键元素，它使代理能够将复杂问题分解以制定有效的计划，与原始框架相同。然而，在我们的解决方案中，规划模块成为核心代理的一部分，并与其他兄弟模块合作，使代理能够实现特定目标。

规划模块需要复杂的理解和推理，这可以利用LLM的能力。实际上，LLM理解细微指令、解释隐含信息以及适应各种问题领域，使其成为规划过程中的宝贵资产。因此，规划模块可以制定更全面、有上下文意识和适应性强的计划，显著增强核心代理的决策过程。此外，规划模块与核心代理内的所有其他模块紧密合作，包括用于增强记忆规划的记忆模块。这种合作通过利用存储的信息(如常识知识、过去的经历和特定领域知识)来增强规划能力。

本节将从四个关键方面详细说明这个模块的功能和特点：**过程(process)** 、**策略(strategies)**、**技术(techniques)**和**反馈源(feedback sources)**。这些方面源于我们在核心代理与LLM之间以及我们的系统与外部系统之间的明确分离，如图2所示。

##### 1 规划过程

在生成要采取的程序时，规划模块遵循增量方法。在这里，步骤规定了如何分解任务、规划程序如何展开以及如何生成和评估替代解决方案。受到人类将复杂任务分解为更简单任务以实现总体目标的能力的启发，这个过程包括两个主要步骤。

**任务分解**

这个初始阶段涉及将复杂任务分解为更简单的子任务，从而建立中间目标的结构化层次。复杂任务的分解可以采用两种主要方法：

- 在非迭代分解方法中，复杂任务一次性分解为简单子任务。规划模块定义所有子任务，在单步中创建完整的任务层次结构。这种方法提前提供了整个任务结构的全面概述。
- 迭代分解方法涉及任务的逐步分解。规划模块首先定义初始子任务和要达到的目标，制定适当的计划并生成要采取的程序。在执行程序并完成计划后，考虑输出，并定义下一个子任务。这个过程重复进行，每个新的子任务被计划和执行，有助于定义下一个要实现的子任务。这种方法的关键优势是其灵活性和根据每个子任务的结果调整计划的能力。迭代方法的典型应用是分解-对齐-推理代理(DARA)框架。[DARA](https://aclanthology.org/2024.findings-acl.203.pdf)展示了迭代分解如何导致更精确和有上下文意识的规划，特别是对于具有多个相互依赖子任务的复杂任务。

**计划生成**

对于分解步骤中派生出的每个子任务，制定特定计划，概述实现任务目标的程序，同时定义涉及的不同工具和参与者。根据选择的规划策略，该模块可以为每个子任务生成单一计划或多个候选计划，将在下一节中进一步详细说明。

##### 2 规划策略

为了指导复杂任务的规划、组织和执行，规划模块在计划生成步骤中制定程序时必须遵循特定策略。选择规划策略可以显著影响结果计划的有效性、效率和鲁棒性。在LLM-Agent-UMF中，我们定义了两种主要策略：

**单路径策略**

这种方法涉及生成单一路径或程序序列以实现目标，遵循计划的每一步而不探索替代方案，从而为规划提供直接、确定性的方法。[思维链(CoT)](https://aclanthology.org/2024.acl-long.65.pdf)就是这样一个策略的例子。实际上，它使用顺序推理，因为它涉及将复杂问题分解为多个程序，每个程序都建立在前一个程序之上。

**多路径策略**

因此，在单路径策略中，一个程序中的任何错误都可能导致后续程序或整个计划变得次优或不可行，对整个策略产生负面影响。缓解这种失败的直接方法是多路径策略，它涉及两个主要步骤：第一阶段涉及利用LLM为复杂任务生成多个计划。实际上，每个中间步骤都有多个后续路径。至于第二阶段，它涉及评估和选择最合适的路径。

事实上，[思维树(ToT)和思维图(GoT)](https://arxiv.org/pdf/2401.14295)是两个使用这种多路径方法的框架。它们都通过利用LLM作为思维生成器来产生中间程序，这些程序要么以ToT的层次结构树的形式结构化，要么以GoT的更复杂图形的形式结构化。然而，管理这些结构的复杂性不能单独由LLM处理。它需要集成一个专门的软件组件，负责协调过程，与LLM交互，并将思维组织成所需的结构，无论是树还是图。这个重要的软件组件被识别为核心代理中的规划模块。规划模块进一步评估生成结构中的不同路径，并根据其评估选择最佳计划。

##### 3 规划技术

规划模块遵循[规划技术](https://arxiv.org/pdf/2402.02716)作为形成可执行计划的方法论方法。这些技术根据任务的复杂性和对上下文理解的需求等标准选择。我们的框架提出了两种主要技术：

**基于规则的技术**

在我们的架构框架中，基于规则的方法包括文献中通常提到的**符号规划器(symbolic planners)**。这些技术在具有复杂约束的上下文中特别有价值，如数学问题解决或在高度问题情况下生成计划。

符号规划器，利用像[PDDL](https://www.cs.cmu.edu/~mmv/planning/readings/98aips-PDDL.pdf)(Planning Domain Definition Language, 规划领域定义语言)这样的框架，利用形式推理来确定从初始状态到目标目标状态的最佳轨迹。这些方法涉及将问题场景形式化为结构化格式，然后将它们提交给专门的规划算法。

**语言模型驱动的技术**

语言模型驱动(LM驱动)的方法利用LM固有的广泛知识和推理能力来协调规划策略。在我们的框架中，这一类还包括**神经规划器(neural planners)**，它们擅长处理需要细微理解和适应性问题解决能力的复杂和模糊任务。

在我们的框架中，这种分类清楚地区分了主要由LM驱动的方法和依赖基于规则的方法。它允许在核心代理架构的背景下更流畅地理解规划技术，同时仍然承认[4]和[21]中各种规划方法的宝贵贡献。

##### 4 反馈源

没有反馈的规划可能会带来几个挑战，因为反馈在优化核心代理内规划模块的性能中起着至关重要的作用。例如，在迭代任务分解中，反馈对下一个生成的步骤有影响，并增强了代理与用户期望的一致性。

为了有效解决这些挑战，规划模块依赖于多种反馈源。如图3所示，核心代理与其系统边界内的工具以及外部实体(如外部系统和人类)进行互动。因此，与这些组件的互动可以提供有价值的反馈：

**人类反馈**

人类反馈可能是将规划模块与人类价值观和偏好对齐的重要信息来源。这种反馈来自于核心代理与人类之间的直接互动。例如，当核心代理提出一个计划时，人类可能会对其适当性、有效性或伦理影响提供反馈。这种反馈可以采取多种形式，如评级或评论。

**工具反馈**

核心代理经常使用各种工具，这些工具可以是系统的内部组件或外部应用程序。例如，内部计算器工具在接收到非法操作(如零除)时可能会引发异常。同样，外部工具以错误消息或性能指标的形式提供反馈。实际上，如果核心代理使用天气预测远程API，预测的准确性就作为反馈。这种工具提供的反馈有助于核心代理完善其工具选择和使用策略。

**兄弟核心代理反馈**

在多核心代理系统中，如将在第3.4节中讨论的，兄弟核心代理的反馈成为宝贵的信息来源。这种类型的反馈来自于同一系统内不同核心代理之间的互动和信息交换。这种代理内反馈可以包括共享观察、对问题的替代观点或对提议计划的评估。这种反馈促进了协作问题解决，并允许计划的交叉验证。它通过促进集体智能，增强了多核心代理系统的总体鲁棒性。

总之，规划模块是我们框架的关键组成部分，采用结构化的规划过程，包括任务分解和计划生成步骤。这个过程与规划策略——单路径和多路径——不同，但与之紧密相连，指导计划的制定。这些策略至关重要，因为它们塑造了核心代理解决问题的方法，影响解决方案的质量和效率。通过分解任务和生成多个计划，核心代理可以更快、更有效地识别最佳解决方案。

规划模块的有效性通过整合来自各种来源的反馈(包括人类、工具和兄弟核心代理)进一步提高。这种反馈循环允许计划的持续改进和适应，确保代理保持响应性和效率。此外，整合规划策略和反馈机制增强了适应性，使核心代理能够解决从简单任务到复杂挑战的广泛场景。这种战略多样性为系统提供了更大的智能和多功能性。

值得注意的是，规划模块并不孤立运作。它与其它模块紧密合作，特别是记忆模块，将在下一节讨论。这种合作，特别是在增强记忆规划的背景下，通过利用存储的信息和过去的经历，进一步增强了核心代理的能力。

#### 3.2.2 记忆模块

记忆模块负责存储和检索与核心代理活动相关的信息，从而提高核心代理的决策效率和任务执行能力。在[26]和[4]中，基于LLM的代理中的记忆模块是从抽象功能的角度来处理的，忽略了从软件架构角度的分析。这导致记忆模块与[4]提出的框架中定义的其他模块之间存在一些重叠。因此，我们提出了一个更全面且定义更明确的记忆模块，基于三个视角：记忆结构、记忆位置和记忆格式。

调查[4]中提出的框架将**记忆结构**分类为统一记忆，旨在通过上下文学习模拟人类短期记忆，以及混合记忆，代表短期和长期记忆功能。虽然这些名称旨在区分不同类型的代理系统，但它们不必要地偏离了该领域已建立的术语。通过第一个视角，记忆结构，我们引入了更传统且广泛认可的分类，包括短期和长期记忆，与[27]建立的人类记忆结构更加一致。

与框架[4]中的定义不同，我们的短期记忆定义更侧重于核心代理的影响，而不是LLM。从内容角度来看，各种信息来源有助于短期记忆。正如论文[26]所指出的，数据可以来源于给定任务的一次尝试，或同一任务的先前尝试，这被称为**短期记忆**。这些数据的范围较窄，专注于特定任务，主要传达给LLM，用于上下文学习和通过与任务相关的更多信息增强LLM能力。相反，**长期记忆**指的是在长时间记忆存储和回忆信息的能力，超出了特定任务的范围。这种类型的记忆使核心代理能够在长时间互动中保持连贯性和上下文，从过去的经历中学习和适应。也就是说，[MemoryBank](https://ojs.aaai.org/index.php/AAAI/article/view/29946)将所有与用户的互动存储在一个大的符号记忆中，并将经历处理成高级摘要，以反映未来类似的任务。

然而，核心代理可以保留的记忆量总是有限制的。因此，必须实施诸如**遗忘机制**等技术，以决定哪些记忆要丢弃，哪些要保留([A Survey on the Memory Mechanism of Large Language Model based Agents](https://arxiv.org/pdf/2404.13501))。正如前面提到的，调查[4]从抽象功能的角度处理记忆，这与我们强调明确划分不同模块的框架不一致。我们的方法旨在从软件角度提供对核心代理组件更精确和结构化的理解。例如，根据调查[4]，记忆模块包括一个具有认知方面的“反思”操作，我们认为这属于规划模块。规划模块专注于实现代理的目标，负责决策和协调所有其他模块。因此，它更适合处理反思和通过与记忆模块协作访问存储的数据来优化记忆。同样，从记忆中提取有用信息并反思它以产生可靠的计划属于规划模块的责任。例如，[Voyager](https://openreview.net/forum?id=ehfRiF0R3a)将环境反馈视为短期信息，并利用LLM的能力调整其计划，在规划模块的范围内做出更有效和合理的决策。

此外，写操作是记忆的一个重要方面，它将其与数据存储库区分开来。因此，我们从记忆类别中排除了知识库。事实上，以只读方式从数据库中检索知识属于行动模块的责任，将在第3.2.4节中讨论。由于我们将写入和读取作为记忆模块的基本操作，并从可能的操作集中排除了反思，我们决定从我们的框架中省略调查[4]中讨论的记忆操作视角。

除了关注数据的范围，如[26]所述，在试验内和跨试验，我们强调记忆的位置，因为它从软件架构的角度来看更相关。因此，我们引入了第三个视角，**记忆位置**，包括两个类别：嵌入式记忆，内部到核心代理边界，和记忆扩展，外部到核心代理边界，但仍在代理系统边界内，如图3所示。

最后，最后一个视角，**记忆格式**，在[4]和[26]的两项工作中已经存在，侧重于记忆的形状和表示，可能有不同的表现形式：自然语言、嵌入、SQL数据库或结构化列表。实际上，诸如代理行为和观察这样的记忆信息可以直接用原始自然语言描述，提供灵活性并保留丰富的语义信息。另一种解决方案是将记忆信息编码到嵌入向量中，以提高检索和阅读效率。此外，如[ChatDB](https://arxiv.org/pdf/2306.03901)所示，数据库可以用作记忆持有者，以结构化表示存储记忆信息，允许代理使用SQL查询高效全面地操作记忆。最后，如[GITM](https://arxiv.org/pdf/2305.17144)中使用的，结构化列表让核心代理以结构化的方式保存子目标的顺序行动，并将记忆信息组织成层次列表，以简洁地传达语义信息。

作为一个观察，最常见的格式是文本，然而[4]指出这些格式并不互斥，因此一个核心代理可以处理多种格式，如GITM的键值列表结构，结合了嵌入向量和原始自然语言，以利用每种方法的各自好处。

#### 3.2.3 档案模块

与论文[4]中提出的方法类似，我们的框架定义了档案模块的功能，即为LLM建立角色，并采用了更多样化的方法。这个模板明确区分了核心代理和LLM的角色。实际上，档案模块有助于根据规划模块采用的特定用例和策略，动态适应各种档案。

档案模块具有四种定义档案的方法：手工上下文学习方法(Handcrafted In-Context Learning Method)、LLM生成方法(LLM-generation method)、数据集对齐方法(Dataset Alignment Method)和新引入的微调即插即用模块方法(Fine-tuned Pluggable Modules method)。

**手工上下文学习法**

先前在调查[4]中称为手工方法，涉及委托核心代理通过使用预配置提示的上下文学习技术来设置LLM的档案。这种方法允许对LLM的个性和行为进行细粒度控制。虽然这是一种简单的方法来实现，但它需要使用适合上下文学习的LLM，通常具有笨重的规模。

**LLM生成方法**

便于使用LLM为代理自动创建档案。这种方法首先指定档案的特征，包括年龄、性别和兴趣等详细信息。可选地，可以选择几个种子代理档案作为少数示例，如论文[4]中概述的。一旦建立了这些种子档案，LLM就被用来通过参考初始种子示例生成额外的档案。例如，RecAgent[32]建议设计适当的提示，鼓励GPT模型通过参考与各种样本相对应的属性表来生成全面的档案描述，并生成额外的档案。LLM生成方法虽然提供了显著的节省时间的优势，但受限于对LLM的依赖。这种依赖可能导致生成的代理档案中存在潜在的偏见[33]或不准确性。

**数据集对齐方法**

从现实世界的数据集[4]中衍生档案，这些数据集包括关于真实个人的数据。这种方法首先将这些数据集中的信息组织成描述LLM角色特征的自然语言提示。然后使用这些结构化数据创建档案。在[34]进行的研究中，研究人员使用GPT-3以及来自ANES的真实世界人口统计数据，根据居住州等特征分配角色。随后，他们评估了GPT-3是否能够可靠地模仿真实人类行为。数据集对齐方法确保LLM档案准确反映现实世界的特征和行为，使其有意义且现实。然而，这种方法的有效性在很大程度上依赖于底层现实世界数据集的准确性和代表性。

**微调即插即用模块方法**

这是一种开创性的解决方案，利用多种最新技术设置LLM的档案，旨在提供LLM档案的高效定制和适应。这种方法通过注入一个微调的即插即用模块来定义LLM档案，该模块被训练用来影响语言模型的行为。实际上，该模块是一组额外的可调参数，必须先前使用参数高效微调(PEFT)技术进行训练，如顺序适配器(AdapterS)、提示调整或LoRA[35]。

这个过程确保了精确有效的定制，以实现所需的档案，消除了上下文学习的必要，传统上下文学习涉及在每个查询中注入大量的提示信息。省略这一步，所需的上下文大小显著减少，因为适配器直接将期望的行为和档案编码到模型参数中。上下文大小和记忆占用的减少使LLM能够更高效地运行，在推理过程中使用更少的记忆，而不会降低性能。

#### 3.2.4 行动模块

与[4]中描述的方法类似，我们在LLM-Agent-UMF中定义了该模块的功能。该模块作为汇聚点，所有其他模块的贡献及其潜在输入都以结果的形式可视化。它将代理的决策转化为可执行的行动，从四个角度来构想：行动目标(Action Goal)、行动产生( Action Production)、行动空间(Action Space)和行动影响(Action Impact)。

**行动目标**

代表了核心代理通过执行基于各种目标的行动意图实现的目标，例如任务完成、通信或环境探索。行动模块保持这个行动目标，并指导核心代理相应地选择适当的行动。

**行动产生**

侧重于行动是如何产生的以及背后的催化剂。实际上，核心代理可以通过三种主要方法产生行动：通过记忆回忆的行动(Action via Memory Recollection)、通过计划遵循的行动(Action via Plan Following)和通过API调用请求的行动(Action via API Call Request)，这是我们框架中新引入的。

通过记忆回忆的行动，核心代理通过根据当前任务从其记忆中提取相关信息来产生行动。例如，在GITM中，如果代理需要实现子目标，它会检查其记忆以寻找类似的过去经历，并利用这些经历中的成功行动来处理当前任务。

同样，通过计划遵循的方法，核心代理可以通过坚持预先生成的计划来执行行动。在GITM和DEPS(描述、解释、计划和选择)中，代理将任务分解为子任务和子程序，依次行动以实现每个程序并完成整个任务。如果计划失败，两个代理都具有重新规划的能力，因此行动模块执行新计划。这两种方法，通过记忆回忆的行动和通过计划遵循的行动，与[4]中描述的框架一致。

通过探索其他最新技术如TALM和[ToolFormer](https://proceedings.neurips.cc/paper_files/paper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf)，它们展示了LLM通过整合外部工具来提高不同任务性能的能力，我们引入了一种名为通过API调用请求的行动的新方法。这种新方法使核心代理能够响应由LLM发起的API调用请求来执行行动，促进了外部资源的顺利整合和有效利用。

**行动空间**

定义了核心代理可以执行的可能行动集，与原始框架[4]保持一致。这些行动可以利用内部知识，其中核心代理作用于内部信息，和/或在需要全面专家知识时利用工具。这些工具可以包括API，如HuggingGPT，它通过HuggingFace API利用AI模型来完成复杂的用户任务。或者，核心代理不仅可以依赖其记忆，还可以通过与数据库和知识库等其他只读数据源通信来扩展其操作范围和知识。这里值得注意的是，数据存储库可以采用记忆模块中讨论的相同格式(第3.2.2节)。例如，LLamaIndex在索引阶段将数据存储为向量嵌入，以利用语义搜索，其中嵌入之间的相似性用于按其与查询的相关性对文档进行排名。相反，ReAct使用文本数据存储库，如维基百科，以减少思维链推理中的错误传播。

**行动影响**

指的是行动产生的后果。可以引用许多影响，例如通过移动到不同位置、收集资源或建造建筑物来改变环境。行动还可以通过更新其记忆或获取新知识来改变核心代理的内部状态，这可能会影响规划模块。此外，影响可以触发新的行动，在任务完成期间创建一系列行动。

#### 3.2.5 安全模块

随着大型语言模型(LLMs)的不断进步和广泛应用，解决与其使用相关的潜在风险和意外后果变得至关重要。这些担忧主要集中在未经授权和不道德的使用、数据偏见和隐私方面。这导致了最近在LLMs领域引入了防护措施，作为算法来识别和防止LLMs的滥用。为了增强我们的框架，我们提出了第五个模块：安全模块。该模块旨在提供更有能力和负责任的核心代理。其作用是特别在生产环境中监控行动模块，以确保LLMs的安全和负责任的使用。

安全模块在**CIA**(Confidentiality, Integrity, Availability 机密性、完整性、可用性)**三元组**的参数内运行[42]，这是一个至关重要的模型，涵盖了安全领域的三个关键原则。**机密性**围绕保护敏感信息免遭未经授权的访问或披露。在基于LLMs的代理中，这一原则对于保护用户数据和确保不泄露敏感信息至关重要。**完整性**涉及在整个生命周期中维护数据的准确性、一致性和可信度。对于代理而言，这一原则包括维护模型输出的可靠性，并防止对系统或其数据进行未经授权的修改。最后，**可用性**专注于确保信息和资源在授权用户需要时随时可用。在LLM应用的背景下，这包括维护系统的正常运行时间，并为用户提供安全的回答。通过遵循这些原则，安全模块旨在为代理的操作建立一个健全和可信的环境，有效地解决与其部署和使用相关的重大关切。

在进行深入研究安全模块时，我们的方法将涉及探索多个方面：识别和保护核心代理建模框架内的关键资产和数据，实施策略和机制来保护这些资产免受潜在威胁，确保核心代理能够有效地应对和减轻任何安全事件，并在遵守相关数据保护法规的同时维护用户数据的隐私。

##### 安全措施

无论部署的防护措施类型如何，安全模块都包括三个基本轴：提示保护、响应保护和数据隐私保护。

**提示保护**

提示保护需要采用措施来检测和减轻通过提示注入攻击对大型语言模型的未经授权访问[43]。增强基于LLMs的代理的安全性的技术可以直接集成到LLM本身中，**对抗性训练(AT)**就是一个突出的例子[44]。AT通过使用包含对抗性示例的增强训练数据对LLM进行微调，从而增强了LLM的防御机制，提高了模型防范恶意提示的能力，提高了其鲁棒性。然而，AT面临着显著的限制，例如在有效地选择对抗性示例和模型暴露于对抗性扰动(如HOUYI[45]，一种黑盒提示注入攻击)方面的挑战。此外，这种基于训练的安全技术可能会影响LLM的生成性能，这需要额外的评估步骤。

其他技术通过将安全措施与LLM分离，并将其委托给我们确定的具有安全模块的核心代理的不同实体来解决这些限制，如图3所示。这种分离对于提高保护至关重要，并使得在LLM输入上实施更先进的安全协议成为可能，这些协议可以独立于LLM的训练过程进行发展。这种方法的一个例子是Nvidia NeMo[46]，它作为用户和LLM之间的中间层，采用先进技术，如向量数据库和与存储的规范形式进行比较，以过滤和处理用户输入，然后才到达模型，从而在不直接修改底层LLM的情况下提供强大的提示保护。

这些方法对于解决可扩展性挑战、实现主动防御和促进LLM安全中的持续学习至关重要，确保保护机制能够适应新威胁并维护LLM交互的完整性。

**响应保护**

最近的调查[47]表明，尽管实施了提示保护技术，但大型语言模型(LLMs)对先进攻击(称为越狱)的整体抵抗力可能不会有显著提高。这些越狱旨在通过操纵其响应来利用语言模型中的偏见或漏洞。著名的例子包括白盒攻击AutoDAN-Zhu[48]，它生成隐蔽的提示以避免触发模型的保护机制。此外，黑盒攻击利用手工制作的提示来欺骗LLM[47]。这些越狱技术的效力在[12]中得到了进一步的说明，研究人员通过将可能有害的查询“如何热车”构建为假设场景，成功地对ChatGPT 3.5进行了越狱攻击。这些越狱方法的存在突显了对LLM输出进行持续和严格监控以检测和减轻潜在违规行为的迫切必要性。

事实上，保护代理输出涉及确保由LLM生成的文本的安全性和完整性。这包括检测和删除有害内容，同时保持连贯性和相关性。这种技术的两个著名例子是Guardrails AI[47](https://arxiv.org/pdf/2406.02622)和LLMSafeGuard[49](https://arxiv.org/pdf/2404.19048)，在第4节中进一步讨论。

**数据隐私保护**

最后，保护数据隐私至关重要，特别是处理敏感或个人信息时。确保LLMs受到保护，防止敏感数据泄露[47]至关重要。现有研究主要侧重于通过传统技术(如差分隐私[50]和水印[51])保护训练数据。事实上，调整后的差分隐私模型会向数据添加噪声，使得难以识别单个数据点。类似地，水印技术将可识别的标记嵌入到LLM输出中，允许追踪数据来源并防止未经授权的使用。

然而，根据我们提出的框架，主要目标从仅仅保护训练数据的隐私转移到确保LLM不会向外部工具泄露敏感信息。这种方法旨在在与其他系统交互时维护数据的隐私和安全。事实上，如前所述，核心代理可以利用外部工具、API和知识库来增强LLM的能力。作为整个代理系统的一部分，内部工具是隐私圈的一部分，因此，无需在通信程序上应用安全措施。然而，使用外部资源引入了潜在风险，需要特别关注。这些风险包括缺乏健全的数据隐私措施，可能导致数据泄露或未经授权的访问。例如，当核心代理利用第三方服务获取额外信息或执行特定任务时，传输的数据可能包含特定系统未授权访问的敏感细节。此外，如果不利用适当的安全渠道，这些敏感信息可能会被拦截或处理不当。

为了减轻这些风险，核心代理内的安全模块必须实施一系列强大的技术，如访问控制机制和数据加密。因此，框架确保与外部资源的互动保持最高标准的安全性和数据隐私。

因此，安全模块沿着三个基本轴运行：提示保护、响应保护和数据隐私保护。它们的整合形成了一个强大的防御机制，能够减轻从提示注入攻击到潜在数据泄露的各种威胁。通过这种方法，安全模块塑造了核心代理的行为，优先考虑每个方面的安全性，从数据检索到外部通信。

##### 防护措施类型

为了有效实施这些安全轴，已经开发了各种防护措施方法。这些防护措施作为安全模块的操作层，将高级安全目标转化为可操作的保护措施。论文[47]深入探讨了LLM服务提供商和开源社区提供的多种防护措施方法和解决方案。通过对这些方法的细致分析，出现了两种主要类型，基于规则的防护措施和基于LLM的防护措施。

**基于规则的防护措施**

这些防护措施基于一组预定的规则和法规运行，旨在筛选和防止LLMs可能有害或不期望的输入/输出。为了阐明过程，用户定义需要保护的内容。随后，防护措施根据这些预定义的法规和自定义规则[47]评估输入/输出，以确定合规性。如果内容被认为不安全，它可能会被阻止，或者可能会发出警告。例如，对抗性鲁棒性工具箱(ART)[52]专门设计用于加强模型对对抗性攻击的安全性和鲁棒性。它提供了防御和适应恶意输入的工具和方法，从而保护AI应用免受潜在漏洞的侵害。

**基于LLM的防护措施**

虽然基于规则的防护措施为保护LLM操作提供了坚实的基础，但它们在适应性和维护方面面临限制。手动、持续改进和干预以升级规则可能是耗时的，并且可能难以跟上快速发展的威胁和多样化的用例。基于LLM的防护措施为这些挑战提供了一个引人注目的解决方案。构建这些防护措施的普遍设计方法涉及使用神经符号代理[47]。这些代理在安全方面类似于核心代理，承担分析输入和输出、确保它们遵守预定义要求的关键任务。通过利用语言模型固有的学习和适应能力，这些防护措施可以更快、更自动化地发展和响应新情况。它们可以比死板的规则集更有效地理解上下文、细微差别和意图，允许更复杂和灵活的保护机制。

此外，神经符号代理解决了可能在要求之间出现冲突的问题，利用历史数据进行符号推理，并具有与其他AI系统协作的能力[47]。虽然基于LLM的解决方案可能会引入计算开销，但通过采用专门设计用于防护措施任务的轻量级模型，可以减轻这一潜在缺点。这些优化的模型可以在减少资源需求的同时提供基于LLM的安全优势，实现了强大保护和操作效率之间的平衡。

事实上，在代理的一般范围内，核心代理可以与辅助LLM通信，后者在专门的数据集上进行了微调，以设定主LLM生成的响应的可接受性准则。核心代理允许定制防护措施规则，包括监控和执行协议[12]。然后，这些定制规则传递给辅助LLM以对输入的性质进行分类。这种分类帮助核心代理决定是否满足了要求。这种方法的一个著名例子是LLaMA Guard[12](https://arxiv.org/pdf/2402.01822)。由Meta(Facebook)引入，它专门设计用于保证LLaMA模型的安全性和合理使用，并用于分析输入和输出数据。它采用预测分类技术来评估和提高跨用户指定类别的安全性。这种实施强调了基于LLM的防护措施在加强AI系统的完整性和可靠性中的关键作用。通过利用LLM的能力来理解和执行复杂的安全规则，Llama Guard为确保安全和负责任的AI操作提供了灵活而强大的机制，特别是在像Llama 3.1[53]这样的下一代LLM模型中。

为了总结基于LLM的代理统一建模框架，我们提出的解决方案通过引入核心代理组件来模仿人脑的模块化架构，该组件包括五个内部模块：规划、记忆、档案、行动和安全。这种模块化设计在安全级别上引入了增强，并解决了可扩展性和可维护性方面的挑战，有效地将核心代理功能与LLM分开。因此，这种结构化方面强调了每个模块的作用及其集成的含义，特别是规划模块，因为它赋予了采用它的核心代理权威性。后一种观点导致了将在第3.3节讨论的核心代理的分类。

### 3.3 核心代理分类

主动/被动核心代理分类 Active/Passive Core-Agent Classification

正如前几节所讨论的，核心代理是LLM-Agent-UMF中的一个独立实体。虽然LLM擅长于理解、推理和生成响应等认知任务，但它缺乏直接与环境或外部工具互动的能力。这就是核心代理发挥关键作用的地方。它弥合了LLM的认知能力与与外部资源互动的需求之间的差距，实现了与各种工具和系统的无缝集成。因此，核心代理以其行动能力和通过与这些不同工具的互动来响应用户请求的能力而著称。实际上，ToolLLM是一个通用的工具使用框架，它增强了LLM的能力，使代理能够使用外部工具和API。它使用神经API检索器来为每个指令推荐适当的API。然后它们采用基于深度优先搜索的决策树算法来评估多个推理轨迹并扩展搜索空间。因此，它增强了检索器(retriever)的规划能力，并赋予了微调后的LLM，ToolLlaMA，生成适当指令的能力。在这里，检索器与基于搜索的决策树算法相结合，满足了我们对核心代理的定义。在这种情况下，基于LLM的代理执行认知任务时，记忆和规划模块在核心代理中是必不可少的，以确保推理能力，因为它们使代理能够保留和回忆过去的经历，规划和同步行动，推理和做出决策。

在其他情况下，例如Toolformer，我们识别出符合我们定义的核心代理的实体，但缺少规划和记忆模块。事实上，Toolformer对其LLM进行了功能调用的微调，使其能够在需要时生成API请求。因此，LLM决定何时进行API调用，使用哪个API以及如何整合结果，而API请求的实际执行则委托给我们识别为核心代理的实体。在这种情况下，核心代理的规划模块是多余的，因为规划完全由LLM处理。然而，它的行动模块是存在的，因为它仍然负责系统地执行API调用。例如，如果模型建议使用计算器API，核心代理将检索数学操作的参数，执行计算，并将计算结果返回给LLM。

对最新技术的研究得出结论，行动模块在核心代理中总是不可或缺的，因为它负责产生执行步骤以实现其目标。然而，核心代理的架构差异以及在一些提议的代理系统中缺少一些模块，突显了引入新的分类法对核心代理进行分类的必要性，将其分为两类：主动核心代理和被动核心代理。以下各节将分析并明确主动和被动核心代理在结构上与我们框架的主要差异和相似之处。

#### 3.3.1 活跃核心代理

主动核心代理包括第3.2节描述和图3所示的五个模块，但区分主动和被动核心代理的是其管理方面的特点。主动核心代理以在代理中的领导地位而著称，作为其他组件的协调者，因此它自然需要一个规划模块来将任务分解为子任务，并与记忆模块协作以提供必要的上下文、分析信息并做出决策。因此，我们认为主动核心代理是有状态的，意味着它可以维护有关其过去互动和状态的信息。这通过一个自适应的记忆来实现，它捕获并存储代理生命周期的各个方面，允许它使用这些历史数据来指导未来的行动和决策。在主动核心代理类别中，档案模块的作用被强调，因为它指导LLM的特定行为方向。此外，安全模块在保护LLM与人类之间的通信方面发挥着重要作用，确保可靠的交换；作为中介，核心代理通过实施表1中概述的安全措施，保护LLM免受越狱尝试等威胁，并保护用户数据隐私。

在我们的最新技术研究中，我们观察到基于LLM的代理最近建立在从规划到执行任务的主动核心代理上[4]。正如[17]中强调的，主动核心代理更有效，因为它们包含了规划和记忆模块，使它们能够有效地推理、规划和执行任务。这种结构允许代理适应变化的情况并做出明智的决策，使系统更加健壮和有能力。

然而，完全依赖主动核心代理会增加代理的复杂性，这可能导致可扩展性问题，并负面影响代理的可维护性，因为它将阻碍和复杂化未来的改进工作。正如[17]中指出的，“代理系统随着其需要执行的任务数量的增加而呈指数级增长”。因此，与其将责任集中在一个实体上，不如利用其他核心代理来细化任务执行并降低代理系统的复杂性，这将更有益，并符合单一职责原则。这种方法得到了软件工程中“关注点分离”概念的支持，它强调了在多个组件之间分配责任以提高系统模块化和可维护性的重要性。通过在多个核心代理之间分配任务，我们可以减少单个核心代理的认知负荷，提高系统效率，并提高整体性能。

#### 3.3.2 被动核心代理

被动核心代理在LLMs承担代理的所有认知任务，如规划和决策时被使用，而被动核心代理的角色主要是执行特定程序。直接后果是，规划模块变得不必要，同样，推理中所需的记忆也不需要。与主动核心代理不同，被动核心代理是无状态的，短期记忆由LLM处理，只覆盖当前任务的状态。在基于LLM的代理中，被动核心代理始终遵循特定领域的LLMs的指示，缺乏控制LLM档案的能力，因此没有档案模块。LLM档案可能在系统设置期间静态定义，或由另一个实体动态定义，这将在下一节讨论。

被动核心代理中最重要的模块是行动模块。我们的框架认为，被动核心代理的功能限于特定任务的执行。行动通常由API调用请求触发，这些请求不是由被动核心代理基于决策或自行生成的，而是由另一个实体(例如，LLM或主动核心代理)提供的，如图4所示。行动不会改变代理的内部状态或更改预定计划。这再次指出了被动核心代理中缺少规划模块。此外，我们引入了被动和主动核心代理之间的另一个区别：人类与核心代理之间的通信在两类中都是互动的和双向的，旨在收集信息和/或反馈。然而，正如图4所指出的，人类与被动核心代理之间的通信只能由被动核心代理部分发起，这与主动核心代理不同，在主动核心代理中，通信可以由任何一方发起。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9004.png" alt="包括被动核心代理的基于LLM的代理架构" style="width:800px" align="left" />

图4 LLM-based agent architecture including a passive core-agent

尽管被动核心代理不直接负责处理来自人类的提示并提供生成的文本响应，但它们仍应拥有一个健全的安全模块。这一组件在确保它们与其他人类或第三方系统的互动过程中的隐私至关重要，通过防止敏感数据泄露，同时最大程度地减少潜在威胁和违规行为。因此，这增强了基于LLM的代理应用的整体可信度和可靠性。同样重要的是要注意，在如图4所示的设置中，LLM通过实施第3.2.5节中先前讨论的一种机制(如对抗性训练)来确保提示的安全性。

在本节中，我们详细描述了被动和主动核心代理的构建，强调了它们的架构设计。这一分析使我们能够识别它们的用途和局限性，详细见表2。这两个类别都提高了模块化，降低了系统复杂性，并具有多任务处理能力。被动核心代理加强了单一职责原则，并意味着基于行动和安全模块的简单实现，提高了可重用性，并提供了简单的集成到多核心代理设置中的途径，最小化了同步要求，这将在第3.4节中讨论。然而，它们的简单性限制了它们处理复杂任务的能力，排除了人类发起的通信，并缺乏记忆。因此，它限制了对代理的整体状态和上下文数据访问的可见性，这些只能通过API调用请求获得。此外，它们无法控制LLM档案。

相比之下，主动核心代理增强了LLM的规划和记忆能力，使它们适合处理复杂任务。它们可以访问记忆和上下文数据，动态控制LLM的档案，并将复杂任务分解为可管理的子任务。尽管有这些优势，但与被动核心代理相比，主动核心代理需要复杂的实现，涉及额外的模块，并且在多核心代理设置中需要复杂的同步，这将在第3.4节中详细说明。

### 3.4 多核心代理架构

处理复杂任务通常需要使用多个代理，因为单个代理可能不具备应对不同领域的所需能力或专业知识。然而，基于LLM的多代理系统面临着包括可扩展性、集成、代理间关系管理以及在管理复杂任务时确保可解释性等方面的重大挑战[55]。在某些情况下，实施多代理系统可能是不必要的，因为它们的复杂性和缺点可以通过多核心代理系统来规避。单一代理系统可以潜在地容纳多个核心代理，每个核心代理专注于不同的任务，如系统执行或复杂管理。这个想法引导我们提出了一个开创性的多主动/被动核心代理架构。

为了在代理系统内有效分配责任和管理工作负载，我们必须提出一个高效的多核心代理架构分类。我们的框架将多核心代理分为两个主要类别：统一和混合。

#### 3.4.1 统一多核代理

统一多核心代理完全基于主动核心代理或被动核心代理，与混合多核心代理不同，后者在单个系统中整合了主动和被动核心代理。

**统一多被动核心代理架构**

利用被动核心代理处理低级操作和执行特定任务的能力。图5所示的配置是一个例子，其中LLM与多个被动核心代理通信，并战略性地利用它们单一的优势来检索不同信息或执行专门功能，以生成全面的最终输出。实际上，语言模型承担领导角色，并对被动核心代理群体拥有完全控制权。

本质上，统一多被动核心代理系统的特点在于易于集成新的被动核心代理，从而在不需要复杂同步的情况下扩展其功能。因此，引入新的被动核心代理所产生的唯一修改涉及调整LLM档案，可以在设置/配置时间静态进行，也可以通过主动核心代理动态进行，这将在混合设置的上下文中讨论。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9005.png" alt="多被动核心代理架构" style="width:800px" align="left" />

图5 Multi-Passive Core-Agent Architecture

**统一主动核心代理架构**

处理一个系统中一群主动核心代理的互动，如图6所示。与仅使用行动和安全模块运行的被动核心代理相反，主动核心代理拥有所有五个模块(规划、记忆、档案、行动和安全)，使它们能够管理复杂的认知任务。由于其更广泛的能力和功能，这种架构可能被视为统一多被动核心代理设计的更好替代方案。然而，由于主动实体的权威性质，多主动核心代理设计比仅基于被动核心代理的设计更为复杂。在一个系统中包含多个主动元素引入了类似于多代理系统中的挑战。例如，主动核心代理之间的有效通信至关重要；鉴于它们的动态性质，及时准确地交换信息(如兄弟姐妹核心代理之间的反馈和状态更新)对于确保代理的协同运作至关重要。随着主动核心代理数量的增加，管理内部通信变得越来越复杂，导致频繁出现的同步问题。这就是为什么多主动核心代理系统可能需要共识算法，如Raft，来选举领导者。

因此，我们推断这两种架构的独立实施是有限的，可能会有问题。虽然多被动核心代理架构在执行细粒度任务和低级操作方面是高效的，但它缺乏处理决策、任务规划和资源分配等高级任务的组件，这些是多主动核心代理系统固有的。然而，后者引入了同步问题并增加了系统复杂性。这种困境迫使我们引入混合方法。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9006.png" alt="多主动核心代理架构" style="width:800px" align="left" />

图6 Multi-Active Core-Agent Architecture

#### 3.4.2 混合多核代理

为了利用被动和主动核心代理架构的优势，我们提出了一个最优系统，如图7所示。它在一个统一的系统中整合了一个作为管理者的主动实体和多个作为工作者的被动实体。主动核心代理的管理方面之一是它能够动态配置LLMs的档案，使它们能够有效地利用被动核心代理来处理特定任务。这种配置利用了在主动核心代理的指导和领导下，众多被动核心代理的并行执行能力，使系统能够处理更广泛的任务，同时保持适当的灵活性、可扩展性和可扩展性。

这种混合设计实现了多核心架构的全部潜力：通过结合统一被动核心代理架构的优势和主动核心代理的能力，系统可以根据手头任务的具体要求动态分配资源和调整其配置。我们提出的一主动多被动架构在多主动核心代理架构的复杂性和被动核心代理提供的实用性之间取得了平衡。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9007.png" alt="一主动多被动核心代理混合架构" style="width:800px" align="left" />

图7 One-active-many-passive core-agent hybrid architecture

事实上，在以动态环境变化为特征的场景中，包含多个主动核心代理变得至关重要，以维持代理的弹性和适应性。自然地，鉴于前面概述的复杂性，基于许多主动和许多被动核心代理的代理的实现，如图8所示，将是复杂的，特别是在主动核心代理之间的同步层面。这样的系统需要精心设计，强调代理内部的互动、遵守通信协议、为每个主动核心代理划分任务和错误处理策略。显然，这些挑战强调了我们提出的一主动多被动架构的简单性。然而，仍然有一个充满希望的机会进行进一步的研究，因为多主动核心代理带来的挑战为推进和完善我们的框架铺平了道路。

总之，核心代理的模块化有助于从软件的角度保证代理架构内的可组合性。它便于在系统扩展时将新的被动核心代理无缝集成到单一代理系统中，避免了向多代理系统的过渡。此外，这种架构通过遵循开放/封闭原则(OCP)，增强了核心代理在不断发展的系统中的集成，促进了健壮性和灵活性，从而解决了可扩展性和适应性挑战。正如论文[6]中概述的，系统的扩展需要动态扩展以适应不断增长的需求并确保最佳性能。这涉及到诸如增加代理数量或使用更大的LLMs等自适应能力。这些挑战通过基于多个核心代理的架构有效地解决，主要是由于核心代理在代理系统中的单一角色。事实上，我们的框架允许主动核心代理动态地加入或分离被动核心代理，如图8中连接领导者主动核心代理和被动核心代理(2)的开关所示。在下一节中，我们将讨论我们工作的成果。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9008.png" alt="多主动多被动核心代理混合架构" style="width:800px" align="left" />

图8 Many-active-many-passive core-agent hybrid architecture

## 4 结果与讨论

### 4.1 新核心代理术语的评估

传统上，代理被讨论为一个单一的庞大单元，其中不同的内部功能实体，如LLMs和补充软件组件，以一种交织的方式处理，缺乏明确的定义界限。这种方法在尝试分析或比较表现出代理行为的各种系统时可能会导致混淆。代理定义仍然被误解的主要原因之一在于研究人员和实践者在描述他们的工作时使用的术语存在差异。例如，一些研究可能不会明确地将他们的基于LLM的系统称为“代理”，即使它表现出通常与代理相关的特征，如自主性、适应性和目标导向行为。ToolLLM研究论文提供了这种差异的典型例子。尽管作者确实结合使用了API检索器组件和他们的LLM，但他们避免使用“代理”一词。在Toolformer工作中也可以观察到同样的情况，它隐含地包含了由LLM生成的API调用请求的软件，但同样避免将系统称为代理。

引入“核心代理”一词来表示LLM驱动代理中的中央组件，并定义它所扮演的角色，解决了这些术语上的歧义，并促进了关于这类系统的更透明讨论。为了清晰沟通，正如[58]中所解释的，应该避免对同一事物使用不同的术语或对不同事物使用单一术语。他们建议，建立一个定义良好的语言可以帮助减少混淆，促进一致性，并增强研究人员和教育者之间的沟通。这些改进最终将促进更好的合作，导致这些系统在广泛的应用中的加速开发和优化。

我们在这项工作中解决的一个术语上的歧义涉及到“记忆”的概念。例如，ChatDB通过将记忆在一个上下文中定义为代理从知识源检索的数据，而在其他上下文中，它指的是存储处理数据和对核心代理操作至关重要的信息的空间，来说明双重用途。为了清楚地区分这些用途，我们澄清前者定义属于“数据存储库”，而后者准确地对应于“记忆”。

除了解决歧义之外，基于我们为“核心代理”组件所建立的定义，我们成功地在多个基于LLM的系统中识别出了核心代理，主要是Toolformer和ToolLLM。一方面，Toolformer包含了一个只包含负责API执行的行动模块的简单结构核心代理。

另一方面，ToolLLM采用了更复杂的方法。事实上，我们认识到使用了一个包含两个模块的核心代理：由神经API检索器代表的行动模块，以及负责管理代理内部信息流的隐含规划模块：核心代理拦截用户指令，利用API检索器收集相关的API，将API中继给LLM以生成响应，执行请求的API，最后将结果返回给LLM以制定最终用户响应。因此，在这些系统中识别出的核心代理，伴随着LLM的存在，阐明了Toolformer和ToolLLM确实是基于LLM的代理。

此外，[59]通过利用基于LLM和基于Planning Domain Definition Language (PDDL)的规划器来改进规划过程。事实上，LLM生成了基于PDDL的问题描述，然后由基于PDDL的规划器评估以制定最佳计划，最后再翻译回自然语言。我们观察到，我们的框架与上述架构一致；讨论的技术确实描述了一个包含具有PDDL解释器的规划模块的核心代理，并使用LLM将自然语言翻译。

将安全模块集成到核心代理中的做法得到了LLM中存在的安全问题和全面解决它们的迫切性的证实。虽然一些研究只关注防护措施技术或算法，而不将它们与代理联系起来，但利用我们框架的应用防护措施发生在核心代理的框架内，特别是在其安全模块内。

例如，LLMSafeGuard引入了一个轻量级框架来实时保护LLM文本生成。这项研究选择了使用beam search算法来生成候选响应。利用外部验证器，它拒绝违反安全约束的候选者，并继续使用有效的候选者。将这项工作投射到我们的框架上，我们得出结论，外部验证器确实是一个核心代理，其规划模块评估候选者与代理的安全约束的一致性，以决定在拒绝的情况下生成替代候选者还是在接受的情况下进行句子完成。显然，这个模块与实施实时验证方法的安全模块通信，以决定在LLM的生成过程中采取哪条路径。

尽管论文[60]强调了通过提出实现每个属性的方法来实现基于LLM的代理的可靠性、机密性和完整性的必要性，但它并没有明确地从架构上讨论这些机制的实施。此外，所有讨论的技术都服务于我们框架中概述的各种安全目标，强化了将防护措施重新定位到核心代理内安全模块的理由。

### 4.2 主动/被动核心代理概念的评估

我们引入的框架LLM-Agent-UMF，为比较几种最先进的基于LLM的代理提供了一个有价值的工具，如表3所示。在本节中，我们通过将LLM-Agent-UMF投影到现有的代理实现上，并强调规划、记忆、档案、行动和安全模块等基本模块的存在或缺失，来评估我们的LLM-Agent-UMF。这种分析使我们能够将识别出的核心代理归类为主动和被动。此外，它提供了对现有代理结构的洞察，促进了将不同代理的功能合并到一个系统中以增强能力的机会。

由于一些解决方案，如ChatGPT，是专有的且封闭源代码的，我们不能断然地分析其结构和能力，也不能透明地将它们投影到我们自己的框架上。基于观察到的行为和关于ChatGPT的公开信息，我们可以对其特性和能力做出合理的假设，但不能明确地陈述它们。

为了指导我们的假设，我们评估了ChatGPT 4o mini对非法提示的反应，要求提供热车步骤。我们的调查旨在验证系统在面对恶意查询时的行为。正如我们所期望的，ChatGPT 4o mini拒绝回应直接的非法提示，如图14附录A所示。因此，我们制定了两个关于如何实施安全措施的假设：

#### 假设1

LLM本身被训练来监控输入并防止生成不期望的输出。这可以通过坚持对抗性训练(AT)技术并实施输入验证和清理来实现，以防止恶意提示被使用。此外，如果我们将ChatGPT 4o mini视为一个代理，没有明确证据表明它与外部工具的互动，这将需要核心代理中的行动模块的功能。基于这个论点，我们假设ChatGPT 4o mini首先不是一个代理。

#### 假设2

安全措施独立于主LLM的范围之外实施。输入在转发给LLM之前被处理，输出在生成后并在呈现给用户之前被监控。根据这一事件流程，我们观察到最低程度的算法规划，因此需要一个主动核心代理来管理ChatGPT的防护措施。然而，这种为特定目标设计的简单规划——确保防护工作流程——不需要记忆模块，也不需要档案模块

同样，我们考虑ChatGPT 4o在代码执行上的能力，并假设存在一个主动核心代理。事实上，我们围绕该过程构建了**第三个假设**，如下所示：核心代理检查提示是否需要编码操作。如果是这样，它根据手头的任务改变LLM的档案，然后利用LLM的能力生成代码，该代码稍后在隔离环境中执行。之后，它将LLM的档案重置为解释结果的适当文本表示。这个假设可以通过ChatGPT 4o mini第二个假设关于安全措施的假设进一步丰富，使我们得出结论，ChatGPT 4o是一个具有全功能主动核心代理的基于LLM的代理，而不是一个独立的LLM。

在表3中，我们对一组基于LLM的代理进行了分类。我们的选择包括多种开源和专有代理。

通过独立检查每个代理中的核心代理，开发者可以推断核心代理的兼容性，并识别将多个代理集成到一个系统中可能遇到的挑战，如同步的必要性、核心代理之间的潜在冲突或功能冗余。

### 4.3 多核代理架构评估

得益于表3中进行的分类，我们现在可以轻松地将现有代理的各个方面合并到一个单一实体中。为了演示这一能力，我们提出了四个代表性场景，这些场景突出了LLM-Agent-UMF在设计多核心代理系统方面的潜力，通过结合来自最先进代理的独特特征。这些场景每一个都利用了Llama 3.1 8B，这是Meta AI团队的最新最先进LLM，因其卓越的性能和优化的记忆占用而选择。

#### 4.3.1 Toolformer 和 Confucius 作为多被动核心代理系统

由于Toolformer和[Confucius](https://ojs.aaai.org/index.php/AAAI/article/view/29759)代理都只包含被动核心代理，因此将它们的能力整合到一个代理中是可行的。如图9所示，新代理名为LA1(基于LLM的代理1)，包含两个被动核心代理。一方面，Toolformer被动核心代理赋予代理使用特殊工具的能力，如计算器、日历、知识检索LM、机器翻译系统和维基百科搜索引擎，确保LA1能够准确有效地处理这些工具。另一方面，Confucius被动核心代理作为补充的第二个核心代理，使LA1能够管理未见过的的工具，并与Toolformer一起工作，应对测试阶段未评估或遇到的新工具。这种多功能设计使LA1能够应对现实世界场景中的新挑战，同时最大化效率。

然而，确保代理LLM，Llama 3.1 8B，与相关法规数据集保持一致至关重要。正如LLM-Agent-UMF所阐明的，可以使用LoRA等技术创建可插拔模块来定义LLM的档案。实际上，应该使用Toolformer的修改版本CCNet增强API调用来教会LLM如何与Toolformer被动核心代理适当地通信。同样，Confucius作为一个工具学习框架，也应该被利用来训练LLM掌握各种外部工具。

将这两个被动核心代理整合到LA1中展示了LLM-Agent-UMF在设计多被动核心代理系统方面的有效性，并突出了其灵活性以及结合多个现有代理能力的潜力。此外，重要的是要认识到，在这一过程中，LLM-Agent-UMF引导我们识别出建筑设计的弱点，例如缺少隐私保护机制来监控Toolformer和Confucius核心代理与外部服务提供商之间的数据传输。这强调了持续研究解决这些问题的重要性。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9009.png" alt="Toolformer和Confucius-多被动核心代理架构" style="width:800px" align="left" />

图9 LLM-based Agent 1 (LA1): Toolformer and Confucius – Multi Passive Core-Agent Architecture

#### 4.3.2 ToolLLM 和 ChatDB 作为多主动核心代理系统

第二种场景探索了一种新的代理设计，该设计整合了ToolLLM和ChatDB的功能。虽然这两个代理各自拥有独特的优势，但它们的结合功能提供了有利的协同效应。ToolLLM配备了一个神经API检索器，能够利用适当的外部API来完成人类的指令。另一方面，ChatDB包含了一个基于SQL的符号记忆框架，使得LLM能够执行复杂的多跳推理。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9010.png" alt="ToolLLM和ChatDB-多活跃核心代理架构" style="width:800px" align="left" />

图10 LLM-based Agent 2-A (LA2-A): ToolLLM and ChatDB – Multi Active Core-Agent Architecture

正如第3.4.2节中提到的，在一个系统中整合多个活跃的核心代理可能会带来挑战。为了评估这种情况，探索了两种架构变体：LA2-A和LA2-B。在LA2-A中，如图10所示，ToolLLM和ChatDB作为两个独立的活跃核心代理保留了它们各自的功能。这种情况需要在两个活跃核心代理之间进行同步，选择像Raft[56]这样的共识算法将是一个明智的选择。为了进一步优化系统的记忆占用，将在两个活跃核心代理之间共享一个独特的Llama 3.1 8B实例，它们中的每一个都必须动态地注入适当的档案，无论是作为可插拔的训练模块如LoRA还是使用系统提示。

然而，对于LA2-B，如图11所示，两个核心代理的独特能力被合并到一个单一的庞大的活跃核心代理中。在这种情况下，识别可能出现冲突的特定模块至关重要。作为活跃核心代理的关键元素，规划模块必须进行彻底分析。实际上，它应该被设计为通过整合ToolLLM的API检索器来最优地处理外部API调用，同时与ChatDB的记忆模块无缝通信，后者专门处理基于SQL的数据库管理。此外，档案模块必须能够根据手头的任务为LLM选择合适的档案。通过解决这些模块中的潜在冲突，LA2-B可以有效地利用两个代理的优势，并通过只使用一个庞大的活跃核心代理来实现协同优势。

这两种场景都突出了LLM-Agent-UMF在设计结合了多个复杂最新代理的新型基于LLM的代理方面的多功能性，并在集成努力中识别和解决相关挑战。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9011.png" alt="ToolLLM和ChatDB-多活跃核心代理架构" style="width:800px" align="left" />

图11 LLM-based Agent 2-A (LA2-A): ToolLLM and ChatDB – Multi Active Core-Agent Architecture

#### 4.3.3 在 ToolLLM 中植入 LLMSafeGuard 安全模块

第三个观察是，任何活跃的核心代理都可以作为基础，扩展其他模块，如图12所示。以ToolLLM为例，我们可以植入基于特定安全目标选定的另一个代理的安全模块。也就是说，如果目标是用实时保护生成的文本来增强ToolLLM的能力[54]，我们可以结合LLMSafeGuard的安全模块，从而形成一个新设计的代理，LA3。这个例子强调了从软件架构的角度来看，这种集成的简单性。

事实上，LLM-Agent-UMF使我们能够轻松地识别和纳入缺失的模块，而不会造成功能冲突或挑战。从结构上看，LA3继承了ToolLLM的四个主要模块，以及来自LLMSafeGuard的安全模块，无缝地扩展了其能力，同时保持了组件之间的兼容性和一致性。

#### 4.3.4 混合主动/被动核心代理系统

最后提出的代理设计，LA4，是最具广泛基础的集成提案，代表了第3.4.2节中概述的一活跃多被动架构。如图13所示，LA4架构包含了来自LLM+P的活跃核心代理，植入了LLMSafeGuard的安全模块，并整合了来自Toolformer和Confucius的两个被动核心代理。

选择LLM+P活跃核心代理作为我们中心活跃实体的动机是其尖端的规划模块。正如第4.1节中描述的，它无缝地使用LLM从自然语言输入生成基于PDDL的描述，随后由集成的PDDL规划器评估以制定最优计划。不幸的是，正如表3中所确定的，LLM+P没有安全模块，这使得整个代理容易受到安全威胁，如对抗性攻击，这些攻击可以轻易绕过使用对抗性训练等基本保护机制。这导致我们利用了第4.3.3节中提出的相同解决方案，在LLM+P活跃核心代理中植入了LLMSafeGuard安全模块。结果，这一过程产生了一个优化的活跃核心代理，它包含了有效运行所需的所有五个必要模块，同时确保了对潜在安全威胁的强大防护。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9012.png" alt="ToolLLM与LLMSafeGuard的安全模块" style="width:800px" align="left" />

图12 LLM-based Agent 3 (LA3): ToolLLM with the security module of LLMSafeGuard

为了进一步增强LA4的能力和性能，赋予代理有效利用现有工具和API的技能将是有利的。在第4.3.1节中，由于它们的互补特性，Toolformer和Confucius被提议为合适的候选者。事实上，它们的被动核心代理性质使得集成变得简单，并不要求高级的同步机制，因为两者都将由LLM控制，而LLM本身由活跃核心代理管理。主要考虑的是将Toolformer和Confucius的档案整合到LA4活跃核心代理的档案模块中，允许它根据特定需求动态地调整LLM的行为。通过在LA4中结合这些不同的技术，它将成为一个综合代理，能够利用工具和外部API制定最优的规划策略。

尽管如此，至关重要的是要解决在LA4设计中通过应用LLM-Agent-UMF发现的安全漏洞。事实上，Toolformer和Confucius被动核心代理使用的外部API调用机制没有被监控或防范潜在的信息泄露。遵循LLM-Agent-UMF提供的指导，这个问题可以通过在这些被动核心代理上实施专门的安全模块，或者作为活跃核心代理安全模块内的补充措施来解决，从而集中管理信息保护过程。技术和实施细节的最佳选择将在未来的工作中探索。

前四种场景示例说明了研究人员和开发人员在开发过程之前，如何根据清晰的架构推理做出有关LLM基础代理设计的明智决策。这种系统化的方法将增强基于LLM的代理的鲁棒性和功能性。在下一节中，我们将讨论局限性和未来的工作，以增强我们的框架。

<img src="https://arxiv.org/html/2409.11393v1/extracted/5859312/fig9013.png" alt="LLM+P-LLMSafeGuard-Toolformer和Confucius-混合活跃/被动核心代理" style="width:800px" align="left" />

图13 LLM-based Agent 4 (LA4): LLM+P, LLMSafeGuard, Toolformer and Confucius – Hybrid Active/Passive Core-Agent

## 5 结论和未来工作

在本文中，我们介绍了基于LLM的代理中名为核心代理的结构组件。这个组件旨在解决软件开发人员遇到的架构模糊性问题，并增强模块化。我们提出了LLM-Agent-UMF，这是一个全面的框架，用于建模代理的结构，详细说明了核心代理的五个模块：规划、记忆、档案、行动和安全。随后，我们将核心代理分类为被动和主动，并强调了它们的结构和功能差异。基于这种分类，我们设计了统一和混合的多核心代理架构。最突出的是，一活跃多被动架构充分利用了活跃和被动核心代理的潜力，在开发简便性和混合架构的强大能力之间取得了平衡。通过将我们的框架应用于最新代理，我们识别出了它们结构中的核心代理及其构成的内部模块，这有助于我们的分类过程。这使我们能够认识到每个代理的个体特征，并发现将不同功能合并到单个多核心代理中的潜在前景。

我们的工作为基于LLM的代理的发展奠定了基础，这些代理具有清晰的结构，并利用了核心代理的力量。LLM-Agent-UMF的逐步采用将进一步证明其效率。改进它的一个有趣的未来方向是寻找简化多活跃核心代理架构实施的解决方案。事实上，它们面临着与同步相关的挑战，这需要进一步调查。在这种情况下，我们看到了两个有希望的途径：整合像Raft这样的共识算法来选举一个负责协调的领导者；或者，整合一个中央网关，它只负责根据负载、可用性和领域等因素选择最合适的活跃核心代理来处理用户请求。每个活跃核心代理都应在网关中注册，提供有关其能力和状态的信息。被选中的核心代理处理任务，并通过网关将响应发送回用户。

总之，这个框架的最终目的是重新构思基于LLM的代理的概念。通过基于这个单元而不是以单体方式来发展它们，研究人员和实践者可以使用统一的术语来指代共同架构中的不同模块。这个共享的基础有助于研究和增强的一致性。此外，开发人员可以开始实施一致的解决方案，这些解决方案易于维护，并且非常适合未来的改进。

## 参考文献

[1] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, 和 Xing Xie. 关于大型语言模型评估的综述。ACM智能系统技术杂志，15(3)，2024年3月。ISSN 2157-6904。doi:10.1145/3641289。网址：<https://doi.org/10.1145/3641289>。

[2] Stan Franklin 和 Art Graesser。它是代理还是仅仅是程序？自主代理的分类。在Jörg P. Müller, Michael J. Wooldridge, 和 Nicholas R. Jennings编辑的《智能代理III：代理理论、架构和语言》，第21-35页，柏林，海德堡，1997年。Springer Berlin Heidelberg。ISBN 978-3-540-68057-4。doi:10.1007/BFb0013570。

[3] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, 和 Tao Gui。大型语言模型基础代理的崛起和潜力：一项综述，2023年。

[4] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, 和 Jirong Wen。**关于基于大型语言模型的自主代理的综述**。计算机科学前沿，18(6):186345，2024年。doi:10.1007/s11704-024-40231-1。网址：<https://doi.org/10.1007/s11704-024-40231-1>。

[5] Aaron Parisi, Yao Zhao, 和 Noah Fiedel。Talm: 增强工具的语言模型，2022年。网址：<https://arxiv.org/abs/2205.12255>。

[6] Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, 和 Xiuqiang He。探索基于大型语言模型的智能代理：定义、方法和前景，2024年。网址：<https://arxiv.org/abs/2401.03428>。

[7] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, 和 Jianfeng Gao。变色龙：与大型语言模型的插件式组合推理。在A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, 和 S. Levine编辑的《神经信息处理系统进展》，第36卷，第43447-43478页。Curran Associates, Inc.，2023年。网址：<https://proceedings.neurips.cc/> paper_files/paper/2023/file/871ed095b734818cfba48db6aeb25a62-Paper-Conference.pdf。

[8] Xingyao Wang, Yangyi Chen, Lifan Yuan, Yizhe Zhang, Yunzhu Li, Hao Peng, 和 Heng Ji。可执行代码行动能更好地引发LLM代理，2024年。网址：<https://arxiv.org/abs/2402.01030>。

[9] Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Tekin, Gaowen Liu, Ramana Kompella, 和 Ling Liu。关于基于大型语言模型的游戏代理的综述，2024年。网址：<https://arxiv.org/abs/2404.02039>。

[10] Zhixuan Chu, Yan Wang, Feng Zhu, Lu Yu, Longfei Li, 和 Jinjie Gu。专业代理 - 将大型语言模型发展成具有人类水平能力的自主专家，2024年。网址：<https://arxiv.org/abs/2402.03628>。

[11] M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D. White, 和 Philippe Schwaller。用化学工具增强大型语言模型。自然机器智能，6(5):525-535，2024年5月。doi:10.1038/s42256-024-00832-8。网址：<https://doi.org/10.1038/s42256-024-00832-8>。

[12] Yi Dong, Ronghui Mu, Gaojie Jin, Yi Qi, Jinwei Hu, Xingyu Zhao, Jie Meng, Wenjie Ruan, 和 Xiaowei Huang。为大型语言模型建立护栏，2024年。网址：<https://arxiv.org/abs/2402.01822>。

[13] Alexander Wei, Nika Haghtalab, 和 Jacob Steinhardt。越狱：LLM安全训练如何失败？在A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, 和 S. Levine编辑的《神经信息处理系统进展》，第36卷，第80079-80110页。Curran Associates, Inc.，2023年。网址：<https://proceedings.neurips.cc/paper_files/paper/2023/file/fd6613131889a4b656206c50a8bd7790-Paper-Conference.pdf>。

[14] Haonan Duan, Adam Dziedzic, Nicolas Papernot, 和 Franziska Boenisch。一群随机鹦鹉：为大型语言模型进行差异性隐私提示学习。在A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, 和 S. Levine编辑的《神经信息处理系统进展》，第36卷，第76852-76871页。Curran Associates, Inc.，2023年。网址：<https://proceedings.neurips.cc/paper_files/paper/2023/file/f26119b4ffe38c24d97e4c49d334b99e-Paper-Conference.pdf>。

[15] Unggi Lee, Sanghyeok Lee, Junbo Koh, Yeil Jeong, Haewon Jung, Gyuri Byun, Yunseo Lee, Jewoong Moon, Jieun Lim, 和 Hyeoncheol Kim。为教师培训设计的生成性代理：与大型语言模型基础代理一起设计教育问题解决模拟，2023年。

[16] Apostolos Ampatzoglou, Angeliki-Agathi Tsintzira, Elvira-Maria Arvanitou, Alexander Chatzigeorgiou, Ioannis Stamelos, Alexandru Moga, Robert Heb, Oliviu Matei, Nikolaos Tsiridis, 和 Dionisis Kehagias。在工业中应用单一责任原则：模块化的好处和权衡。在第23届国际软件工程评估和评估会议论文集，EASE ’19，第347-352页，纽约，美国，2019年。计算机协会。ISBN 9781450371452。doi:10.1145/3319008.3320125。网址：<https://doi.org/10.1145/3319008.3320125>。

[17] Yuheng Cheng, Ceyao Zhang, Zhengwen Zhang, Xiangrui Meng, Sirui Hong, Wenhao Li, Zihao Wang, Zekai Wang, Feng Yin, Junhua Zhao, 和 Xiuqiang He。探索基于大型语言模型的智能代理：定义、方法和前景，2024年。网址：<https://arxiv.org/abs/2401.03428>。

[18] O. Turan 和 Ö. Ö. Tanrıöver。对微软VS代码指标的实体原则影响的实验评估。AJIT-E: 信息技术学术杂志，9(34):7-24，2018年。doi:10.5824/1309-1581.2018.4.001.x。

[19] Miguel A. Laguna, José M. Marqués, 和 Yania Crespo。用例模型中扩展关系的含义：开放封闭原则还是先见之明？在Barbara Pernici编辑的《高级信息系统工程》，第409-423页，柏林，海德堡，2010年。Springer Berlin Heidelberg。ISBN 978-3-642-13094-6。

[20] Malik Ghallab。自动规划：理论与实践。Morgan Kaufmann，2004年。

[21] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang, 和 Enhong Chen。了解LLM代理的规划：一项综述，2024年。网址：<https://arxiv.org/abs/2402.02716>。

[22] Haishuo Fang, Xiaodan Zhu, 和 Iryna Gurevych。Dara：用于知识图谱上问题回答的分解-对齐-推理自主语言代理。在Lun-Wei Ku, Andre Martins, 和 Vivek Srikumar编辑的《计算语言学协会2024年发现》，第3406-3432页，泰国曼谷和虚拟会议，2024年8月。计算语言学协会。网址：<https://aclanthology.org/2024.findings-acl.203>。

[23] Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, 和 Ting Liu。穿越迷宫的导航：思维链推理的综述：进展、前沿和未来。在Lun-Wei Ku, Andre Martins, 和 Vivek Srikumar编辑的《第62届计算语言学协会年会论文集(第1卷：长论文)》，第1173-1203页，泰国曼谷，2024年8月。计算语言学协会。网址：<https://aclanthology.org/2024.acl-long.65>。

[24] Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger, Guangyuan Piao, Nils Blach, Piotr Nyczyk, Marcin Copik, Grzegorz Kwas ́niewski, Jürgen Müller, Lukas Gianinazzi, Ales Kubicek, Hubert Niewiadomski, Aidan O’Mahony, Onur Mutlu, 和 Torsten Hoefler。揭开思维链、树和图的神秘面纱，2024年。网址：<https://arxiv.org/abs/2401.14295>。

[25] Malik Ghallab, Craig Knoblock, David Wilkins, Anthony Barrett, Dave Christianson, Marc Friedman, Chung Kwok, Keith Golden, Scott Penberthy, David Smith, Ying Sun, 和 Daniel Weld。PDDL - 规划领域定义语言，1998年8月。

[26] Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, 和 Ji-Rong Wen。关于基于大型语言模型的代理记忆机制的综述，2024年。网址：<https://arxiv.org/abs/2404.13501>。

[27] R.C. Atkinson 和 R.M. Shiffrin。人类记忆：一个提议的系统及其控制过程。在Kenneth W. Spence 和 Janet Taylor Spence编辑的《学习和动机心理学》，第2卷，第89-195页。Academic Press，1968年。doi:10.1016/S0079-7421(08)60422-3。网址：<https://www.sciencedirect.com/> science/article/pii/S0079742108604223。

[28] Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, 和 Yanlin Wang。MemoryBank：增强大型语言模型的长期记忆。人工智能协会会议论文集，38(17): 19724-19731，2024年3月。doi:10.1609/aaai.v38i17.29946。网址：<https://ojs.aaai.org/index.php/AAAI/> article/view/29946。

[29] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, 和 Anima Anandkumar。Voyager：一个具有大型语言模型的开放式具身代理。机器学习研究交易，2024年。ISSN 2835-8856。网址：<https://openreview.net/forum?id=ehfRiF0R3a>。

[30] Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, 和 Hang Zhao。ChatDB：将数据库作为大型语言模型的符号记忆增强，2023年。网址：<https://arxiv.org/abs/2306.03901>。

[31] Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang, 和 Jifeng Dai。幽灵在Minecraft中：通过基于文本的知识和记忆训练大型语言模型的通用能力代理，2023年。网址：<https://arxiv.org/abs/2305.17144>。

[32] AniketKumarSingh, Bishal Lamichhane, Suman Devkota, Uttam Dhakal, 和 Chandra Dhakal。大型语言模型是否表现出类人偏见？探索人工智能中的信心-能力差距。信息，15(2)，2024年。ISSN 2078-2489。doi:10.3390/info15020092。网址：<https://www.mdpi.com/2078-2489/15/2/92>。

[33] Aniket Kumar Singh, Bishal Lamichhane, Suman Devkota, Uttam Dhakal, 和 Chandra Dhakal。大型语言模型是否表现出类人偏见？探索人工智能中的信心-能力差距。Inf., 15:92，2024年。网址：<https://api.semanticscholar.org/CorpusID:267539494>。

[34] Lisa P. Argyle, Ethan C. Busby, Nancy Fulda, Joshua R. Gubler, Christopher Rytting, 和 David Wingate。从一个，许多：使用语言模型模拟人类样本。政治分析，31(3):337-351，2023年。doi:10.1017/pan.2023.2。

[35] Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, 和 Fu Lee Wang。针对预训练语言模型的参数高效微调方法：关键回顾和评估，2023年。网址：<https://arxiv.org/abs/2312.12148>。

[36] Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, 和 Yitao Liang。描述、解释、规划和选择：与大型语言模型的交互式规划使开放世界多任务代理成为可能，2024年。网址：<https://arxiv.org/abs/2302.01560>。

[37] Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, 和 Thomas Scialom。Toolformer：语言模型可以自学使用工具。在A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, 和 S. Levine编辑的《神经信息处理系统进展》，第36卷，第68539-68551页。Curran Associates, Inc.，2023年。网址：<https://proceedings.neurips.cc/paper_files/paper/2023/file/d842425e4bf79ba039352da0f658a906-Paper-Conference.pdf>。

[38] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, 和 Yueting Zhuang。HuggingGPT：用ChatGPT及其朋友们解决AI任务。在A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, 和 S. Levine编辑的《神经信息处理系统进展》，第36卷，第38154-38180页。Curran Associates, Inc.，2023年。网址：<https://proceedings.neurips.cc/paper_files/paper/2023/file/77c33e6a367922d003ff102ffb92b658-Paper-Conference.pdf>。

[39] Jerry Liu。LlamaIndex，2022年11月。网址：<https://github.com/jerryjliu/llama_index>。

[40] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, 和 Yuan Cao。React：在语言模型中结合推理和行动，2023年。网址：<https://arxiv.org/abs/2210.03629>。

[41] Abhay Zala, Jaemin Cho, Han Lin, Jaehong Yoon, 和 Mohit Bansal。EnvGen：通过LLM生成和适应环境以训练具身代理，2024年。网址：<https://arxiv.org/abs/2403.12014>。

[42] MD Minhaz Chowdhury, Nafiz Rifat, Mostofa Ahsan, Shadman Latif, Rahul Gomes, 和 Md Saifur Rahman。ChatGPT：对网络安全CIA三角的威胁。在2023年IEEE国际电子信息技术会议(eIT)论文集，第1-6页，2023年。doi:10.1109/eIT57321.2023.10187355。

[43] Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, 和 Noah A. Smith。RealToxicityPrompts：评估语言模型中的神经毒性退化。在Trevor Cohn, Yulan He, 和 Yang Liu编辑的《计算语言学协会：EMNLP 2020发现》，第3356-3369页，在线，2020年11月。计算语言学协会。doi:10.18653/v1/2020.findings-emnlp.301。网址：<https://aclanthology.org/2020.findings-emnlp.301>。

[44] Ian J. Goodfellow, Jonathon Shlens, 和 Christian Szegedy。解释和利用对抗性示例，2015年。网址：<https://arxiv.org/abs/1412.6572>。

[45] Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Zihao Wang, Xiaofeng Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, 和 Yang Liu。针对LLM集成应用的提示注入攻击，2024年。网址：<https://arxiv.org/abs/2306.05499>。

[46] Traian Rebedea, Razvan Dinu, Makesh Narsimhan Sreedhar, Christopher Parisien, 和 Jonathan Cohen。NeMo护栏：一个用于可控制和安全的LLM应用的可编程护栏工具包。在Yansong Feng 和 Els Lefever编辑的《2023年自然语言处理经验方法会议：系统演示》，第431-445页，新加坡，2023年12月。计算语言学协会。doi:10.18653/v1/2023.emnlp-demo.40。网址：<https://aclanthology.org/2023.emnlp-demo.40>。

[47] Yi Dong, Ronghui Mu, Yanghao Zhang, Siqi Sun, Tianle Zhang, Changshun Wu, Gaojie Jin, Yi Qi, Jinwei Hu, Jie Meng, Saddek Bensalem, 和 Xiaowei Huang。保护大型语言模型：一项综述，2024年。网址：<https://arxiv.org/abs/2406.02622>。

[48] Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Zichao Wang, Furong Huang, Ani Nenkova, 和 Tong Sun。AutoDan：对大型语言模型的可解释梯度基础对抗性攻击，2023年。网址：<https://arxiv.org/abs/2310.15140>。

[49] Ximing Dong, Dayi Lin, Shaowei Wang, 和 Ahmed E. Hassan。实时保护大型语言模型文本生成的框架，2024年。网址：<https://arxiv.org/abs/2404.19048>。

[50] Haoran Li, Yulin Chen, Jinglong Luo, Yan Kang, Xiaojin Zhang, Qi Hu, Chunkit Chan, 和 Yangqiu Song。大型语言模型中的隐私：攻击、防御和未来方向，2023年。网址：<https://arxiv.org/abs/2310.10383>。

[51] John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, 和 Tom Goldstein。大型语言模型的水印，2024年。网址：<https://arxiv.org/abs/2301.10226>。

[52] Maria-Irina Nicolae, Mathieu Sinn, Minh Ngoc Tran, Beat Buesser, Ambrish Rawat, Martin Wistuba, Valentina Zantedeschi, Nathalie Baracaldo, Bryant Chen, Heiko Ludwig, Ian M. Molloy, 和 Ben Edwards。对抗性鲁棒性工具箱v1.0.0，2019年。网址：<https://arxiv.org/abs/1807.01069>。

[53] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, 和 Aiesha Letman等人。Llama 3模型群，2024年。网址：<https://arxiv.org/abs/2407.21783>。

[54] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, 和 Maosong Sun。ToolLLM：促进大型语言模型掌握16000+现实世界API，2023年。网址：<https://arxiv.org/abs/2307.16789>。

[55] Thorsten Händler。自主LLM驱动的多代理架构的分类。在KMIS，第85-98页，2023年。

[56] Dongyan Huang, Xiaoli Ma, 和 Shengli Zhang。对私有区块链RAFT共识算法的性能分析。IEEE系统、人与控制论系统交易，50(1):172-181，2020年。doi:10.1109/TSMC.2019.2895471。

[57] Diego Ongaro 和 John Ousterhout。寻找一种易于理解的共识算法。在2014年USENIX年度技术会议(USENIX ATC 14)，第305-319页，宾夕法尼亚州费城，2014年6月。USENIX协会。ISBN 978-1-931971-10-2。网址：<https://www.usenix.org/conference/atc14/technical-sessions/> presentation/ongaro。

[58] Josip Slisko 和 Dewey I Dykstra Jr。科学术语在研究和教学中的作用：是否遗漏了重要的东西？研究教学杂志：国家研究教学协会官方杂志，34(6):655-660，1997年。

[59] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, 和 Peter Stone。LLM+P：赋予大型语言模型最优规划能力，2023年。网址：<https://arxiv.org/abs/2304.11477>。

[60] Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, Rui Kong, Yile Wang, Hanfei Geng, Jian Luan, Xuefeng Jin, Zilong Ye, Guanjing Xiong, Fan Zhang, Xiang Li, Mengwei Xu, Zhijun Li, Peng Li, Yang Liu, Ya-Qin Zhang, 和 Yunxin Liu。个人LLM代理：关于能力、效率和安全的见解和综述，2024年。网址：<https://arxiv.org/abs/2401.05459>。

[61] Aleksander Ma ̨dry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, 和 Adrian Vladu。朝着对抗性攻击的大型学习模型发展。统计，1050(9)，2017年。

[62] Shishir G. Patil, Tianjun Zhang, Xin Wang, 和 Joseph E. Gonzalez。Gorilla：将大型语言模型与大量API连接，2023年。网址：<https://arxiv.org/abs/2305.15334>。

[63] Shen Gao, Zhengliang Shi, Minghang Zhu, Bowen Fang, Xin Xin, Pengjie Ren, Zhumin Chen, Jun Ma, 和 Zhaochun Ren。Confucius：通过由易到难的课程从内省反馈中迭代工具学习。人工智能协会会议论文集，38(16):18030-18038，2024年3月。doi:10.1609/aaai.v38i16.29759。网址：<https://ojs.aaai.org/index.php/AAAI/article/view/29759>。

[64] Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, Boxi Cao, 和 Le Sun。ToolALPACA：通过3000个模拟案例为语言模型提供通用工具学习，2023年。网址：<https://arxiv.org/abs/2306.05301>。

[65] Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao Ge, Xiu Li, 和 Ying Shan。GPT4Tools：通过自指令教会大型语言模型使用工具。在A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, 和 S. Levine编辑的《神经信息处理系统进展》，第36卷，第71995-72007页。Curran Associates, Inc.，2023年。网址：<https://proceedings.neurips.cc/paper_files/paper/2023/file/e393677793767624f2821cec8bdd02f1-Paper-Conference.pdf>。
