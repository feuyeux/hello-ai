# Dive into deep learning

> <https://zh.d2l.ai>
> <https://github.com/d2l-ai/berkeley-stat-157/tree/master/slides-zh>
> <https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497>
> <https://courses.d2l.ai/zh-v2/>

```sh
conda deactivate
conda create --name d2l python=3.9 -y
conda activate d2l
```

```sh
pip install torch==1.12.0
pip install torchvision==0.13.0
pip install d2l==0.17.6
```

```sh
mkdir d2l-zh && cd d2l-zh
curl https://zh-v2.d2l.ai/d2l-zh-2.0.0.zip -o d2l-zh.zip
unzip d2l-zh.zip && rm d2l-zh.zip
cd tensorflow
```

- [64 注意力机制](https://www.bilibili.com/video/BV1264y1i7R1/)
- [65 注意力分数](https://www.bilibili.com/video/BV1Tb4y167rb/)
- [66 使用注意力机制的seq2seq](https://www.bilibili.com/video/BV1v44y1C7Tg/)
- [67 自注意力](https://www.bilibili.com/video/BV19o4y1m7mo/)
- [68 Transformer](https://www.bilibili.com/video/BV1Kq4y1H7FL/)
- [69 BERT预训练](https://www.bilibili.com/video/BV1yU4y1E7Ns/)
- [70 BERT微调](https://www.bilibili.com/video/BV15L4y1v7ts/)
