{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 点积\n",
    "\n",
    "向量 ${\\displaystyle {\\vec {a}}=[a_{1},a_{2},\\cdots ,a_{n}]}$ 和 ${\\displaystyle {\\vec {b}}=[b_{1},b_{2},\\cdots ,b_{n}]}$ 的点积定义为：\n",
    "\n",
    "${\\displaystyle {\\vec {a}}\\cdot {\\vec {b}}=\\sum _{i=1}^{n}a_{i}b_{i}=a_{1}b_{1}+a_{2}b_{2}+\\cdots +a_{n}b_{n}}$\n",
    "\n",
    "- $\\Sigma$ 是求和符号\n",
    "- $n$ 是向量空间的维数\n",
    "\n",
    "例如，两个三维向量${\\displaystyle \\left[1,3,-5\\right]}$和${\\displaystyle \\left[4,-2,-1\\right]}$的点积是\n",
    "\n",
    "$$\n",
    "{\\displaystyle {\\begin{aligned}\\ [1,3,-5]\\cdot [4,-2,-1]&=(1)(4)+(3)(-2)+(-5)(-1)\\\\&=4-6+5\\\\&=3\\end{aligned}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([1, 3, -5])\n",
    "B = torch.tensor([4, -2, -1])\n",
    "\n",
    "print(torch.dot(A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加减法\n",
    "\n",
    "当这两个向量数值、方向都不同，基本向量$\\vec{e}_1=(1,0,0),\\vec{e}_2=(0,1,0),\\vec{e}_3=(0,0,1)$时，向量和计算为 ${\\displaystyle {\\vec {a}}+{\\vec {b}}=(a_{1}+b_{1}){\\vec {e}}_{1}+(a_{2}+b_{2}){\\vec {e}}_{2}+(a_{3}+b_{3}){\\vec {e}}_{3}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  1, -6])\n",
      "tensor([-3,  5, -4])\n"
     ]
    }
   ],
   "source": [
    "print(A+B)\n",
    "print(A-B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 范数\n",
    "\n",
    "已知向量的坐标，就可以知道它的模长。设向量${\\displaystyle {\\vec {v}}=(v_{1},v_{2},\\cdots ,v_{n})}$，其范数的计算表达式由弗罗贝尼乌斯范数（一种同时适用于向量和矩阵的范数计算方法）给出：${\\displaystyle \\left\\|{\\vec {v}}\\right\\|={\\sqrt {v_{1}^{2}+v_{2}^{2}+\\cdots +v_{n}^{2}}}}$。\n",
    "\n",
    "简单说，范数是点到坐标零点的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.]) tensor([[-4., -3., -2.],\n",
      "        [-1.,  0.,  1.],\n",
      "        [ 2.,  3.,  4.]])\n",
      "tensor(7.7460) tensor(7.7460)\n",
      "tensor(4.) tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(9, dtype=torch.float) - 4\n",
    "b = a.reshape((3, 3))\n",
    "print(a,b)\n",
    "# 16+9+4+1+0+1+4+9+16 = 60 根号60=7.746\n",
    "print(torch.norm(a),torch.norm(b))\n",
    "# 计算 a 和 b 的正无穷范数（所有元素中绝对值最大的）\n",
    "# 正无穷范数：所有元素中绝对值最大的\n",
    "print(torch.norm(a, float('inf')),torch.norm(b, float('inf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [-1.,  1.,  4.]])\n",
      "tensor([1.4142, 2.2361, 5.0000]) tensor([3.7417, 4.2426]) tensor([6., 6.])\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([[1, 2, 3], [-1, 1, 4]], dtype=torch.float)\n",
    "print(c)\n",
    "# 沿着第 0 维（列）、第 1 维（行）的范数。默认情况下，torch.norm 计算的是二范数（欧几里得范数），即每列元素平方和的平方根\n",
    "# sqrt(1^2+(-1)^2) = sqrt(2) = 1.41\n",
    "# sqrt(1^2+2^2+3^2) = sqrt(14) = 3.74\n",
    "print(torch.norm(c, dim=0), torch.norm(c, dim=1))\n",
    "# 沿着第 1 维（行）的 L1 范数，即每行元素绝对值的和 L1 范数：|1.0| + |2.0| + |3.0| = 1 + 2 + 3 = 6\n",
    "print(torch.norm(c, p=1, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1.],\n",
      "         [2., 3.]],\n",
      "\n",
      "        [[4., 5.],\n",
      "         [6., 7.]]])\n",
      "tensor([ 3.7417, 11.2250])\n",
      "tensor(3.7417)\n",
      "tensor(11.2250)\n"
     ]
    }
   ],
   "source": [
    "d = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)\n",
    "print(d)\n",
    "\n",
    "# 沿着第 1 和第 2 维的范数。默认情况下，torch.norm 计算的是二范数（欧几里得范数），即每个切片的元素平方和的平方根。\n",
    "# 第一个切片 d[0, :, :]：元素：[0., 1., 2., 3.]\n",
    "# 二范数：sqrt(0^2 + 1^2 + 2^2 + 3^2) = sqrt(0 + 1 + 4 + 9) = sqrt(14) ≈ 3.742\n",
    "# 第二个切片 d[1, :, :]：元素：[4., 5., 6., 7.]\n",
    "# 二范数：sqrt(4^2 + 5^2 + 6^2 + 7^2) = sqrt(16 + 25 + 36 + 49) = sqrt(126) ≈ 11.225\n",
    "print(torch.norm(d, dim=(1, 2)))\n",
    "\n",
    "# 第一个切片 d[0, :, :] 的范数。这个切片是一个 2x2 的张量，默认情况下计算的是二范数。\n",
    "# 元素：[0., 1., 2., 3.]\n",
    "# 二范数：sqrt(0^2 + 1^2 + 2^2 + 3^2) = sqrt(0 + 1 + 4 + 9) = sqrt(14) ≈ 3.742\n",
    "print(torch.norm(d[0, :, :]))\n",
    "\n",
    "# 第二个切片 d[1, :, :] 的范数。这个切片也是一个 2x2 的张量，默认情况下计算的是二范数。\n",
    "# 元素：[4., 5., 6., 7.]\n",
    "# 二范数：sqrt(4^2 + 5^2 + 6^2 + 7^2) = sqrt(16 + 25 + 36 + 49) = sqrt(126) ≈ 11.225\n",
    "print(torch.norm(d[1, :, :]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_trt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
