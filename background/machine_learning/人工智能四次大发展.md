<!-- markdownlint-disable MD033 MD036 MD041 MD045 -->

# AI四次大发展

<img src="/Users/hanl5/coding/feuyeux/hello-ai/background/hisbar.jpeg" style="width:800px" />

| 阶段         | 时间          | 代表性技术成果                                     | 数据规模                  | 技术栈                                            |
| ------------ | ------------- | -------------------------------------------------- | ------------------------- | ------------------------------------------------- |
| 弱人工智能   | 1950年-1990年 | 基于人工设计的规则系统                             | 数百规则集                | 基于专家知识和规则的系统                          |
| 统计机器学习 | 1990年-2012年 | HMM, CTF, SVM 反向传播, 卷积网络                   | 百万级标注数据            | 统计机器学习算法 + 算法包 (scikit-learn, XGBoost) |
| 深度学习     | 2013年-2018年 | ImageNet, ResNet, Word2vec, Attention, Transformer | 十亿级标注数据            | 深度神经网络 + 开发框架 (TensorFlow, PyTorch)     |
| 大语言模型   | 2018年-至今   | BERT, PaLM, LLaMA, GPT-4, GLM                      | 全网万亿数据 十亿用户反馈 | 预训练 + 微调 + 开源社区                          |

<img src="/Users/hanl5/coding/feuyeux/hello-ai/background/ai-his.png" style="width:800px" />

**1950-1980：Artificial Intelligence（人工智能）的萌芽期**

关键词：symbolic（符号主义）、基于规则、专家系统、图灵测试

<img src="/Users/hanl5/coding/feuyeux/hello-ai/background/symbolic.jpeg" style="width:400px" />

核心特点：以理论基础建立为核心，采用符号主义方法，受限于计算与数据，系统多针对特定简单问题，泛化能力不足。

- 理论基础建立：这一时期，AI的概念由艾伦·图灵等先驱提出，并围绕逻辑推理、问题求解等核心议题展开研究。
- 符号主义：主要基于规则的系统，通过编写大量规则来模拟人类智能行为，如专家系统。
- 局限与挑战：受限于计算能力和数据量的不足，AI系统往往只能解决特定领域内的

代表成果：约翰·麦卡锡提出“人工智能”概念以及DENDRAL专家系统在化学领域的成功应用，这两者共同奠定了AI发展的基础。

- 约翰·麦卡锡提出“人工智能”一词。
- 第一个专家系统DENDRAL在化学领域取得成功。

**1980-2010：Machine Learning（机器学习）的兴起**

关键词：基于统计、数据驱动、机器学习算法、特征工程

<img src="/Users/hanl5/coding/feuyeux/hello-ai/background/ml.png" style="width:500px" />

核心特点：以数据驱动和统计学习为核心，通过优化模型参数提升预测和分类准确性，并成功拓展至语音识别、图像识别等多个应用领域。

- 数据驱动：随着数据量的增加和计算能力的提升，机器学习开始兴起，强调从数据中自动学习并改进算法。
- 统计学习：基于统计学原理，通过训练数据来优化模型参数，提高预测或分类的准确性。
- 应用拓展：机器学习技术开始应用于语音识别、图像识别等领域，并取得显著进展。

代表技术：支持向量机（SVM）、决策树、随机森林等算法的出现，以及神经网络的复兴（尽管面临规模和训练上的挑战），共同推动了机器学习领域的显著进步。

- 支持向量机（SVM）、决策树、随机森林等算法的出现。
- 神经网络（尽管当时规模较小且训练困难）的复兴。

**2010-2020：Deep Learning（深度学习）的爆发**

关键词：connectionist（连接主义）、深度神经网络、PyTorch、Tensorflow

<img src="/Users/hanl5/coding/feuyeux/hello-ai/background/hybrid-ai.jpeg" style="width:800px" />

核心特点：在大数据、高性能计算和算法创新的推动下实现了神经网络的复兴，通过端到端学习直接从数据中提取特征，广泛应用于图像识别、自然语言处理和语音识别等领域，推动了AI技术的飞跃。

- 神经网络复兴：得益于大数据、高性能计算（如GPU）和算法创新（如反向传播算法的优化），深度神经网络（DNN）得以快速发展。
- 端到端学习：深度学习模型能够直接从原始数据中学习特征表示，无需人工设计特征工程。
- 广泛应用：在图像识别（如ImageNet竞赛）、自然语言处理（NLP）、语音识别等领域取得突破性进展，推动了AI技术的广泛应用。

代表成果：AlphaGo在围棋领域的卓越表现彰显了AI的深度学习能力，而Transformer模型的诞生则极大地推动了自然语言处理（NLP）技术的飞跃发展。

- AlphaGo在围棋比赛中击败人类世界冠军。
- Transformer模型的出现，极大地推动了NLP领域的发展。

**2020-？：Large Language Model（大语言模型）的崛起**

关键词：scaling law（缩放定律）、AIGC、超大规模参数、PLM、SFL

<img src="/Users/hanl5/coding/feuyeux/hello-ai/background/llm-radar.png" style="width:800px" />

核心特点：超大规模参数、零样本/少样本学习能力以及广泛的应用前景，这些特点共同赋予了它们对自然语言的深刻理解和生成能力，推动了AI技术的革新与发展。

- 超大规模：大语言模型（如GPT系列、BERT等）通过训练包含数十亿甚至数千亿参数的模型，实现了对自然语言的深刻理解和生成能力。
- 零样本/少样本学习：这些模型能够在没有或仅有少量标注数据的情况下，完成各种NLP任务，展现了强大的泛化能力。
- 应用前景广阔：大语言模型正在改变内容创作、智能客服、教育、医疗等多个行业的面貌，成为AI技术发展的新热点。

代表成果：GPT系列（GPT-3、ChatGPT、GPT-4）凭借超大规模与强生成力重塑NLP，LLaMA开源则加速了LLM技术的普及与应用创新。**

- GPT-3及其后续如ChatGPT、GPT-4，凭借超大规模参数和强大生成能力，重塑了NLP领域，推动对话系统、文本创作等前沿发展。
- LLaMA作为开源大模型，为研究者提供了灵活工具，加速LLM技术普及与应用探索。
