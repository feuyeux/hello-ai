<!-- markdownlint-disable MD033 MD036 MD041 MD045 -->

### Information theory

“信息”作为科学术语最早出现在哈特莱（R.V.L.Hartley）于1928年撰写的《信息传输》一文。

信息是用来消除随机不定性的东西
——香农(Claude Elwood Shannon) 信息论之父

#### 热力熵(Entropy)

鲁道夫·克劳修斯(Rudolf Clausius)提出熵的概念，来描述一个系统中趋于恒温的程度。

路德维希·玻尔兹曼(Ludwig Boltzmann) 把熵和封闭系统的无序状态联系起来
$$
\Epsilon = k\ log(\Omega);k玻尔兹曼常数
$$
熵永远朝不断增加的方向发展，系统越无序，越趋于恒温。

#### 信息熵

香农第一定律(信源编码定律)：对于信源发出的所有信息设计一种编码，其平均长度一定大于信源的信息熵。存在一种编码方式，使编码的平均长度无限接近于它的信息熵。霍夫曼编码(Huffman)。

香农第二定律：信息的传播速率不可能超过信道的容量。

最大熵原理：在对未知事件寻找概率模型时，这个模型应满足所有观察到数据，但对未知情况不要做任何假设。保留全部带不确定性，将风险降到最低。

相对熵/交叉熵：库尔贝克-莱伯勒距离(Kullback-Leibler Divergence)，反映两个信息源(/概率模型)之间的一致性。两者完全一致时，交叉熵等于零。

信息量

$$I=\log_2m$$

香农公式(shannon formula)

$$C = B \log_2(1+ \frac S N)$$

信息的杂乱程度的量化描述

$$\Eta(x) = -\sum\limits_{k=1}^np(x_i)\log_2 P(x), i=1,2,…,n$$

#### 玻尔兹曼机

- **Boltzmann**机是第一个受统计力学启发的多层学习机，它是一类典型的随机神经网络属于反馈神经网络类型  。其命名来源于**Boltzmann**在统计热力学中的早期工作和网络本身的动态分布行为 。
- 它在神经元状态变化中引入了统计概率，网络的平衡状态服从**Boltzmann**分布，网络运行机制基于模拟退火算法。
- **Boltzmann**机结合多层前馈神经网络和离散**Hopfield**网络在网络结构、学习算法和动态运行机制方面的优点，是建立在离散**Hopfield**网基础上的，具有学习能力，能够通过一个模拟退火过程寻求最优解。不过，其训练时间比**BP**网络要长。
- 离散**Hopfield**神经网络**+**模拟退火**+**隐单元**=Boltzman**机

受限玻尔兹曼机 伯努利分布(Bernoulli distribution)
