# Agentic Reasoning Design Patterns

**人工智能（AI）**已经发展出更复杂、更有能力的智能体，如虚拟助手(virtual assistants)、自主机器人(autonomous robots)和会话大语言模型(conversational LLM)代理。这些智能体可以思考、行动和协作以实现复杂的目标。**智能体推理设计模式(Agentic Reasoning Design Patterns)**解释了这些代理的工作原理，概述了**AI智能体**用于推理(reasoning)、决策(decision-making)和与环境交互( interacting with their environment)的基本策略(essential strategies)。

**人工智能体**是一种自主的软件实体(autonomous software entity)，能够感知周围环境(perceiving its environment)，做出决策(making decisions)，并采取行动(taking actions)以实现特定目标。大型语言模型使这些智能体能够理解自然语言并通过问题进行推理。它们还可以与各种工具和其他代理互动，有效地解决复杂挑战。例如，客户支持人工智能代理可能会使用大型语言模型来理解用户的查询，搜索知识库以找到适当的解决方案，并生成有用的回应，根据用户反馈调整其方法，以改善未来的互动。

本文将探讨四种关键设计模式： **Reflection(反思)**, **Tool Use(工具使用)**, **Planning(规划)**和**Multi-agent Collaboration(多智能体协作)**。

## 1. Reflection Pattern

Reflection是基于LLM的智能体通过自我评估和迭代改进其自身推理能力的能力。这种方法特别适用于提高客户支持或诊断场景中的决策准确性。

模型对提示生成初始响应，评估此输出的质量和正确性，然后根据自身的反馈精炼内容。模型实质上扮演着创作者和批评家的双重角色。这个过程涉及多个迭代，AI在这两个角色之间交替，直到输出达到一定的质量水平或预设的停止标准。

它评估自己的工作，检查错误、不一致之处，或输出的可提升领域，然后进行修订。这种**生成和自我评估**的周期允许AI迭代地精炼其响应，随着时间的推移，导致结果更加准确和有用。

这种模式对于大型语言模型（LLMs）尤其有价值，因为语言可能复杂且微妙。通过**反思自己的输出**，AI可以捕捉错误，澄清含糊不清的短语，并确保其响应更好地与预期意义或任务要求保持一致。就像我们的课程开发者为了提高学习成果而精炼课程一样，反思模式使AI系统能够持续提高生成内容的质量。

![Agentic AI Reflection Pattern](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/Agentic-AI-Reflection-Pattern.webp)

Reflection Pattern之所以有效，是因为它通过迭代的反馈允许**逐步改进**。通过反复反思输出，识别改进领域，并精炼文本，你可以获得比单次生成步骤更高的质量结果。

想象一下在**撰写研究摘要**时使用这种模式。

- **提示(Prompt)：**“概括这篇关于气候变化的研究论文的关键点。”
- **生成(Generate)：**AI提供了一个简短的摘要。
- **反思(Reflect)：**你注意到摘要中缺少了一些重要的论文内容，比如研究发现的含义。
- **反思后的文本(Reflected Text)：**你更新了摘要，包括了这些细节，并精炼了语言以增强清晰度。
- **迭代(Iterate)：**你重复这个过程，直到摘要准确捕捉到所有关键点。

Reflection Pattern主要由以下三部分组成：

1. **Generation** Step(生成步骤)：从用户提供一个初始提示开始，这可能是生成文本、编写代码或解决复杂问题的请求。例如，提示可能要求AI生成一篇关于历史人物的论文，或者用特定的编程语言实现一个算法。

- **零样本提示(Zero-Shot Prompting)**：第一次生成通常采用零样本风格，即AI在没有先前的示例或迭代的情况下生成响应。
- 初始输出(Initial Output)：产生的输出被视为第一稿。虽然它可能相关且连贯，但可能仍然包含错误或缺乏必要的细节。

  生成步骤的目标是产生一个候选输出，该输出可以在后续步骤中进一步评估和精炼。

2. **Reflection** Step(反思步骤)：这是AI模型审查自身生成内容的关键阶段。这一步骤包括：

- **自我批判(Self-Critique)**：模型批判自己的工作，识别改进领域，如事实错误、风格问题或逻辑不一致。
- **反馈生成(Feedback Generation)**：AI生成具体反馈，可能包括重组内容的建议、添加细节或纠正错误。
- **评估标准(Evaluation Criteria)**：批判可能基于预定义的标准，如语法准确性、连贯性、与提示的相关性或遵守特定的格式指南。

  反思过程可以模拟学科专家的风格，以提供更深入的反馈。例如，AI可能采取软件工程师的身份来审查一段代码，或者作为历史学家批评一篇论文。

3. Iteration and **Refinement**(迭代与精炼)：在这个阶段，反思步骤中生成的反馈被用来指导下一轮输出的生成。AI将建议的更改和改进纳入内容的新版本。这个周期重复多次，每次迭代都使输出更接近所需的质量。

- 适应性学习(Adaptive Learning)：通过这个迭代过程，AI学会识别自己错误中的模式，并精炼对任务要求的理解。
- 多次迭代(Multiple Iterations)：这个过程可以重复固定次数的步骤（例如，10次迭代），或者直到满足特定的停止条件，比如达到一定的内容质量水平或遇到“停止”关键词。

![How the Reflection Pattern Works](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/image-1-1-1.webp)

图中的组成部分

1. **Prompt (Input):** 给模型的初始输入，作为文本生成过程的起点。
2. **Generate:** AI模型根据提示创建响应的过程。
3. **Output Text:** 模型生成的响应。
4. **Reflect:** 生成的输出被分析、审查或修改以提升质量的一步。
5. **Reflected Text:** 在初次生成后经过修改或调整的输出。
6. **Iterate:** 过程重复进行，使用反思后的文本生成新的输出，进一步精炼结果。

流程解释

1. **Step 1 – Generate:** 用户首先向AI模型提供一个提示。例如，提示可能是：“写一个关于一只猫旅行到太空的短篇故事。”
2. **Step 2 – Output Text:** 模型根据提示生成一个响应，例如：“从前，有一只叫胡须的猫，在后院发现了一艘神奇的火箭船。胡须跳了进去，发射到太空中，在那里他遇到了来自喵塔星球的异星猫。”
3. **Step 3 – Reflect:** 在这个阶段，你审查生成的输出以评估质量。你可能会注意到故事缺乏关于胡须情感或旅途中面临的挑战的细节。
4. **Step 4 – Reflected Text:** 根据反思修订文本或提出改进建议。反思后的版本可能包括额外的细节：
   “胡须既兴奋又害怕地踏进火箭船。随着引擎轰鸣着启动，他紧紧抓住座位，不知道自己是否还能再见到家。穿越太空的旅程充满了奇异的景象和危险，如流星雨和宇宙风暴，这些都考验着胡须的勇气。”
5. **Step 5 – Iterate:** 现在这个精炼的文本可以反馈到生成过程中，可能作为新的提示或进一步文本生成的改进基础。根据反思后的文本，模型可以生成故事的更加精致版本。

Self-RAG或者CRAG都是这种模式的真实案例。

![Self-RAG vs. Traditional RAG](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/image-49-1.webp)

RAG：理一个提示，例如“美国各州是如何获得它们的名称的？”。

- 步骤1 涉及检索与提示相关的几篇文档（显示为标记为1、2、3的气泡）。检索到的段落被添加到输入提示中。
- 步骤2 显示语言模型根据提示加上检索到的段落生成响应。然而，它可能产生不一致的输出（例如，矛盾的段落或引入未支持的主张）。

该模型缺乏自我反思机制，导致最终生成中可能包含潜在的错误或不相关内容。

Self-RAG：使用Self-RAG处理相同的提示。系统按需检索，意味着只有在需要时才会进行检索，系统动态决定何时检索将有益。

- 步骤1 检索多个相关段落，但它允许模型有选择地与这些信息互动，而不是强制所有检索内容都进入响应。
- 步骤2：并行生成多个输出。每个版本在使用检索段落的方式上都有所不同，确保不相关或矛盾的 信息可以被批判。例如，一些输出被标记为不相关或部分相关。
- 步骤3：Self-RAG批判生成的输出并选择最佳的一个。这包括对每个输出的相关性、事实准确性和整体质量进行评级。在这种情况下，输出1被选为最相关的，从而得到一个更干净、更准确的最终响应。

总之，该图对比了传统RAG如何不经反思地融入检索段落，而Self-RAG则通过选择性检索、生成和批判来实现更高的事实性和连贯性。

体现这种模式的两项突出技术包括：

- **自我精炼：自我反馈的迭代改进 [Self-Refine: Iterative Refinement with Self-Feedback](https://arxiv.org/abs/2303.17651)**
  Madaan et al. (2023) 描述了智能体如何使用自己的反馈迭代地改进其响应，以提高推理和决策的质量。例如，智能体可以解决问题，评估其表现，并调整其方法，直到达到期望的结果。
- **反思：具有口语强化学习能力的语言智能体 [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366)**
  Shinn et al. (2023) LLM智能体使用强化学习来强化口语正向行为并纠正错误。使智能体能以类似人类导师提供反馈的方式，从正确和错误中学习。

## 2. Tool Use Pattern

LLM智能体不仅限于其内部推理能力；它们还可以利用外部工具来扩展其功能。工具使用对于扩展智能体独立实现的能力至关重要。通过访问专业知识，执行需要外部数据的任务，以及与各种工具互动，智能体显著增强了其问题解决能力。例如，LLM智能体可以使用工具从网络上检索最新信息，执行计算，翻译语言，或与专业数据库互动。

![tool use pattern](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/image-89.webp)

工具使用模式背后的核心思想

1. **任务模块化**：系统不是依赖一个试图处理所有事情的单一AI模型，而是将用户提示分解并将它们分配给**特定工具**（在此表示为工具A、工具B、工具C）。每个工具都专注于一种独特的能力，这使得整个系统更加高效和可扩展。
2. 用于多样化任务的专业工具：
   - **工具A**：例如，这可能是一个事实核查工具，用于查询数据库或互联网以验证信息。
   - **工具B**：这可能是一个数学求解器或代码执行环境，用于处理计算或运行模拟。
   - **工具C**：另一个专业工具，可能是用于语言翻译或图像识别。
3. 图表中的每个工具都被可视化为能够根据需要查询**信息源**（例如，数据库、网络API等），这表明了一个模块化架构，其中不同的子代理或专业组件处理不同的任务。
4. **顺序处理**：模型可能通过工具运行**顺序查询**，这意味着可以逐个处理多个提示，每个工具独立查询其各自的数据源。这允许快速、响应性的结果，特别是当与在特定领域表现出色的工具结合使用时。

大型语言模型（LLM）如何识别对工具的需求？
![](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/image-88.webp)
端到端过程：

- 输入：用户问“2乘以3等于多少？”
- 解释：LLM识别这是一个数学运算。
- 工具选择：LLM选择乘法工具。
- 创建有效载荷：它提取相关参数（a: 2 和 b: 3），准备一个有效载荷，并调用工具。
- 执行：工具执行操作（2 * 3 = 6)，并将结果返回给LLM以呈现给用户。

这在智能体AI中为什么重要？

上图捕捉了智能体AI的一个核心特征，即模型可以根据用户的查询自主决定使用哪个外部工具。LLM不仅仅是提供一个静态的响应，而是作为一个智能体动态选择工具，格式化数据，并返回处理后的结果，这是智能体AI系统中的工具使用模式的核心部分。这种工具集成允许LLM将其能力扩展到简单的语言处理之外，使它们成为更多功能的智能体，能够高效地执行结构化任务。

### 示例 CrewAI 内置工具 (Blog Research and Content Generation Agent (BRCGA))

博客研究和内容生成智能体(BRCGA)能够自动化研究AI行业最新趋势并撰写高质量博客文章的过程。这个代理利用专门工具从网络搜索、目录和文件中收集信息，最终生产出吸引人且信息丰富的内容。
BRCGA分为两个核心角色：

- **Researcher Agent**: 专注于收集洞察和市场分析。
- **Writer Agent**: 负责根据研究撰写文笔流畅的博客文章。

![CrewAI in-built Tools](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/10/CrewAI-in-built-Tools_-1.webp)Source: Author

示例代码

```python
import os
from crewai import Agent, Task, CrewCopy Code
```

```python
# Importing crewAI tools
from crewai_tools import (
    DirectoryReadTool,
    FileReadTool,
    SerperDevTool,
    WebsiteSearchTool
)
```

```python
os.environ["SERPER_API_KEY"] = "Your Key" # serper.dev API key
os.environ["OPENAI_API_KEY"] = "Your Key"
```

```python
# Instantiate tools
docs_tool = DirectoryReadTool(directory='/home/xy/VS_Code/Ques_Ans_Gen/blog-posts')
file_tool = FileReadTool()
search_tool = SerperDevTool()
web_rag_tool = WebsiteSearchTool()
```

```python
# Create agents
researcher = Agent(
    role='Market Research Analyst',
    goal='Provide 2024 market analysis of the AI industry',
    backstory='An expert analyst with a keen eye for market trends.',
    tools=[search_tool, web_rag_tool],
    verbose=True
)
```

```python
writer = Agent(
    role='Content Writer',
    goal='Craft engaging blog posts about the AI industry',
    backstory='A skilled writer with a passion for technology.',
    tools=[docs_tool, file_tool],
    verbose=True
)
```

```python
# Define tasks
research = Task(
    description='Research the latest trends in the AI industry and provide a 
                 summary.',
    expected_output='A summary of the top 3 trending developments in the AI industry    
                     with a unique perspective on their significance.',
    agent=researcher
)
```

```python
write = Task(
    description='Write an engaging blog post about the AI industry, based on the 
                 research analyst’s summary. Draw inspiration from the latest blog 
                 posts in the directory.',
    expected_output='A 4-paragraph blog post formatted in markdown with engaging, 
                     informative, and accessible content, avoiding complex jargon.',
    agent=writer,
    output_file='blog-posts/new_post.md' # The final blog post will be saved here
)
```

```python
# Assemble a crew with planning enabled
crew = Crew(
    agents=[researcher, writer],
    tasks=[research, write],
    verbose=True,
    planning=True, # Enable planning feature
)
```

```python
# Execute tasks
result = crew.kickoff()
```

**智能体AI的工具使用模式**允许大型语言模型（LLMs）通过与外部工具互动来超越其固有的局限性，使它们能够执行基于预训练知识的简单文本生成之外的 tasks。这种模式将AI从仅依赖静态数据转变为动态访问实时信息并执行专业操作，如运行模拟、检索实时数据或执行代码。

核心思想是通过对专业工具（例如，事实核查、解方程或语言翻译）分配任务来**模块化任务**，这导致了更高的**效率、灵活性和可扩展性**。智能体AI不是依赖单一的整体AI处理所有任务，而是利用多个工具，每个工具都针对特定的功能设计，从而实现更快的处理和更有效的多任务处理。

**工具使用模式**突出了智能体AI的关键特性，如决策制定、自主行动、从工具使用中学习和多工具协调。这些能力增强了AI的自主性和问题解决潜力，使其能够独立处理日益复杂的任务。系统甚至可以通过学习成功的工具使用并优化其性能来随时间适应其行为。随着AI的不断发展，其整合和创造新工具的能力将进一步深化其自主性和代理性。

工具使用的例子包括：

- **大猩猩：连接大量API的大型语言模型 [Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/abs/2305.15334)**
  Patil et al. (2023) 提出了一种连接到众多API的模型，使其能够执行检索数据或进行复杂操作等任务。这种设计使语言模型成为广泛服务接口。
- **MM-REACT：ChatGPT多模态推理和行动的提示工程 [MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action](https://arxiv.org/abs/2303.11381)**
  Yang et al. (2023) 创建了一个系统，其中LLM智能体基于不同输入类型（如图像、文本和其他数据）进行多模态推理。这种多功能性使智能体更能处理现实世界的应用。

## 3. Planning

有效的LLM智能体可以通过遵循一系列逻辑步骤(a sequence of logical steps)来创建(create)和执行(execute)计划。规划对于解决需要长期思考(long-term thinking)、策略规划(strategizing)和组织(organizing)的复杂任务至关重要。

**Planning Patterns** 为语言模型提供了将大型任务分解为可管理子目标的策略，使它们能够逐步解决复杂挑战，同时保持总体目标在焦点上。本文将详细讨论规划模式，包括ReAct和ReWOO技术。

![Agentic AI Planning Pattern](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/Artboard-1-copy-5-2.webp)Source: Author

**Agentic AI Planning Pattern** 是一个专注于将大问题分解为小任务，有效管理这些任务，并根据任务结果确保持续改进或适应的框架。这个过程是迭代的，依赖于结构化流程，以确保AI系统可以根据需要调整其计划，每次迭代都更接近期望的目标。

The **Planning Pattern** has the following main components:

1. Planning

   - In this initial stage, the AI agent interprets the prompt and devises an overall **plan**.
   - The plan outlines how the AI intends to tackle the problem, including high-level goals and strategies.

2. Generate Task

   - From the plan, the AI system **generates specific tasks** that must be executed.
   - Each task represents a smaller, manageable portion of the overarching goal, allowing the AI to work in focused steps.

3. Single Task Agent

   - The **Single Task Agent** is responsible for completing each task generated in the previous step.
   - This agent executes each task using predefined methods like **ReAct** (Reason + Act) or **ReWOo** (Reasoning WithOut Observation).
   - Once a task is completed, the agent returns a **Task Result**, which is sent back to the planning loop.

4. Replan

   - The **Replan** stage evaluates the Task Result to determine if any adjustments are needed.
   - If the task execution does not fully meet the desired outcome, the system will **replan** and possibly modify the tasks or strategies.
   - This feedback loop allows the AI system to learn and improve its approach iteratively, making it more adaptable to changing requirements or unexpected outcomes.

5. Iterate

   :

   - This part of the pattern is a loop connecting **Generate Task** and **Replan**.
   - It signifies the iterative nature of the process, where the AI system continuously re-evaluates and adjusts its approach until it achieves satisfactory results.

The Agentic AI Planning Pattern leverages a structured loop of **planning, task generation, execution, and replanning** to ensure that AI systems can autonomously work towards complex goals. This pattern supports adaptability by allowing the [AI](https://www.analyticsvidhya.com/blog/2024/07/data-strategies-and-ai-workflows-for-consumer-experiences/) to modify its approach in response to task outcomes, making it robust and responsive to dynamic environments or changing objectives.

## Example of an Agentic AI Planning Pattern

[![example of an Agentic AI Planning Pattern](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T174155.992.webp)](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T174155.992.webp)Source: Author

The above-given illustration depicts a sequential image understanding process, with steps that align with the **agentic AI planning pattern**. In [agentic AI](https://www.analyticsvidhya.com/blog/2024/05/agentic-ai-demystified-the-ultimate-guide-to-autonomous-agents/), an “agent” takes actions based on observations and planned responses to achieve a specific goal. Here’s how each step in the image fits into the agentic AI framework:



规划的两个重要方法包括：

- **思维链提示工程激发大型语言模型中的推理 [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)**
  Wei et al. (2022) 展示了提示大型语言模型逐步思考问题可以改善它们的问题解决能力。将任务分解为逻辑序列允许智能体遵循导致更准确结果的推理链。例如，在复杂的故障排除中，将过程分解为单独的诊断步骤可以确保不遗漏任何关键细节，最终导致更有效的解决方案。
- **HuggingGPT：在Hugging Face中使用ChatGPT生态解决AI任务 [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580)**
  Shen et al. (2023) 展示了LLM智能体如何与Hugging Face上的模型合作来分工合作解决任务。HuggingGPT跨多个AI模型协调行动，确保每个模型都为一个协调良好的计划做出贡献，以完成复杂任务。

## 4. Multi-Agent Collaboration

多个LLM智能体之间的协作通常会产生更高效和更复杂的结果，例如提高问题解决速度、准确性，以及通过汇集资源和专业知识来处理更复杂的任务。例如，在医疗诊断场景中，多个LLM智能体可以协同工作，分析患者数据，交叉参考医学文献，并提出可能的诊断，从而实现更快和更准确的医疗评估。这种模式依赖于智能体作为团队进行沟通和解决问题。这一领域的两个重要发展包括：

- **ChatDev – 软件开发中的通信智能体 [ChatDev – Communicative Agents for Software Development](https://arxiv.org/abs/2307.07924)** Qian et al. (2023) 展示了智能体如何在软件开发中协作，分配任务，并在流程中高效地工作。这些智能体相互沟通决策和进度，以确保工作流程顺畅。
- **AutoGen：通过多智能体对话启用下一代LLM应用 [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/abs/2308.08155)** Wu et al. (2023) 展示了一种创新的方法，利用LLM进行多智能体对话。在这种设置中，智能体通过对话共同得出解决方案，反映了AI智能体作为协调团队工作的潜力。.

## 5 参考

- [Agentic Reasoning Design Patterns in AI: Examples (vitalflux.com)](https://vitalflux.com/agentic-reasoning-design-patterns-in-ai-examples/)
- [Top 4 Agentic AI Design Patterns - Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/10/agentic-design-patterns/)
- [What is Agentic AI Reflection Pattern? (analyticsvidhya.com)](https://www.analyticsvidhya.com/blog/2024/10/agentic-ai-reflection-pattern/)
- [What is Agentic AI Tool Use Pattern? - Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/10/agentic-ai-tool-use-pattern/)
- [What is Agentic AI Planning Pattern? - Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/11/agentic-ai-planning-pattern/)

### 1. Goal Setting (Understanding the Task)

- **Prompt:** The task begins with a question: “Can you describe this picture and count how many objects are in the picture?”
- **Agentic AI Element:** The AI agent interprets this goal as a directive to analyze the image for both object recognition and description. The goal is to answer the question comprehensively by identifying, counting, and describing objects.

### 2. Planning and Subgoal Formation

- Process Breakdown:
  - To accomplish this goal, the agent breaks the task down into specific subtasks:
    - **Object Detection** (identify and localize objects)
    - **Classification** (identify what each object is)
    - **Caption Generation** (generate a natural language description of the scene)
- **Agentic AI Element:** An agent plans its actions by setting intermediate subgoals in the agentic AI planning pattern. Here, detecting objects is a subgoal required to complete the ultimate objective (generating a descriptive caption that includes a count of objects).

### 3. Perception and Action (Detecting and Describing)

- Tools and Models Used:
  - The agent utilises the facebook/detr-resnet-101 model for **detection**, which identifies and locates objects (e.g., giraffes and zebras) and assigns confidence scores.
  - After detection, the agent uses nlpconnect/vit-gpt2-image-captioning to generate a descriptive caption.
- **Agentic AI Element:** The agent “perceives” its environment (the image) using specific perception modules (pre-trained models) that allow it to gather necessary information. In agentic AI, perception is an active, goal-oriented process. Here, the models act as perception tools, processing visual information to achieve the overall objective.

### 4. Evaluation and Iteration (Combining Results)

- **Processing and Aggregating Information:** The results from detection (bounding boxes and object types) and captioning (descriptive text) are combined. The agent evaluates its outputs, confirming both object detection confidence levels and the coherence of the description.
- **Agentic AI Element:** Agentic AI involves continuously evaluating and adjusting responses based on feedback and information aggregation. The agent reviews its predictions (detection scores and bounding boxes) to ensure they align with the task’s demands.

### 5. Goal Achievement (Answer Presentation)

- **Output Presentation:** The agent finally provides an answer that includes a count of detected objects, a list of identified objects with confidence scores, and a descriptive caption.
- **Agentic AI Element:** The agent completes the goal by synthesising its perception and planning outcomes into a coherent response. In agentic AI, this step is about achieving the task’s overarching goal and generating an output that addresses the user’s initial question.

## Task Decomposition for Agentic AI Planning

![Task Decomposition for Agentic AI Planning](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T174241.828.webp)Source: [Understanding the planning of LLM agents: A survey](https://arxiv.org/pdf/2402.02716)

There are two different approaches to **task decomposition** for agentic AI planning, specifically designed for **handling complex tasks** in dynamic and variable real-world environments. Given the limitations of attempting a single-step plan for complex objectives, **decomposition** into manageable parts becomes essential. This process, akin to the “divide and conquer” strategy, involves breaking down a complex goal into smaller, more achievable sub-goals.

Here’s an explanation of each approach:

### (a) Decomposition-First Approach

1. **Decompose Step**: In this method, the LLM Agent begins by fully decomposing the main goal into **sub-goals** (Sub Goal-1, Sub Goal-2, …, Sub Goal-n) before initiating sub-tasks. This step is indicated by **1** in the diagram.
2. **Sub-Plan Step**: After decomposing the task, the agent creates **sub-plans** for each sub-goal independently. These sub-plans define the specific actions needed to achieve each sub-goal. This planning process is marked as **2** in the image.
3. **Sequential Execution**: Each sub-plan is executed one after the other in sequence, completing each sub-goal in order until the main goal is accomplished.

In essence, the decomposition-first method separates the stages of **decomposition** and **execution**: it completes all planning for the sub-goals before any execution begins. This approach can be effective in stable environments where changes are minimal during the planning process.

### (b) Interleaved Approach

The interleaved approach, **decomposition** and **execution** occur in a more intertwined manner:

1. **Simultaneous Planning and Execution**: Instead of fully decomposing the task before taking action, the LLM Agent begins with a partial decomposition (e.g., starting with Sub Goal-1) and immediately starts planning and executing actions related to this sub-goal.
2. **Adaptive Decomposition**: As each sub-goal is worked on, new sub-goals might be identified and planned for, adapting as the agent progresses. The agent continues decomposing, planning, and executing in cycles, allowing flexibility to respond to changes or unexpected environmental complexities.
3. **Dynamic Execution**: This method is more **adaptive** and **responsive** to changing environments, as planning and execution are interleaved. This allows the agent to adjust to real-time feedback, modifying sub-goals or actions as necessary.

In a nutshell,

- **Decomposition-First**: A structured, step-by-step approach where all sub-goals are planned before any execution. Suitable for **stable environments** where the task is well-defined and unlikely to change during execution.
- **Interleaved**: A flexible, adaptive method where planning and execution happen concurrently. This approach is ideal for **dynamic environments** where real-time feedback and adjustments are essential.

In complex AI planning, choosing between these approaches depends on the environment and the task’s variability. The decomposition-first approach emphasises structure and pre-planning, while the interleaved method prioritises adaptability and real-time responsiveness.

Both approaches have their own strengths, but they also bring unique challenges when faced with highly dynamic and unpredictable scenarios. To navigate such complexity, an emerging framework known as ReAct (Reasoning and Acting) has become increasingly popular in AI research. ReAct synthesizes reasoning and acting in a way that enables agents to think critically about their actions, adjusting their strategies based on immediate feedback. This framework, which blends structured planning with real-time adjustments, allows agents to make more sophisticated decisions and handle variability in diverse environments.

## What is ReAct?

As we already know, LLMs showcase impressive capabilities in providing language understanding and decision-making. However, their ability to reason and act has been studied as separate topics. This section will discuss how LLMs can use reasoning and action planning to handle complex tasks with greater synergy with the ReAct approach. Here’s the evolution and significance of the **ReAct (Reason + Act)** framework in language model (LM) systems. It contrasts traditional approaches (reasoning-only and action-only models) with ReAct, which combines reasoning and acting capabilities. Let’s break down each part of the ReAct architecture to understand what it conveys.

## Workflow of ReAct

![Workflow of ReAct](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T174322.564.webp)Source: [ReAct: Synergizing Reasoning and Acting in Language Models](https://react-lm.github.io/)

### 1. Reason Only

- This model focuses solely on **reasoning** and **thought processing** within the language model. An example of this approach is [**Chain-of-Thought** (CoT) prompting](https://www.analyticsvidhya.com/blog/2023/12/what-is-chain-of-thought-prompting-and-its-benefits/), where the language model goes through logical steps to solve a problem but does not interact directly with the environment.
- In this reasoning-only mode, the model generates a **sequence of thoughts** or “reasoning traces” but is unable to take action or receive feedback from an external environment. It’s limited to internal contemplation without engagement.
- **Limitation**: Since it only reasons, this model can’t adapt its behaviour based on real-time feedback or interact with external systems, making it less dynamic for tasks that require interaction.

### 2. Act Only

- This model is designed purely for **acting** in an environment. Examples include systems like **WebGPT** and **SayCan**, which can perform actions (e.g., making web searches and controlling robots) based on prompts.
- Here, the language model acts in an external **environment** (Env), takes actions, and observes the results of these actions. However, it doesn’t have a reasoning trace to guide its actions logically; it relies more on straightforward action-response without deeper planning.
- **Limitation**: Without reasoning, this approach lacks the capacity for complex, multi-step problem-solving. The actions may be reactive but need more strategic thought that could improve long-term effectiveness.

### 3. ReAct

- The **ReAct** framework combines **Reasoning** and **Acting** within a single loop. Here, the language model alternates between **Reasoning Traces** and **Actions** in the environment.

- Process

  :

  - The model first **reasons** about the task, creating a “thought” or hypothesis about what should be done next.
  - It then takes an **action** in the environment based on its reasoning.
  - After performing the action, the model **observes** the outcome in the environment, which it incorporates into its next reasoning step.

- This cycle of reasoning, acting, and observing continues iteratively, allowing the model to **learn and adapt** based on real-time feedback from the environment.

- **Significance**: By integrating reasoning and acting, ReAct allows the model to break down complex, multi-step tasks into manageable steps, adjust based on outcomes, and work towards solutions that require both planning and interaction. This combination makes ReAct well-suited for dynamic, multi-step tasks where the model must continuously adapt and refine its approach.

### Why ReAct Is Powerful?

- The ReAct framework answers the question posed at the bottom of the diagram: *What if we combine reasoning and acting?*

- By integrating these two capabilities, ReAct enables the model to

  think and act in a coordinated manner

  . This enhances its ability to:

  - Solve complex problems.
  - Adjust actions based on feedback.
  - Operate effectively in environments where sequential decision-making is required.

In essence, ReAct provides a more **holistic approach** to task completion by combining internal reasoning with external action-taking, making it more flexible and effective in real-world applications where purely reasoning or acting models fall short.

Also, here is the comparison of 4 prompting methods: (a) Standard, (b) Chain-of-thought (CoT, Reason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018) question. (2) Comparison of (a) Act-only and (b) ReAct prompting to solve an AlfWorld (Shridhar et al., 2020b) game.

![ReAct: Synergizing Reasoning and Acting in Language Models](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T174357.535.webp)Source: [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629)

The ReACT (Reason + Act) approach outperforms the others by leveraging reasoning and actions in tandem. This allows the AI to adapt to dynamic environments and complex questions. This framework leads to more sophisticated and accurate outcomes, making it highly suitable for tasks that require both thought and interaction.

Also read: [Implementation of ReAct Agent using LlamaIndex and Gemini](https://www.analyticsvidhya.com/blog/2024/10/implementation-of-react-agent-using-llamaindex-and-gemini/)

## Planning Pattern Using OpenAI API and httpx Library

This section aims to outline the process of building an AI agent that leverages the OpenAI API and the httpx library. It introduces the basic structure of creating a chatbot class capable of handling user inputs and executing responses through OpenAI’s language model. The section explains implementing the ReAct pattern to enable a loop of thought, action, pause, and observation. It describes registering custom actions (e.g., Wikipedia search, calculation, blog search) for enhanced functionality. This facilitates dynamic interaction where the agent can use external actions to refine and complete its answers. Let’s get straight to the Basic Structure of building AI Agent:

This code defines a ChatBot class for interacting with OpenAI’s GPT model. It initialises with an optional system prompt, stores conversation history, processes user input, and retrieves responses from the model using OpenAI’s API, simulating conversational capabilities for various applications or chatbot functionalities.

```python
import openai
import re
import httpx
class ChatBot:
    def __init__(self, system=""):
        self.system = system
        self.messages = []
        if self.system:
            self.messages.append({"role": "system", "content": system})
    def __call__(self, message):
        self.messages.append({"role": "user", "content": message})
        result = self.execute()
        self.messages.append({"role": "assistant", "content": result})
        return result
    def execute(self):
        completion = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=self.messages)
        return completion.choices[0].message.contentCopy Code
```

#### Here’s how you can implement the ReAct Pattern

The code outlines a structured process for answering questions using a loop of Thought, Action, PAUSE, and Observation. It defines how an AI agent should think through a question, take appropriate actions (calculations or information searches), pause for results, observe outcomes, and ultimately provide an answer.

```ini
prompt = """
You run in a loop of Thought, Action, PAUSE, Observation.
At the end of the loop you output an Answer.
Use Thought to describe your thoughts about the question you have been asked.
Use Action to run one of the actions available to you - then return PAUSE.
Observation will be the result of running those actions.
Your available actions are:
calculate:
e.g. calculate: 4 * 7 / 3
Runs a calculation and returns the number - uses Python so be sure to use floating point
syntax if necessary
wikipedia:
e.g. wikipedia: Django
Returns a summary from searching Wikipedia
simon_blog_search:
e.g. simon_blog_search: Django
Search Simon's blog for that term
Example session:
Question: What is the capital of France?
Thought: I should look up France on Wikipedia
Action: wikipedia: France
PAUSE
You will be called again with this:
Observation: France is a country. The capital is Paris.
You then output:
Answer: The capital of France is Paris
""".strip()
```

*After implementation of the ReAct Pattern, we will implement the actions*:

- *Action: Wikipedia Search,*
- *Action: Blog Search,*
- *Action: Calculation.*

#### Adding Actions to the AI Agent

Next, we need to register these actions in a dictionary so the AI agent can use them:

```makefile
known_actions = {
    "wikipedia": wikipedia,
    "calculate": calculate,
    "simon_blog_search": simon_blog_search
}
```

#### Here’s how you can complete the integration

This code defines a function or query that simulates a chatbot interaction with a user-specified question. It iteratively processes responses up to a maximum number of turns, extracting and executing specific actions using known handlers and updating prompts based on observations until a final result is returned or printed.

```python
def query(question, max_turns=5):
    i = 0
    bot = ChatBot(prompt)
    next_prompt = question
    while i < max_turns:
        i += 1
        result = bot(next_prompt)
        print(result)
        actions = [action_re.match(a) for a in result.split('\n') if action_re.match(a)]
        if actions:
            action, action_input = actions[0].groups()
            if action not in known_actions:
                raise Exception(f"Unknown action: {action}: {action_input}")
            print(" -- running {} {}".format(action, action_input))
            observation = known_actions[action](action_input)
            print("Observation:", observation)
            next_prompt = f"Observation: {observation}"
        else:
            return result
print(query("What does England share borders with?"))
```

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T174441.069.webp)

For full code implementation, refer to this article: [Comprehensive Guide to Build AI Agents from Scratch](https://www.analyticsvidhya.com/blog/2024/07/build-ai-agents-from-scratch/).

Let’s see the implementation of the Planning Pattern using ReAct with [LangChain](https://www.langchain.com/):

## Planning Pattern using ReAct with LangChain

The objective is to implement a tool-augmented AI agent using LangChain and [OpenAI’s GPT models](https://platform.openai.com/docs/models) that can autonomously conduct research and answer complex questions by integrating custom tools like web search through the [Tavily API](https://tavily.com/). This agent is designed to simulate human-like problem-solving by executing a planning pattern called ReAct (Reasoning and Action). It builds a loop of reasoning and action steps, evaluates responses, and makes decisions to gather and analyze information effectively. The setup supports real-time data queries and structured decision-making, enabling enhanced responses to questions like “What are the names of Ballon d’Or winners since its inception?”

### Install OpenAI and LangChain Dependencies

```diff
!pip install langchain==0.2.0
!pip install langchain-openai==0.1.7
!pip install langchain-community==0.2.0Copy Code
```

### Enter Open AI API Key

```java
from getpass import getpass
OPENAI_KEY = getpass('Enter Open AI API Key: ')
```

Struggling with finding the OpenAI API key? Check out this article – [How to Generate Your Own OpenAI API Key and Add Credits?](https://www.analyticsvidhya.com/blog/2024/10/openai-api-key-and-add-credits/)

### Enter Tavily Search API Key

*Get a free API key from [here](https://tavily.com/#api)*

```ini
TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')
```

### Setup Environment Variables

```lua
import os
os.environ['OPENAI_API_KEY'] = OPENAI_KEY
os.environ['TAVILY_API_KEY'] = TAVILY_API_KEYCopy Code
```

### Create Tools

Here, we create custom tools which are wrappers on top of the Tavily API.

#### Simple Web Search tool

```python
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.tools import tool
import requests
import json
tv_search = TavilySearchResults(max_results=3, search_depth='advanced',
                               max_tokens=10000)

@tool
def search_web(query: str) -> list:
   """Search the web for a query."""
   tavily_tool = TavilySearchResults(max_results=2)
   results = tavily_tool.invoke(query)
   return resultsCopy Code
```

### Test Tool Calling with LLM

```makefile
from langchain_openai import ChatOpenAI
chatgpt = ChatOpenAI(model="gpt-4o", temperature=0)
tools = [search_web]
chatgpt_with_tools = chatgpt.bind_tools(tools)
prompt = "What are the names of Ballon d'Or winners since its inception?"
response = chatgpt_with_tools.invoke(prompt)
response.tool_callsCopy Code
```

**Output**

```
[{'name': 'search_web',
  'args': {'query': "list of Ballon d'Or winners"},
  'id': 'call_FW0h6OpObqVQAIJnOtGLJAXe',
  'type': 'tool_call'}]
```

### Build and Test AI Agent

Now that we have defined the tools and the LLM, we can create the agent. We will use a tool-calling agent to bind the tools to the agent with a prompt. We will also add the capability to store historical conversations as memory.

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
SYS_PROMPT = """You run in a loop of Thought, Action, PAUSE, Observation.
               At the end of the loop, you output an Answer.
               Use Thought to describe your thoughts about the question you have been asked.
               Use Action to run one of the actions available to you - then return PAUSE.
               Observation will be the result of running those actions.
               wikipedia:
               e.g. wikipedia: Ballon d'Or
               Returns a summary from searching Wikipedia.
               Use the following format:
               Question: the input question you must answer
               Thought: you should always think about what to do
               Action: the action to take, should be one of [Wikipedia, duckduckgo_search, Calculator]
               Action Input: the input to the action
               Observation: the result of the action
               ... (this Thought/Action/Action Input/Observation can repeat N times)
               Thought: I now know the final answer
               Final Answer: the final answer to the original input question
             """
prompt_template = ChatPromptTemplate.from_messages(
   [
       ("system", SYS_PROMPT),
       MessagesPlaceholder(variable_name="history", optional=True),
       ("human", "{query}"),
       MessagesPlaceholder(variable_name="agent_scratchpad"),
   ]
)
prompt_template.messagesCopy Code
```

**Output**

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/image-1-2.webp)

Now, we can initiate the agent with the LLM, the prompt, and the tools. The agent is responsible for taking in input and deciding what actions to take. REMEMBER the Agent does not execute those actions – that the AgentExecutor does

Note that we are passing in the model chatgpt, not chatgpt_with_tools.

That is because create_tool_calling_agent will call .bind_tools for us under the hood. This should ideally be used with an LLM which supports tool \ function calling.

```java
from langchain.agents import create_tool_calling_agent
agent = create_tool_calling_agent(chatgpt, tools, prompt_template)
agentCopy Code
```

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/image-2-1-1.webp)

Finally, we combine the agent (the brains) with the tools inside the AgentExecutor (which will repeatedly call the agent and execute tools).

```python
from langchain.agents import AgentExecutor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True)
agent_executorCopy Code
```

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/image-3-1-1.webp)

```python
query = """Tell me the Ballon d'Or winners since it started?
       """
response = agent_executor.invoke({"query": query})

from IPython.display import display, Markdown

display(Markdown(response['output']))
```

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/image-4-1-1.webp)

Also read: [Comprehensive Guide to Build AI Agents from Scratch](https://www.analyticsvidhya.com/blog/2024/07/build-ai-agents-from-scratch/)

*If you want to dig deep into Generative AI then explore: [GenAI Pinnacle Program](https://www.analyticsvidhya.com/genaipinnacle?utm_source=blog_page&utm_medium=blog&utm_campaign=SEO)!*

## Workflow of ReWOO (Reasoning Without Observation)

**ReWOO (Reasoning without Observation)** is a new agent architecture proposed by Xu et al. that emphasises an efficient approach to multi-step planning and variable substitution in [large language model (LLM)](https://www.analyticsvidhya.com/blog/2023/03/an-introduction-to-large-language-models-llms/) systems. It addresses some of the limitations in ReAct-style agent architectures, particularly around execution efficiency and model fine-tuning. Here’s a breakdown of how [ReWOO](https://arxiv.org/abs/2305.18323) improves over traditional approaches:

### How ReWOO Works?

![Workflow of ReWOO (Reasoning Without Observation)](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/1-01-1-scaled.webp)Source: Author

Here’s the workflow of the [ReWOO (Reasoning Without Observation)](https://langchain-ai.github.io/langgraph/tutorials/rewoo/rewoo/) agent model. This model is designed to improve efficiency in multi-step reasoning and tool usage by minimizing redundant observations and focusing on planned sequences of actions. Here’s a step-by-step explanation of each component and the flow of information:

### Components of ReWOO

1. Planner

   :

   - The **Planner** is responsible for creating an entire **plan** at the beginning. It determines the **sequence of actions** or steps needed to solve the task.
   - For each action step, the Planner specifies:
     - **Tool**: The specific tool or function required for the step.
     - **Arguments (args)**: The input values or variables needed for the tool.
   - The plan is defined using **variable substitution**, where the output of one tool (e.g., #E1) can be used as an argument in another tool (e.g., #E2), creating dependencies across steps.
   - Importantly, this planning process occurs in a single **LLM call**, making it more efficient by reducing token consumption than iterative, observation-based reasoning.

2. Worker

   :

   - The **Worker** is responsible for executing the actions per the **plan the Planner generated**.
   - The Worker takes the arguments provided for each step, invokes the specified tool, and returns the result.
   - This execution can be looped until the task is solved, ensuring each tool action is completed in the correct order as outlined in the plan.
   - The Worker functions independently of the LLM, meaning it simply follows the Planner’s instructions without additional calls to the LLM at each step.

3. Solver

   :

   - The **Solver** is the final component that interprets the results of the tools used by the Worker.
   - Based on the **observations** gathered from tool executions, the Solver generates the **final answer** to the user’s query or task.
   - This part may involve a final **LLM call** to synthesize the information into a coherent response.

### Key Enhancements of ReWOO

Here are the key enhancements of ReWOO:

1. Efficient Tool Use and Reduced Token Consumption

   :

   - **Single-Pass Tool Generation**: Unlike ReAct-style agents, which require multiple LLM calls for each reasoning step (and therefore repeat the entire system prompt and previous steps for each call), ReWOO generates the full sequence of required tools in one pass.
   - This approach drastically **reduces token consumption** and **cuts down execution time**, making it more suitable for complex tasks that involve multiple steps or tools.

2. Streamlined Fine-Tuning Process

   :

   - **Decoupled Planning from Tool Outputs**: Since ReWOO’s planning data is not dependent on the actual outputs of tools, it allows for a more straightforward fine-tuning process.
   - **Fine-Tuning Without Tool Execution**: In theory, the model can be fine-tuned without invoking any tools, as it relies on planned actions and substitutions rather than actual tool responses.

### Workflow Process

The process flows through the following steps:

1. Step 1 – User Input

   :

   - The **user** submits a question or task to ReWOO.
   - The input is passed to the Planner to initiate the planning phase.

2. Step 2 – Planner Creates Plan

   :

   - The Planner formulates a multi-step plan, specifying which tools to use and the required arguments.
   - The plan may involve variable substitution, where outputs from one tool are used as inputs for another.
   - The Planner then provides this complete plan to the Worker.

3. Step 3 – Worker Executes Actions

   :

   - The Worker carries out each step of the plan by calling the specified tools with the appropriate arguments.
   - This looped process ensures each tool action is completed sequentially until the task is finished.

4. Step 4 – Solver Generates Answer

   :

   - Once all necessary actions are executed, the Solver interprets the results and generates the final answer for the user.
   - This answer is then returned to the user, completing the workflow.

In essence, ReWOO enhances the agent’s efficiency by separating the **reasoning (Planner)** and **execution (Worker)** phases, thereby creating a faster and more resource-efficient framework for complex tasks.

## Comparison of Reasoning with Observation and ReWOO

![Comparison of Reasoning with Observation and ReWOO](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T175015.109.webp)Source: [ReWOO](https://arxiv.org/pdf/2305.18323)

Two distinct methods for task reasoning in a system involving large language models (LLMs) are **(a) Reasoning with Observation** and **(b) ReWOO (Reasoning with Observations and Organized Evidence)**. Here’s a comparison based on the given diagram:

### 1. Observation-Dependent Reasoning (Left Panel)

- Setup and Process Flow

  :

  - The task from the user is first enhanced with **context** and **exemplars** (examples or prompts to aid the LLM’s reasoning) and is then inputted into the LLM to begin the reasoning process.
  - The LLM generates two key outputs:
    - **T (Thought)**: Represents the internal thought or understanding derived from the LLM’s initial processing.
    - **A (Action)**: This is the action the LLM decides to take based on its thought, typically involving querying tools for information.
  - After each action, the **observation (O)** from the tools is received. This observation acts as a feedback loop and is appended to the prompt history, forming an updated input for the next LLM call.

- Iterative Nature

  :

  - This setup is iterative, meaning the LLM repeatedly cycles through thoughts, actions, and observations until sufficient reasoning is achieved.
  - Each cycle relies on the **continuous stacking of observations in the prompt history**, creating prompt redundancy as more information is accumulated over time.

- Limitation

  :

  - This approach can lead to **prompt redundancy** and possible inefficiencies due to the repetitive input of context and exemplars with each cycle, as the same data (context and exemplars) is repeatedly fed back into the system.

### 2. ReWOO (Right Panel)

- Enhanced Structure

  :

  - Unlike the observation-dependent reasoning setup, ReWOO introduces a more structured approach by separating roles:
    - **Planner**: Responsible for creating a sequence of **interdependent plans (P)**.
    - **Worker**: Fetches **evidence (E)** from various tools according to the Planner’s instructions.
  - The Planner generates plans that are then passed to the Worker. The Worker executes these plans by gathering the necessary evidence through tool interactions.

- Role of Plans and Evidence

  :

  - **Plans (P)**: These are predefined, interdependent steps outlining the system’s reasoning path.
  - **Evidence (E)**: This is the specific information or data retrieved based on the Planner’s instructions.
  - The **combination of plans (P) and evidence (E)** forms a more organized input, which, alongside the original task and context, is finally processed by a **Solver** LLM to produce the user’s output.

- Solver

  :

  - The Solver serves as the final reasoning module, integrating the task, context, plans, and evidence to generate a coherent answer.
  - Since the context and exemplars are not repeatedly fed into the LLM, ReWOO reduces the issue of prompt redundancy.

### Key Differences and Advantages of ReWOO

- Prompt Efficiency

  :

  - **Observation-depe****ndent reasoning** suffers from prompt redundancy due to repeated cycles of the same context and exemplars, potentially overloading the prompt and increasing processing time.
  - **ReWOO**, on the other hand, avoids this redundancy by separating the planning and evidence-gathering stages, making the prompt more efficient.

- Structured Task Execution

  :

  - ReWOO’s design introduces a **Planner** and **Worker**, allowing for a clear distinction between task planning and evidence collection. This structured flow ensures that each step is executed logically, making it easier to manage complex tasks.

- Scalability

  :

  - With its modular setup, ReWOO can effectively handle more complex tasks. Its structured approach to planning and evidence retrieval allows it to scale better with complex reasoning tasks, as each component (Planner, Worker, Solver) has a defined role.

### Summary

- **Observation-Dependent Reasoning**: Cycles through thoughts, actions, and observations, creating prompt redundancy but maintaining simplicity.
- **ReWOO**: Uses a more organized structure by employing a Planner, Worker, and Solver to streamline reasoning, reduce prompt redundancy, and improve efficiency in handling complex tasks.

## Code Implementation of ReWoo

For the Hands-on ReWoo, I am referring to [the ReWOO recipe from Vadym Barda using LangGraph](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/rewoo/rewoo.ipynb). For now, I am not mentioning the libraries and other requirements, but I will dig into defining the graph state, planner, executor, and solver.

![Hands-on on ReWoo](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T175134.475.webp)Source: [Vadym Barda GitHub](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/rewoo/rewoo.ipynb)

In LangGraph, each node updates a **shared graph state**, which serves as input whenever a node is activated. Below, the state dictionary is defined to contain essential task details, such as task, plan, steps, and other necessary variables.

```python
from typing import List
from typing_extensions import TypedDict
class ReWOO(TypedDict):
    task: str
    plan_string: str
    steps: List
    results: dict
    result: strCopy Code
```

### Planner: Generating Task Plans

The **planner** module uses a language model to generate a structured plan in the form of a task list. Each task in the plan is represented by strings that can include **special variables** (like #E{0-9}+) for substituting values from previous results. In this example, the agent has access to two tools:

1. **Google**: It acts as a search engine, and it is represented here by Tavily.
2. **LLM**: A large language model tool to interpret and analyze data, providing reasoning from previous outputs efficiently.

The **prompt** instructs the model on how to create a plan, specifying which tools to use and how to reference prior results using variables.

```makefile
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o")
prompt = """For the following task, make plans that can solve the problem step by step. For each plan, indicate \
which external tool together with tool input to retrieve evidence. You can store the evidence into a \
variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)
# Task Example
task = "what is the exact hometown of the 2024 mens australian open winner"
result = model.invoke(prompt.format(task=task))
print(result.content)
```

**Output**

```
Plan: Use Google to search for the 2024 Australian Open winner.

#E1 = Google[2024 Australian Open winner]

Plan: Retrieve the name of the 2024 Australian Open winner from the search results.

#E2 = LLM[What is the name of the 2024 Australian Open winner, given #E1]

...
```

#### Planner Node

The planner node connects to the graph, creating a get_plan node that receives the ReWOO state and updates it with new steps and plan_string.

```python
import re
from langchain_core.prompts import ChatPromptTemplate
regex_pattern = r"Plan:\s*(.+)\s*(#E\d+)\s*=\s*(\w+)\s*\[([^\]]+)\]"
prompt_template = ChatPromptTemplate.from_messages([("user", prompt)])
planner = prompt_template | model
def get_plan(state: ReWOO):
    task = state["task"]
    result = planner.invoke({"task": task})
    matches = re.findall(regex_pattern, result.content)
    return {"steps": matches, "plan_string": result.content}
```

### Executor: Executing Planned Tasks

The **executor** iterates through each planned task, executing specified tools sequentially. It uses helper functions to determine the current task and performs variable substitution before each tool call.

```python
from langchain_community.tools.tavily_search import TavilySearchResults
search = TavilySearchResults()
def _get_current_task(state: ReWOO):
    if "results" not in state or state["results"] is None:
        return 1
    if len(state["results"]) == len(state["steps"]):
        return None
    else:
        return len(state["results"]) + 1
def tool_execution(state: ReWOO):
    _step = _get_current_task(state)
    _, step_name, tool, tool_input = state["steps"][_step - 1]
    _results = (state["results"] or {}) if "results" in state else {}
    for k, v in _results.items():
        tool_input = tool_input.replace(k, v)
    if tool == "Google":
        result = search.invoke(tool_input)
    elif tool == "LLM":
        result = model.invoke(tool_input)
    else:
        raise ValueError
    _results[step_name] = str(result)
    return {"results": _results}
```

### Solver: Synthesizing Final Output

The **solver** aggregates results from each executed tool and generates a conclusive answer based on the evidence collected.

```python
solve_prompt = """Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \
retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \
contain irrelevant information.
{plan}
Now solve the question or task according to provided Evidence above. Respond with the answer
directly with no extra words.
Task: {task}
Response:"""
def solve(state: ReWOO):
    plan = ""
    for _plan, step_name, tool, tool_input in state["steps"]:
        _results = (state["results"] or {}) if "results" in state else {}
        for k, v in _results.items():
            tool_input = tool_input.replace(k, v)
            step_name = step_name.replace(k, v)
        plan += f"Plan: {_plan}\n{step_name} = {tool}[{tool_input}]"
    prompt = solve_prompt.format(plan=plan, task=state["task"])
    result = model.invoke(prompt)
    return {"result": result.content}
```

### Defining the Graph Workflow

The **graph** is a directed workflow that coordinates interactions between the planner, tool executor, and solver nodes. Conditional edges ensure the process loops until all tasks are completed.

```python
def _route(state):
    _step = _get_current_task(state)
    if _step is None:
        return "solve"
    else:
        return "tool"
from langgraph.graph import END, StateGraph, START
graph = StateGraph(ReWOO)
graph.add_node("plan", get_plan)
graph.add_node("tool", tool_execution)
graph.add_node("solve", solve)
graph.add_edge("plan", "tool")
graph.add_edge("solve", END)
graph.add_conditional_edges("tool", _route)
graph.add_edge(START, "plan")
app = graph.compile()

# Stream output to visualize final results
for s in app.stream({"task": task}):
    print(s)
    print("---")

#Input: task = "what is the exact hometown of the 2024 mens australian open winner"
```

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-07T175236.284.webp)

```javascript
from IPython.display import Image, display
from langchain_core.runnables.graph import MermaidDrawMethod

display(
    Image(
        app.get_graph().draw_mermaid_png(
            draw_method=MermaidDrawMethod.API,
        )
    )
)
```

![Graph](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/image-6-1-1.webp)

```css
print(s["solve"]["result"])
```

**Output**

```
San Candido, Italy
```

## Benefits and Limitations of Agentic AI Planning Pattern

The agentic AI planning pattern offers significant advantages, especially when a task’s complexity prevents predetermined step-by-step decomposition. Planning enables agents to dynamically decide their course of action, allowing for adaptive and context-aware problem-solving. It enhances flexibility and capability in handling unpredictable tasks, making it a powerful tool in situations demanding strategic foresight and decision-making.

However, this capability comes with notable limitations. The dynamic nature of planning introduces unpredictability, making it harder to foresee how an agent might behave in any given scenario. Unlike more deterministic agentic workflows, such as Reflection or Tool Use—which are reliable and effective—planning remains less mature and can yield inconsistent results. While current planning capabilities present challenges, the rapid advancements in AI research suggest that these limitations will likely diminish over time, leading to more robust and predictable planning functionalities.

Know more about it [here.](https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/)

*Also, to understand the Agent AI better, explore: [The Agentic AI Pioneer Program](https://www.analyticsvidhya.com/agenticaipioneer/?utm_source=blog_page&utm_medium=blog&utm_campaign=seo)*

## Conclusion

We explored the Agentic AI Planning Pattern, which is fundamental for structuring and executing complex, multi-step tasks in AI systems. This pattern enables AI to decompose large goals into smaller, manageable sub-goals, ensuring that the overall objective is approached methodically while remaining adaptable to real-time feedback and changes. We discussed two primary decomposition approaches: Decomposition-First, which emphasizes pre-planning for stable environments, and Interleaved, which allows for flexible execution and adaptive planning in dynamic settings. Additionally, we touched on the ReAct framework, showcasing how combining reasoning and acting can create a more interactive and iterative AI problem-solving approach. Lastly, we introduced ReWOO, an advanced architecture that enhances efficiency by minimizing redundant observations and focusing on planned sequences, thus optimizing task completion in complex environments.

These frameworks collectively highlight the power of integrating structured planning, iterative execution, and adaptive strategies for robust agentic AI systems capable of handling complex real-world challenges.

In our next article, we will be talking about the **Multi-Agent Pattern**!

If you’re interested in learning more about Agentic AI Planning Patterns, I recommend:

1. [MichaelisTrofficus](https://github.com/neural-maze/agentic_patterns/blob/main/notebooks/planning_pattern.ipynb): For building the Planning Pattern from Scratch
2. [ReAct](https://arxiv.org/pdf/2210.03629): Synergizing Reasoning and Acting in Language Models
3. [ReWOO](https://arxiv.org/pdf/2305.18323): Decoupling Reasoning from Observations for Efficient Augmented Language Models
4. Reasoning without Observation by [vbarda](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/rewoo/rewoo.ipynb)
5. [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/cookbooks/oreilly_course_cookbooks/Module-6/Agents/#with-react-agent) with With ReAct Agent
6. “[HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](<https://arxiv.org/abs/2303.17580?utm_campaign=The> Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY),” Shen et al. (2023)
7. “[Understanding the planning of LLM agents: A survey](<https://arxiv.org/pdf/2402.02716.pdf?utm_campaign=The> Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY),” by Huang et al. (2024)

# 4 What is Agentic AI Multi-Agent Pattern?

[What is Agentic AI Multi-Agent Pattern? - Analytics Vidhya](https://www.analyticsvidhya.com/blog/2024/11/agentic-ai-multi-agent-pattern/)

Now, talking about the Agentic AI Multi-Agent design pattern – In this pattern, you can divide a complex task into subtasks, and different agents can perform these tasks. For instance, if you are building software, then the tasks of coding, planning, product management, designing and QA will be done by the different agents proficient in their respective tasks. Sounds intriguing, right? Let’s build this together!!!

## The Architecture of Agentic AI Multi-Agent Pattern

![The Architecture of Agentic AI Multi-Agent Pattern](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/Artboard-1-copy-3-1.webp)Source: Author

This architecture showcases an Agentic AI multi-agent system in which various agents with specialized roles interact with each other and with an overarching multi-agent application to process a user prompt and generate a response. Each agent in the system has a unique function, simulating a collaborative team working together to achieve a task efficiently.

### **Components Explained:**

1. User Interaction:

   - **Prompt:** The user initiates the interaction by inputting a prompt into the multi-agent application.
   - **Response:** The system processes the prompt through collaborative agent interactions and returns a response to the user.

2. Agents and Their Roles:

   - **Agent 1: Software Engineer:** Focuses on technical problem-solving related to software development, providing coding solutions, or suggesting software-based strategies.
   - **Agent 2: Project Manager:** Oversees the project management aspect, coordinating efforts among agents and ensuring the process aligns with overall project goals.
   - **Agent 3: Content Developer:** Generates content, writes drafts, or assists in developing documentation and creative materials needed for the project.
   - **Agent 4: Market Research Analyst:** Gathers data, conducts analysis on market trends, and provides insights that inform other agents’ strategies.

3. Interaction Flow:

   - The arrows between agents signify communication channels and collaboration paths. This implies that:
     - **Bidirectional Arrows** (double-headed): Agents can exchange information back and forth, enabling iterative collaboration.
     - **Dashed Lines**: Indicate secondary or indirect communication paths between agents, suggesting a support role in the communication flow rather than primary coordination.

4. Communication Workflow:

   - **Initiation**: The user provides a prompt to the multi-agent system.

   - Coordination

     :

     - **Agent 1 (Software Engineer)** may start by determining any initial technical requirements or strategies.
     - **Agent 2 (Project Manager)** coordinates with **Agent 1** and other agents, ensuring everyone is aligned.
     - **Agent 3 (Content Developer)** creates relevant content or drafts that may be needed as part of the output.
     - **Agent 4 (Market Research Analyst)** supplies research data that could be essential for informed decision-making by the other agents.

   - **Completion**: Once all agents have collaborated, the system compiles the final response and presents it to the user.

![Software development](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/New-Agentic-AI-Multi-Agent-Pattern-.webp)Source: Author

### **Key Characteristics:**

- **Collaborative Intelligence**: This architecture promotes collaborative problem-solving, where agents with specialized expertise contribute distinct insights and skills.
- **Autonomy**: Each agent operates semi-independently, focusing on their specific roles while maintaining communication with other agents.
- **Scalability**: The model can be expanded by adding more specialized agents to address more complex user prompts.

This architecture is particularly effective in multifaceted tasks that require diverse expertise, such as research projects, product development, and comprehensive content creation. The emphasis on distinct roles and coordinated communication ensures that each part of a complex task is handled efficiently and cohesively. I hope you have understood how Multi-Agent works. Now, we will talk about a framework to build Multi-Agent solutions.

## AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation

![AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T180522.746.webp)Source: AutoGen: [Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155)

Do you know many frameworks such as [CrewAI](https://www.crewai.com/), [LangGraph](https://www.langchain.com/langgraph), and [AutoGen](https://microsoft.github.io/autogen/0.2/) that provide ways for developers to build multi-agent solutions? Today, we are talking about the AutoGen:

AutoGen introduces a new paradigm in [LLM applications](https://www.analyticsvidhya.com/blog/2024/05/how-to-build-reliable-llm-applications-with-phidata/) by enabling customisable and conversable agents designed to function within multi-agent conversation frameworks. This design is rooted in the understanding that modern LLMs can adapt and integrate feedback seamlessly, particularly those optimised for dialogue (e.g., GPT-4). AutoGen leverages this capability by allowing agents to interact conversationally—exchanging observations, critiques, and validations, either autonomously or with human oversight.

The versatility of AutoGen agents stems from their ability to incorporate various roles and behaviours tailored to the developer’s needs. For instance, these agents can be programmed to write or execute code, integrate human feedback, or validate outcomes. This flexibility is supported by a modular structure that developers can easily configure. Each agent’s backend is extendable, allowing further customisation and enhancing its functionality beyond default settings. The agents’ conversable nature enables them to hold sustained multi-turn dialogues and adapt to dynamic interaction patterns, making them suitable for diverse applications from question-answering and decision-making to complex problem-solving tasks.

### Conversation Programming

A pivotal innovation within AutoGen is the concept of conversation programming, which revolutionises LLM application development by streamlining the process into multi-agent conversations. This programming paradigm shifts the focus from traditional code-centric workflows to conversation-centric computations, allowing developers to manage complex interactions more intuitively. Conversation programming unfolds in two core steps:

1. **Defining Conversable Agents**: Developers create agents with specific capabilities and roles by configuring built-in features. These agents can be set to operate autonomously, collaborate with other agents, or involve human participation at different points, ensuring a balance between automation and user control.
2. **Programming Interaction Behaviors**: Developers program how these agents interact through conversation-centric logic. This involves using a blend of natural language and code, enabling flexible scripting of conversation patterns. AutoGen facilitates seamless implementation of these interactions with ready-to-use components that can be extended or modified for experimental or tailored applications.

The integration of conversation programming supports the modular combination of different [LLM](https://www.analyticsvidhya.com/articles/llm-vs-agents/) capabilities, enabling the division of complex tasks into manageable subtasks that agents can collaboratively solve. This framework underpins the development of robust and scalable LLM applications across multiple fields, including research, coding, and interactive entertainment.

## How to Use AutoGen to Program a Multi-agent Conversation?

![ How to Use AutoGen to Program a Multi-agent Conversation?](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T180701.258.webp)Source: [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155)

There are three main sections: **AutoGen Agents**, **Developer Code**, and **Program Execution**, illustrating how to use AutoGen to program a multi-agent conversation. Here is a detailed breakdown:

### 1. AutoGen Agents

- ConversableAgent

  : This is the overarching framework within which different types of agents operate. The diagram highlights several agent types:

  - **AssistantAgent**: Configurable with options such as human_input_mode set to “NEVER” and code_execution_config set to False. This means the agent is fully autonomous and does not rely on human input during its operation.
  - **UserProxyAgent**: Set with human_input_mode as “ALWAYS,” indicating that it is user-controlled and will always require human input to respond.
  - **GroupChatManager**: Manages interactions between multiple agents in a group conversation.

- **Unified Conversation Interfaces**: All agents share interfaces for sending, receiving, and generating replies.

### 2. Developer Code

This section demonstrates the steps to set up and customize the interaction between agents.

- Define Agents

  :

  - Two agents, **User Proxy A** and **Assistant B**, are defined. They can communicate with each other, forming the basis of a multi-agent conversation.

- Register a Custom Reply Function

  :

  - A custom reply function (reply_func_A2B) is registered for one agent (Agent B). This function outlines how Agent B generates replies when invoked.

The function includes a simple logic structure:

```lua
def reply_func_A2B(msg):
    output = input_from_human()
    if not output:
        if msg includes code:
            output = execute(msg)
    return outputCopy Code
```

- This function allows Agent B to either get input from a human or execute code if the input message includes executable commands.
- **Initiate Conversations**: A sample initiation line is shown:
  `initiate_chat("Plot a chart of META and TESLA stock price change YTD.”)`

This line sets Agent A to initiate a conversation with Agent B, asking it to plot a chart based on the given command.

### 3. Program Execution

This section details how the conversation proceeds after initialisation.

- Conversation-Driven Control Flow

  :

  - The interaction starts with Agent A sending a request to Agent B.
  - Agent B then receives the request and invokes the generate_reply function, which may trigger code execution if required.

- Conversation-Centric Computation

  :

  - The flow shows how messages are passed between generate_reply and the agents:
    - For example, after attempting to execute the command, an error message is sent back if a required package is missing (e.g., Error: package yfinance is not installed).
    - The reply then informs the user to install the missing package (“Sorry! Please first pip install yfinance and then execute”).

In a nutshell, it visualises how to program a conversation-driven interaction between agents using AutoGen. The process involves defining agents, customising their behaviours through reply functions, and handling conversation control flow, including executing code and responding to user requests.

AutoGen Agents, Developer Code, and Program Execution, are designed to guide a developer through setting up an automated multi-agent interaction, from defining and customising agents to observing the control flow of conversation and execution.

## Hands-on Agentic AI Multi-Agent Pattern

![Hands-on Agentic AI Multi-Agent Pattern](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T180830.313-3.webp)Source: Basic Concepts of AutoGen Agents | DeepLearning.ai

Here we will talk about Agentic AI multi-agent conversation (This is inspired by [Deeplearning.ai](https://www.deeplearning.ai/)). I am using AutoGen, which has a built-in agent class called “Conversable agent.”

Let’s begin with the Setup.

```lua
!pip install openai
# python==3.10.13
!pip install pyautogen==0.2.25
import os
os.environ['OPENAI_API_KEY']='Your_API_Key'
llm_config = {"model": "gpt-4o"}
```

*The configuration specifies the model to be used ([gpt-4o](https://www.analyticsvidhya.com/blog/2024/07/conversational-chatbot-with-gpt4o/))*.

### Define an AutoGen agent

The ConversableAgent class creates a chatbot agent. The human_input_mode=”NEVER” indicates that the agent won’t request manual user input during conversations.

```python
from autogen import ConversableAgent
agent = ConversableAgent(
   name="chatbot",
   llm_config=llm_config,
   human_input_mode="NEVER",
)
reply = agent.generate_reply(
   messages=[{"content": "You are renowned AI expert. Now Tell me 2 jokes on AI .", "role": "user"}]
)
print(reply)
```

![Output](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T181615.501.webp)

```bash
reply = agent.generate_reply(
   messages=[{"content": "Repeat the joke.", "role": "user"}]
)
print(reply)
```

**Output**

```
Certainly! Could you please tell me which joke you'd like me to repeat?
```

### Setting up the Conversation

Setting up a conversation between two agents, Sunil and Harshit, where the memory of their interactions is retained.

Harshit and Sunil are AI-driven agents designed for engaging, humorous dialogues focused on social media reports. Harshit, a social media expert and office comedian, uses light, humour-filled language to keep conversations lively. Sunil, as head of the content department and Harshit’s senior, shares this comedic trait, adding structured humour by starting jokes with the last punchline. Both agents use pre-configured LLM settings and operate autonomously (human_input_mode=”NEVER”). This dynamic simulates workplace banter, blending professional discussions with entertainment, and is ideal for training, team simulations, or content generation. The continuous, comedic flow mimics real office interactions, enhancing engagement and relatability.

A ConversableAgent is typically an artificial intelligence agent capable of engaging in conversations based on predefined system messages and configurations. These agents use [natural language processing (NLP)](https://www.analyticsvidhya.com/blog/2024/08/nlp-in-modern-chatbots/) capabilities provided by [large language models (LLMs)](https://www.analyticsvidhya.com/blog/2023/03/an-introduction-to-large-language-models-llms/) to respond intelligently according to their system message instructions.

```makefile
Harshit = ConversableAgent(
   name="Harshit",
   system_message=
   "Your name is Harshit and you are a social media expert and do stand-up Comedy in office."
   "Also this is a office comedy"
   "this conversation is about social media reports"
   "Keep the language light and Humour high",
   llm_config=llm_config,
   human_input_mode="NEVER",
)
Sunil = ConversableAgent(
   name="Sunil",
   system_message=
   "Your name is Sunil and you are head of content department in Analytics Vidhya, Harshit is your Junior and you also do stand-up comedy in office. "
   "Start the next joke from the punchline of the previous joke."
   "Also this is a office comedy and Harshit is Sunil's Junior"
   "This must be funny and not so lengthy"
    "this conversation is about social media reports",
   llm_config=llm_config,
   human_input_mode="NEVER",
)
```

Two agents, Harshit and Sunil, are defined by their unique attributes, personalities, and backgrounds. Based on their roles, they are instructed to have humorous interactions.

```makefile
chat_result = Sunil.initiate_chat(
   recipient=Harshit,
   message="I'm Sunil. Harshit, let's keep the jokes rolling.",
   max_turns=3,
)
```

Sunil starts a conversation with Harshit with an initial message and a limit of 3 conversational turns.

```cpp
import pprint
pprint.pprint(chat_result.chat_history)
```

**Output**

```
[{'content': "I'm Sunil. Harshit, let's keep the jokes rolling.",

  'role': 'assistant'},

 {'content': "Sure, Sunil! Let's talk about social media reports—basically "

             'where numbers and hashtags collide in a dance-off. You know, '

             'those analytics graphs are like the weather in North India; they '

             'change every five minutes, and somehow they always predict doom. '

             "But don't worry, you're not going to need an umbrella, just a "

             'strong stomach!',

  'role': 'user'},

 {'content': "That's true, Harshit! Those graphs change more often than I "

             'change my favorite Mughal Darbar biryani place. Speaking of '

             'change, did you hear why the social media influencer went broke? '

             "Because they took too many selfies and couldn't afford to pay "

             'attention! But honestly, our reports are a bit like that '

             'influencer—always needing a new filter to look good.',

  'role': 'assistant'},

 {'content': "Haha, that's spot on, Sunil! Our social media reports have more "

             'filters than my "best selfie of 2023" folder—and somehow, they '

             'still look like they woke up on the wrong side of the algorithm! '

             "It's amazing how on Instagram we strive to make our lives look "

             'perfect, while in our reports, we strive to make the numbers '

             "look believable. It's like magic, but with less prestige and "

             'more caffeine!',

  'role': 'user'},

 {'content': 'Absolutely, Harshit! Our reports are like those reality TV '

             'shows—the drama is real, but the numbers, maybe not so much. And '

             "trust me, the only time I'll ever willingly pull an all-nighter "

             'for a report is if it promises a plot twist, like turning red '

             "numbers to black! Speaking of which, why don't our reports ever "

             "go on silent mode? They're always sending alerts at odd hours "

             "like they're auditioning for a horror movie!",

  'role': 'assistant'},

 {'content': 'Haha, Sunil, I completely agree! Our reports could definitely '

             'headline a suspense thriller: "The Metrics That Never Sleep." '

             'Just when you think you can relax, bam! An alert jumps out like '

             'a cheap jump scare, reminding you that your engagement rate is '

             "working harder than you are! And let's not even get started on "

             "the notifications. They're like that one friend who keeps "

             'showing up unannounced with extra enthusiasm and zero regard for '

             'your personal space—or your night’s sleep!',

  'role': 'user'}]
```

### For Chat Termination

This code is part of a setup for defining chatbot agents, Harshit and Sunil, who act as stand-up comedians. The goal is to customize their behaviour, specifically how they handle conversation termination. By specifying termination messages, the bots can end their interactions naturally, following predefined cues like “I gotta go.”

This helps in:

- **Enhanced User Experience:** Users get a more intuitive and human-like interaction, with a clear and relatable way to conclude conversations.
- **Maintained Flow and Humor:** Since these agents are stand-up comedians, managing their exit lines with playful phrases fits their roles and enhances immersion.

```makefile
Harshit = ConversableAgent(
   name="Harshit",
   system_message=
   "Your name is Harshit and you are a stand-up comedian. "
   "When you're ready to end the conversation, say 'I gotta go'.",
   llm_config=llm_config,
   human_input_mode="NEVER",
   is_termination_msg=lambda msg: "I gotta go" in msg["content"],
)
Sunil = ConversableAgent(
   name="Sunil",
   system_message=
   "Your name is Sunil and you are a stand-up comedian. "
   "When you're ready to end the conversation, say 'I gotta go'.",
   llm_config=llm_config,
   human_input_mode="NEVER",
   is_termination_msg=lambda msg: "I gotta go" in msg["content"] or "Goodbye" in msg["content"],
)
chat_result = joe.initiate_chat(
   recipient=cathy,
   message="I'm Sunil. Harshit, let's keep the jokes rolling."
)
```

**Output**

```
[{'content': "I'm Sunil. Harshit, let's keep the jokes rolling.",

  'role': 'assistant'},

 {'content': "Hey, Sunil! Great to have you here. Alright, let's get this joke "

             "train on track. Why don't scientists trust atoms? Because they "

             "make up everything! Keep ‘em coming! What's on your mind?",

  'role': 'user'},

 {'content': 'Hey, great to be here! That joke really has some chemistry, '

             "doesn't it? Speaking of science, did you hear about the "

             "mathematician who's afraid of negative numbers? He'll stop at "

             "nothing to avoid them! So, what's new with you?",

  'role': 'assistant'},

 {'content': "Nice! That's a mathematically perfect joke! As for me, I've been "

             'working on my coffee habit—which is just code for my endless '

             'pursuit of the perfect punchline. You know, caffeine might not '

             "solve any of my problems, but it's worth a shot! What's new in "

             'your world, Sunil?',

  'role': 'user'},

 {'content': "Sounds like you're brewing up some comedy gold there! As for me, "

             "I've been trying to get in shape, but it's tough. My idea of "

             'exercise is a cross between a lunge and a crunch—I call it '

             'lunch! Any big plans for the day?',

  'role': 'assistant'},

 {'content': "Haha, lunch is the most rewarding workout! As for me, I'm hoping "

             'to finalize my plans for a "Netflix Marathon," making sure the '

             "couch doesn't run away without me. And maybe come up with a few "

             "jokes that'll make even my socks roll down with laughter. How "

             'about you? Any other adventures, or is lunch the pinnacle of '

             "today's activities?",

  'role': 'user'},

 {'content': 'A "Netflix Marathon" sounds like my kind of event! Just remember '

             'to stretch between episodes—don’t want to pull a lazy muscle. As '

             'for me, I’m on a quest to find the perfect punchline myself. You '

             'know, one of those rare jokes that leave the audience breathless '

             'and begging for more… kind of like my cooking! Anyway, I gotta '

             'go, but this was a blast. Keep those socks in check!',

  'role': 'assistant'},

 {'content': "What's last joke we talked about?", 'role': 'user'},

 {'content': 'We last talked about the idea of cooking that leaves people '

             "breathless—not because it's amazing, but because it might just "

             "be that bad! It's kind of like when you open the oven and "

             'everyone nearby takes a big step back. Thanks for the laughs, '

             'and keep that comedy coming!',

  'role': 'assistant'},

 {'content': 'Haha, sounds like your cooking and the fire alarm could be best '

             "friends! Thanks for the laughs too, Sunil. It's been a real "

             'treat chatting with you. Take care, and I hope your search for '

             'that perfect punchline (and maybe recipe) goes well. I gotta go, '

             "but let's catch up again soon!",

  'role': 'user'}]
```

#### Output Analysis

- The conversation between Sunil and Harshit displays a lighthearted and humorous exchange, maintaining their defined personas (e.g., social media expertise and office comedy).
- The chat history records messages back and forth between the agents, showcasing how they build on each other’s content, respond to prompts, and maintain a coherent flow.

#### Key Points

- **Agent Customization**: Each agent has a defined name, role, and system messages, enabling tailored interactions.
- **Joke Chaining**: Sunil’s system message ensures each joke builds upon the previous punchline.
- **Termination Handling**: Both agents can recognise phrases that indicate the end of the conversation.
- **Humour and Light Language**: The system is designed to create an engaging and witty exchange, emphasising humour and relatability.

This setup can be leveraged to create automated, character-based dialogue simulations suitable for various applications, such as interactive storytelling, chatbots, or training simulations.

Let’s see how you can build a Multi-Agent System from Scratch.

## Agentic AI Multi-Agent Pattern from Scratch

Firstly, kudos to [Michaelis Trofficus](https://github.com/neural-maze/agentic_patterns/blob/main/notebooks/multiagent_pattern.ipynb) for making life easier by showing how we can build all the Agentic Design Patterns from scratch. In the above section, I have used the AutoGen framework, but now, let’s see how building this from scratch works.

*Note: Michaelis adapted ideas from Airflow’s design approach, using “>>” and “<<” symbols to indicate dependencies between agents. In this simplified micro-CrewAI model, the agents function like Airflow Tasks, and the Crew acts as an Airflow DAG.*

Also, he has been working on a minimalist version of CrewAI and has drawn inspiration from two key concepts: Crew and Agent.

By working on a minimalist version, Michaelis likely aiming to create a simpler, more streamlined framework of CrewAI, focusing on essential features and avoiding complex, extraneous elements. This would make the system easier to use and adapt while retaining the core collaboration and task delegation capabilities inspired by the Crew (team coordination) and Agent (individual autonomy) models. Before digging into the hands-on lets understand these:

### What is a Crew?

Here’s the GitHub Repo: [GitHub Crew](https://github.com/neural-maze/agentic_patterns/blob/main/src/agentic_patterns/multiagent_pattern/crew.py)

The Crew class is designed to represent a **group of agents working together within a coordinated environment**. It offers a framework to manage and execute agents in a structured way, ensuring that dependencies between them are respected.

#### 1. Core Concept of Crew

- The Crew class acts as a manager for a collection of agents, providing the means to handle them as a cohesive unit within a context.
- The structure ensures that agents are run in an order that respects their dependencies, preventing conflicts and enabling smooth execution.

#### 2. Key Attributes and Methods in Crew Class

- **current_crew (Class Attribute)**: Tracks the currently active Crew instance. This is essential for associating agents with the correct Crew context when they are created or registered.

- ****init** Method**: Initializes the `Crew` instance and creates an empty list, `agents`, to store agents that belong to the crew.

- Context Manager Methods (**enter** and **exit**)

  :

  - ****enter****: When a Crew instance is used in a `with` statement, this method sets it as the active crew.
  - ****exit****: Clears the active crew context when exiting the `with` block.

- **add_agent Method**: Adds a new agent to the `agents` list.

- **register_agent (Static Method)**: Associates an agent with the active Crew by adding it to the `agents` list if current_crew is not `None`.

- topological_sort Method

  :

  - **Purpose**: Sorts the agents in a topological order based on their dependencies to prevent any circular references.

  - Process

    :

    - Uses an in-degree dictionary to track dependencies for each agent.
    - Adds agents with no dependencies to a queue and processes them to build a sorted list.
    - Raises an error if a circular dependency is detected (when the sorted list doesn’t match the total number of agents).

- **plot Method**: Visualizes the agents and their dependencies as a Directed Acyclic Graph (DAG) using Graphviz.

- `run` Method

  :

  - **Functionality**: Runs all agents in the order determined by topological_sort.
  - **Execution**: Calls each agent’s `run` method and uses fancy_print for better output formatting.

#### 3. How It Works

- **Context Management**: The `Crew` class uses context management (**enter** and **exit**) to create a scope where all agents are associated with a specific crew. This makes it easier to manage the lifecycle and interactions of agents within a defined context.
- **Topological Sorting**: The topological sort ensures that agents are executed in a sequence where dependencies are resolved. This is critical in scenarios where agents rely on each other’s outputs or states.
- **Graph Visualization**: The `plot` method provides a clear, visual representation of the dependency structure, aiding in understanding the execution flow.

The Crew class is a comprehensive solution for managing interdependent agents, providing context management and dependency resolution through topological sorting, visualization, and an execution mechanism—all essential for workflows that involve coordinated agent-based operations.

### What is an Agent?

Here’s the GitHub Repo: [GitHub Agent](https://github.com/neural-maze/agentic_patterns/blob/main/src/agentic_patterns/multiagent_pattern/agent.py)

An **Agent** in the context of this code is an abstraction representing an AI unit capable of collaborating within a multi-agent system to complete tasks. The design incorporates features for inter-agent dependency management, task execution, and context sharing among agents. The key components of the `Agent` class are:

1. Attributes

   :

   - **Name, backstory, task description, and task expected output**: These define the identity and the specific task details of the agent.
   - **ReactAgent**: A built-in instance used to generate responses, indicating that `Agent` is based on a reactive AI architecture.
   - **Dependencies and Dependents**: Lists tracking other agents that the current agent either depends on or is responsible for.
   - **Context**: A string attribute accumulating context or results shared from other agents, used to influence its output.

2. Initialization (**init** method)

   :

   - Sets up the agent’s core attributes and registers the agent to a session (termed as “Crew” in this context) if one exists.
   - Associates the agent with tools and a specific language model (defaulting to “llama-3.1-70b-versatile”).

3. Dependency Management

   :

   - The agent uses custom operators (`>>` and `<<`) to visually express and establish dependencies between agents, inspired by data pipeline frameworks like Apache Airflow.
   - `add_dependency` and `add_dependent` methods handle the management of agent relationships programmatically.

4. Functionality

   :

   - **receive_context**: Receives output from dependent agents and adds it to the context, which enriches the agent’s task execution.
   - **create_prompt**: Constructs a comprehensive prompt based on the agent’s task, context, and expected output to guide the response generation.
   - **run**: Executes the task by using the prompt generated, runs the ReactAgent, and then propagates the result to all dependents.

5. Collaborative Mechanism

   :

   - Agents form a multi-agent system capable of working collaboratively, sharing context and outputs, where each agent can trigger subsequent agents based on dependencies.
   - The `Crew` abstraction acts as a coordination system to register and manage these agents, forming a network of task-oriented entities.

Overall, an `Agent` is essentially a modular, self-sufficient AI unit that can coordinate and communicate with others to solve complex tasks collaboratively. It acts as a node in a broader AI-driven workflow, capable of handling tasks autonomously and contributing to the collective output of the multi-agent system.

### What is a Tool?

Here’s the GitHub Repo: [GitHub Tool](https://github.com/neural-maze/agentic_patterns/blob/main/src/agentic_patterns/tool_pattern/tool.py)

A Tool is a class that serves as a wrapper for a function, capturing details about the function’s signature and providing a way to execute the function. Essentially, a Tool object makes it possible to manage functions more uniformly, including validating input arguments and presenting metadata about the function.

#### How It Works

- **Creating a Tool**: You can use the @tool decorator to wrap any function. This will create an instance of `Tool` that contains metadata about the function and provides methods for running it.
- **Executing a Tool**: The run method on a Tool object allows the wrapped function to be executed with keyword arguments.
- **Input Validation**: The validate_arguments function helps ensure that inputs are of the correct type, making the execution of the Tool more robust and predictable.

Let’s get started!

The author has built his own custom implementations of Agent, Crew and tool, as we discussed in detail earlier, as it is useful and modular to encapsulate relevant functions and behavior within dedicated classes and modules. We will now import these classes and functions and use them to build our multi-agent system from scratch

Here’s the repo links for all 3 (agent, crew, tool)

- [GitHub Crew](https://github.com/neural-maze/agentic_patterns/blob/main/src/agentic_patterns/multiagent_pattern/crew.py)
- [GitHub Agent](https://github.com/neural-maze/agentic_patterns/blob/main/src/agentic_patterns/multiagent_pattern/agent.py)
- [GitHub Tool](https://github.com/neural-maze/agentic_patterns/blob/main/src/agentic_patterns/tool_pattern/tool.py)

#### Implementation

Refer to this Repo for full code: [multiagent_pattern](https://github.com/neural-maze/agentic_patterns/tree/main/src/agentic_patterns/multiagent_pattern)

```javascript
from agentic_patterns.multiagent_pattern.agent import Agent
from agentic_patterns.tool_pattern.tool import tool
from agentic_patterns.multiagent_pattern.crew import CrewCopy Code
```

- **`Agent`**: Class used to create instances of agents that have specific roles and tasks.
- **`tool`**: Decorator to expose functions as tools that agents can use.
- **`Crew`**: Manages multiple agents and controls the order in which they execute their tasks.

```python
# Define a function as a tool that agents can use
@tool
def write_str_to_txt(string_data: str, txt_filename: str):
    """
    Writes a string to a txt file.

    This function takes a string and writes it to a text file. If the file already exists,
    it will be overwritten with the new data.

    Args:
        string_data (str): The string containing the data to be written to the file.
        txt_filename (str): Name of the text file to which the data should be written.
    """
    # Write the string data to the file
    with open(txt_filename, mode='w', encoding='utf-8') as file:
        file.write(string_data)

    print(f'Data successfully written to {txt_filename}')

```

- **`@tool` Decorator**: Marks `write_str_to_txt` as a tool that can be used by agents.

- **Function Purpose**: Takes a string and writes it to a specified text file. If the file exists, it will be overwritten.

- Arguments

  :

  - `string_data`: The content to write to the file.
  - `txt_filename`: The name of the output file.

```python
# Create a crew of agents to execute a sequence of tasks
with Crew() as crew:
    # Define the first agent: a poet who writes poems
    agent_1 = Agent(
        name="Poet Agent",
        backstory="You are a well-known poet, who enjoys creating high quality poetry.",
        task_description="Write a poem about the meaning of life",
        task_expected_output="Just output the poem, without any title or introductory sentences",
    )
    
    # Define the second agent: a translator for Spanish
    agent_2 = Agent(
        name="Poem Translator Agent",
        backstory="You are an expert translator especially skilled in Spanish",
        task_description="Translate a poem into Spanish",
        task_expected_output="Just output the translated poem and nothing else",
    )
    
    # Define the third agent: a writer that saves content to a text file
    agent_3 = Agent(
        name="Writer Agent",
        backstory="You are an expert transcriber, that loves writing poems into txt files",
        task_description="You'll receive a Spanish poem in your context. You need to write the poem into './poem.txt' file.",
        task_expected_output="A txt file containing the Spanish poem received from the context",
        tools=write_str_to_txt,  # Allows this agent to use the tool defined earlier
    )

    # Define the workflow order for agents
    agent_1 >> agent_2 >> agent_3

# Run the crew of agents, executing their tasks in the specified order
    crew.run()
```

- **with Crew() as crew:**: Initiates a context for defining and running the agents.

- agent_1

  :

  - **Name**: “Poet Agent”
  - **Backstory**: Positions it as a skilled poet.
  - **Task Description**: Writes a poem focused on the meaning of life.
  - **Expected Output**: Outputs just the poem, with no additional text.

- agent_2

  :

  - **Name**: “Poem Translator Agent”
  - **Backstory**: Establishes it as a Spanish language expert.
  - **Task Description**: Translates a poem into Spanish.
  - **Expected Output**: Only the translated poem.

- agent_3

  :

  - **Name**: “Writer Agent”
  - **Backstory**: Describes it as a transcription specialist.
  - **Task Description**: Writes the Spanish poem to a text file named `./poem.txt`.
  - **Tools**: Has access to the write_str_to_txt tool for saving the poem.

- Workflow

  (agent_1 >> agent_2 >> agent_3):

  - Establishes the order in which the agents complete their tasks: first, the poem is created by `agent_1`, then translated by `agent_2`, and finally saved to a file by `agent_3`.

- **crew.run()**: Triggers the execution of tasks in the specified sequence.

```bash
#here's crew plot
crew.plot()
```

![Plot Graph](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T183107.630.webp)

For full code: [notebooks/multiagent_pattern.ipynb](https://github.com/neural-maze/agentic_patterns/blob/main/notebooks/multiagent_pattern.ipynb)

## MetaGPT Agents: Meta Programming for Multi-Agents in Standard Operating Procedures

![MetaGPT Agents: Meta Programming for Multi-Agents in Standard Operating Procedures](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T183154.970.webp)Source: [The software development SOPs between MetaGPT and real-world human teams.](https://arxiv.org/pdf/2308.00352)

**[MetaGPT](https://github.com/geekan/MetaGPT)** is a framework for multi-agent collaboration using large language models (LLMs) designed to replicate human-like workflows through **Standardized Operating Procedures (SOPs)**. This approach enhances problem-solving by structuring LLM interactions to reduce logic inconsistencies and hallucinations. MetaGPT breaks down complex tasks, assigns specialized roles, and ensures quality through defined outputs. It outperforms existing systems like [AutoGPT](https://autogpt.net/) and [LangChain](https://www.langchain.com/) on code generation benchmarks, showcasing a robust and efficient meta-programming solution for software engineering.

### Structured Methodologies and SOP-Driven Workflows

MetaGPT represents a breakthrough in meta-programming by incorporating structured methodologies that mimic standard operating procedures (SOPs). This innovative framework, built on GPT models, requires agents to produce detailed and structured outputs such as requirement documents, design artifacts, and technical specifications. These outputs ensure clarity in communication and minimize errors during collaboration, effectively enhancing the accuracy and consistency of generated code. The SOP-driven workflow in MetaGPT organizes agents to function cohesively, akin to a streamlined team in a software development firm, where strict standards govern handovers and reduce unnecessary exchanges between agents.

### Role Differentiation and Task Management

By defining specialized roles such as Product Manager, Architect, Engineer, Project Manager, and QA Engineer, MetaGPT orchestrates complex tasks into manageable, specific actions. This role differentiation facilitates the efficient execution of projects, with each agent contributing its expertise and maintaining structured communication. Integrating these practices enables a more seamless and effective collaboration process, limiting issues like redundant messaging or miscommunications that could hinder progress.

### Communication Protocol and Feedback System

MetaGPT also stands out with an innovative communication protocol that allows agents to exchange targeted information and access shared resources through structured interfaces and publish-subscribe mechanisms. A unique feature is the executable feedback system, which not only checks but refines and runs code during runtime, significantly improving the generated outputs’ quality and reliability.

### Application of Human-Centric Practices

The application of human-centric practices such as SOPs reinforces the robustness of the system, making it a powerful tool for constructing LLM-based multi-agent architectures. This pioneering use of meta-programming within a collaborative framework paves the way for more regulated and human-like interactions among artificial agents, positioning MetaGPT as a forward-thinking approach in the field of multi-agent system design.

## Software Development Process in MetaGPT

![Software Development Process in MetaGPT](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T183339.003.webp)Source: [MetaGPT](https://arxiv.org/pdf/2308.00352)

The provided diagram illustrates how MetaGPT, a GPT-based meta-programming framework, manages the software development process by implementing Standard Operating Procedures (SOPs). Here’s a breakdown of the diagram:

1. **Human Input**: The process begins with a user providing a project requirement, in this case, the creation of a 2048 sliding tile number puzzle game.

2. Product Manager (PM)

   :

   - The Product Manager conducts a thorough analysis and formulates a detailed Product Requirement Document (PRD).
   - The PRD includes **Product Goals**, **User Stories**, a **Competitive Analysis**, and a **Requirement Analysis**.
   - This analysis breaks down the user requirements into manageable parts and defines the main goals, user needs, and design considerations for the project.

3. Architect

   :

   - The Architect receives the PRD and translates it into a **system design**.
   - This design includes a **program call flow**, a **file list**, and a high-level plan for structuring the software components.
   - The Architect determines how the components will interact and which tools and frameworks (e.g., Pygame for game development with [Python](http://python.org/)) will be used.

4. Project Manager (PM)

   :

   - The Project Manager then creates a **task list** based on the Architect’s system design and distributes the work to the respective agents.
   - This ensures that tasks are clearly defined and aligned with the project requirements.

5. Engineer

   :

   - The Engineer works on implementing the designated code and functionalities based on the detailed plans.
   - The code snippet shown highlights the development of the core game logic, which includes classes and functions necessary for the 2048 game.

6. QA Engineer

   :

   - The QA Engineer reviews and tests the code for quality assurance.
   - This step ensures that the game meets the predefined requirements and maintains high standards of functionality and reliability.

7. End Product

   :

   - The diagram includes a visual representation of the final output, which shows how users interact with the developed game.

The workflow, as depicted, emphasizes the sequential flow of information and tasks from one role to another, demonstrating how MetaGPT uses defined SOPs to streamline the development process. This structured approach minimizes miscommunications and maximizes productivity by enforcing clear roles, responsibilities, and standard communication practices among agents.

## Why Multi-Agent Systems Require MetaGPT?

Multi-agent systems based on large language models (LLMs) face significant challenges when handling complex tasks. While they can perform simple dialogue tasks effectively, issues arise with more complicated scenarios due to inherent limitations in logical consistency. These issues are often exacerbated by cascading hallucinations, where errors compound as LLMs are naively chained together, resulting in flawed or incorrect outcomes.

### MetaGPT Addresses these Challenges through Several Key Innovations

1. **Meta-Programming Framework:** MetaGPT offers a unique meta-programming approach that integrates structured human-like workflows into multi-agent interactions. This structured framework ensures that agents adhere to systematic methods akin to those humans use when solving complex problems.
2. **Standardized Operating Procedures (SOPs):** By encoding SOPs into the prompt sequences, MetaGPT aligns the workflows of multi-agent systems with well-defined procedures. This results in smoother collaboration among agents and minimizes logical inconsistencies, as these SOPs guide agents through a structured process.
3. **Error Reduction through Verification:** Agents within the MetaGPT framework are designed to emulate human-like domain expertise, enabling them to verify intermediate results and check the correctness of their outputs. This verification step is crucial for reducing errors that can arise from typical LLM-based system failures.
4. **Assembly Line Paradigm:** MetaGPT introduces an assembly line-like approach to task management, where various agents are assigned specific roles. This structured distribution of roles ensures that complex tasks are broken down into manageable subtasks, facilitating coordinated efforts among multiple agents and improving overall task execution.
5. **Enhanced Performance on Benchmarks:** In tests involving collaborative software engineering benchmarks, MetaGPT has shown the ability to produce more coherent and reliable outputs compared to traditional chat-based multi-agent systems. This demonstrates the effectiveness of its assembly line structure and role-specific task division in achieving better task outcomes.

Multi-agent systems require MetaGPT to manage the intricacies of complex tasks through structured, human-like workflows that reduce errors and logical inconsistencies. By employing SOPs, role assignments, and intermediate result verification, MetaGPT ensures that agents work collaboratively and efficiently, leading to superior performance and coherent task completion.

## What are the Benefits of Agentic AI Multi-Agent Pattern?

![What are the Benefits of Agentic AI Multi-Agent Pattern?](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/11/unnamed-2024-11-13T183513.605.webp)

Here are the benefits of the Multi-Agent Pattern:

1. **Enhanced Performance through Collaboration**: Deploying multiple AI agents working together often yields superior results compared to a single agent. Collaborative efforts among agents can lead to improved outcomes, as evidenced by studies demonstrating better performance in multi-agent setups.
2. **Improved Focus and Comprehension**: Large language models (LLMs) capable of processing extensive input may still struggle to understand complex or lengthy information. By assigning specific roles to different agents, each can concentrate on a particular task, enhancing overall comprehension and effectiveness.
3. **Optimized Subtasks for Efficiency**: Breaking down complex projects into smaller, manageable subtasks allows each agent to specialize and optimize its assigned role. This targeted approach ensures that each component of the task is handled with greater precision and efficiency.
4. **Structured Framework for Complex Tasks**: The multi-agent pattern provides a systematic way to decompose intricate tasks, similar to how developers use processes or threads in programming. This structure simplifies the management and execution of complex projects.
5. **Familiar Management Analogy**: Managing AI agents mirrors the way managers oversee teams in organizations. This familiar concept helps developers intuitively assign roles and responsibilities to agents, leveraging existing understanding of team dynamics.
6. **Flexible and Dynamic Workflows**: Each agent operates with its own workflow and memory system, allowing for dynamic interaction and collaboration with other agents. This flexibility enables agents to engage in planning, tool use, and adapt to changing requirements, resulting in efficient and complex workflows.
7. **Reduced Risk in Experimentation**: Mismanaging human teams can have significant consequences, but experimenting with AI agents carries much less risk. This allows for trial and error in optimizing agent roles and interactions without severe repercussions.
8. **Efficient Resource Utilization**: Assigning specific tasks to dedicated agents ensures that computational resources are used effectively. This focused allocation prevents overloading a single agent and promotes balanced workload distribution.
9. **Scalability and Adaptability**: The multi-agent approach allows for easy scaling of tasks by adding or adjusting agents as needed. This adaptability is crucial for handling projects of varying sizes and complexities.
10. **Enhanced Problem-Solving Capabilities**: Collaborative interactions among agents can lead to innovative solutions and improved problem-solving. The combined expertise and perspectives of multiple agents can uncover approaches that a single agent might miss.
11. **Improved Task Prioritization**: By specifying the importance of each agent’s subtask, developers can ensure that critical aspects of a project receive appropriate attention. This prioritisation enhances the quality and relevance of each agent’s outputs.

The agentic AI multi-agent pattern offers a robust framework for improving complex task performance, efficiency, and scalability. By emulating familiar management structures and leveraging the strengths of specialised agents, this approach enhances AI systems’ capabilities while minimising risks associated with mismanagement.

*Also, to understand the Agent AI better, explore: [The Agentic AI Pioneer Program](https://www.analyticsvidhya.com/agenticaipioneer/?utm_source=blog_page&utm_medium=blog&utm_campaign=seo)*.

## Conclusion

The Agentic AI Multi-Agent Pattern serves as an advanced architecture within AI design, embodying a collaborative framework where specialised agents work collectively to complete complex tasks. Building upon foundational patterns such as Reflection, Tool Use, and Planning, the Agentic AI Multi-Agent Pattern divides large projects into manageable subtasks, allowing agents with unique roles to contribute their expertise. This modular approach promotes coordinated problem-solving, autonomy, and scalability, facilitating efficient workflows akin to team dynamics in real-world management.

The Multi-Agent Pattern’s benefits include enhanced focus, optimised task execution, dynamic adaptability, and improved problem-solving capabilities. By emulating human team management and fostering agent autonomy, this pattern paves the way for more sophisticated, reliable, and efficient AI applications across various industries, from software engineering to content creation and beyond.

I hope you found this series on Agentic AI Design Pattern beneficial in learning how Agents works. If you have any questions or suggestions let me know in the comments!!!

**References**

1. “[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](<https://arxiv.org/abs/2201.11903?utm_campaign=The> Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY),” Wei et al. (2022)
2. “[HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](<https://arxiv.org/abs/2303.17580?utm_campaign=The> Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY),” Shen et al. (2023)
3. “[Understanding the planning of LLM agents: A survey](<https://arxiv.org/pdf/2402.02716.pdf?utm_campaign=The> Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-8Kh954rkXmE4vgpKvro3Klpjhn7IuT-Y_eXIYtgVIq9PTzwa5zFWX7FZZqv1tuDEEsTDuY),” by Huang et al. (2024)
4. [MichaelisTrofficus](https://github.com/neural-maze/agentic_patterns/blob/main/notebooks/multiagent_pattern.ipynb): For building the Agentic AI Multi-Agent Pattern from Scratch
