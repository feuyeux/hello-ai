# AGENT AI: SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION

<https://arxiv.org/pdf/2401.03568v2>
<https://mp.weixin.qq.com/s/mGrhbzNDHZhN8OHPKagMWA>

多模态交互智能体(Agent)全面综述：定义、范式、学习、系统、分类、应用、评估

Original 旺知识 旺知识 2024年07月13日 16:12 广东

多模态AI系统很可能会成为我们日常生活中无处不在的存在。使这些系统更具交互性的一种有希望的方法是将它们作为物理和虚拟环境中的智能体。目前，系统利用现有的基础模型作为创建具身智能体的基本构建块。将智能体嵌入这些环境中，有助于模型处理和解释视觉和上下文数据，这对于创建更复杂和上下文感知的AI系统至关重要。例如，一个能够感知用户行为、人类行为、环境对象、音频表达和场景集体情感的系统，可以用来通知和指导给定环境中智能体的响应。为了加速基于智能体的多模态智能研究，我们定义“智能体AI”为一类交互系统，能够感知视觉刺激、语言输入和其他环境基础数据，并能够产生有意义的具身行动。特别是，我们探索了旨在通过整合外部知识、多感官输入和人类反馈来改进基于下一个具身行动预测的智能体的系统。我们认为，通过在基础环境中开发智能体AI系统，还可以减少大型基础模型的幻觉及其产生环境不正确输出的倾向。新兴的智能体AI领域包括了多模态交互的更广泛的具身和智能体方面。超越智能体在物理世界中的行动和交互，我们设想一个未来，人们可以轻松创建任何虚拟现实或模拟场景，并与其中的具身智能体进行交互。

1 引言

1.1 动机

历史上，AI系统在1956年达特茅斯会议上被定义为能够从环境中收集信息并以有用的方式与之交互的人工生命形式。受到这个定义的启发，Minsky的MIT团队在1970年构建了一个名为“Copy Demo”的机器人系统，该系统观察“积木世界”场景并成功重建了观察到的多面体积木结构。该系统包括观察、规划和操纵模块，揭示了这些子问题每个都非常具有挑战性，需要进一步的研究。AI领域分裂成专业化的子领域，在解决这些和其他问题方面取得了巨大进展，但过度的还原主义模糊了AI研究的总体目标。

为了超越现状，有必要回归到受亚里士多德整体论启发的AI基础。幸运的是，最近在大型语言模型（LLMs）和视觉语言模型（VLMs）方面的革命使得创建符合整体理念的新型AI智能体成为可能。抓住这个机会，本文探讨了集成语言熟练度、视觉认知、上下文记忆、直观推理和适应性的模型。在我们探索的过程中，我们还重新审视了基于亚里士多德终极原因的系统设计，即系统的“目的”，这可能在之前的AI发展中被忽视了。

随着强大的预训练LLMs和VLMs的出现，自然语言处理和计算机视觉领域迎来了复兴。LLMs现在展示了令人印象深刻的解读现实世界语言数据细微差别的能力，通常达到了与人类专业知识平行甚至超越的能力（OpenAI，2023）。最近，研究人员已经表明，LLMs可以扩展为在各种环境中作为智能体行动，执行复杂的动作和任务，当它们与特定领域的知识和模块配对时（Xi等人，2023）。这些场景以复杂的推理、对智能体角色及其环境的理解以及多步骤规划为特征，测试了智能体在环境约束内做出高度微妙和复杂决策的能力（Wu等人，2023；Meta基础AI研究（FAIR）外交团队等人，2022）。

在这些初步努力的基础上，AI社区正处于一个重要的范式转变的边缘，从创建被动、结构化任务的AI模型转变为能够在多样化和复杂环境中承担动态、智能体角色的模型。在这种情况下，本文调查了使用LLMs和VLMs作为智能体的巨大潜力，强调了具有语言熟练度、视觉认知、上下文记忆、直观推理和适应性混合的模型。利用LLMs和VLMs作为智能体，特别是在游戏、机器人技术和医疗保健等领域，不仅为最新AI系统提供了严格的评估平台，而且还预示着以智能体为中心的AI将对社会和产业产生的变革性影响。当这些智能体模型被充分利用时，可以重新定义人类体验并提升运营标准。由这些模型引入的广泛自动化预示着产业和社会经济动态的重大转变。这些进步将与多方面的领导者板块交织在一起，不仅是技术层面的，还有伦理层面的，正如我们将在第11节中详细讨论的。我们探讨了智能体AI的这些子领域的重叠区域，并在图1中说明了它们的相互联系。
图1：概述了一个智能体AI系统，该系统能够在不同的领域和应用中感知和行动。智能体AI作为实现通用人工智能（AGI）的有希望的途径正在出现。智能体AI训练已经展示了在物理世界中多模态理解的能力。它通过利用生成性AI以及多个独立数据源，提供了一个与现实无关的训练框架。当在跨现实数据上训练时，为代理和行动相关任务训练的大型基础模型可以应用于物理和虚拟世界。我们展示了一个智能体AI系统的概述，该系统能够在许多不同的领域和应用中感知和行动，可能作为使用代理范式实现AGI的途径。

1.2 背景

现在，我们将介绍支持智能体AI概念、理论背景和现代实现的相关研究论文。

大型基础模型：LLMs和VLMs一直在推动开发通用智能机器（Bubeck等人，2023；Mirchandani等人，2023）的努力。尽管它们是使用大型文本语料库进行训练的，但它们卓越的问题解决能力并不局限于规范的语言处理领域。LLMs可能解决以前被认为是专属于人类专家或特定领域算法处理的复杂任务，范围从数学推理（Imani等人，2023；Wei等人，2022；Zhu等人，2022）到回答专业法律问题（Blair-Stanek等人，2023；Choi等人，2023；Nay，2022）。最近的研究显示，使用LLMs为机器人和游戏AI生成复杂计划的可能性（Liang等人，2022；Wang等人，2023a，b；Yao等人，2023a；Huang等人，2023a），标志着LLMs作为通用智能代理的重要里程碑。

具身AI一些工作利用LLMs执行任务规划（Huang等人，2022a；Wang等人，2023b；Yao等人，2023a；Li等人，2023a），特别是LLMs的全球规模领域知识和出现零样本具身能力，执行复杂的任务规划和推理。最近机器人研究也利用LLMs执行任务规划（Ahn等人，2022a；Huang等人，2022b；Liang等人，2022），通过将自然语言指令分解为子任务序列，无论是以自然语言形式还是Python代码形式，然后使用低级控制器执行这些子任务。此外，它们结合环境反馈来提高任务性能（Huang等人，2022b），（Liang等人，2022），（Wang等人，2023a），和（Ikeuchi等人，2023）。

交互学习：设计用于交互学习的AI智能体使用机器学习技术和用户交互的组合。最初，AI智能体在大型数据集上进行训练。这个数据集包括各种类型的信息，取决于智能体的预期功能。例如，设计用于语言任务的AI将在大量文本数据上进行训练。训练涉及使用机器学习算法，可能包括深度学习模型如神经网络。这些训练模型使AI能够识别模式，进行预测，并基于其训练数据生成响应。AI智能体也可以通过与用户的实时交互学习。这种交互学习可以以各种方式发生：1）基于反馈的学习：AI根据直接用户反馈调整其响应（Li等人，2023b；Yu等人，2023a；Parakh等人，2023；Zha等人，2023；Wake等人，2023a，b，c）。例如，如果用户纠正了AI的响应，AI可以使用这些信息来改进未来的响应（Zha等人，2023；Liu等人，2023a）。2）观察学习：AI观察用户交互并隐式学习。例如，如果用户经常提出类似的问题或以特定方式与AI交互，AI可能会调整其响应以更好地适应这些模式。它允许AI智能体理解并处理人类语言，多模态设置，解释跨现实上下文，并生成人类用户响应。随着更多的用户交互和反馈，AI智能体的性能通常会持续提高。这个过程通常由人类操作员或开发人员监督，以确保AI正在适当地学习，并且没有发展出偏见或错误的模式。

1.3 概述

多模态智能体AI（MAA）是一类系统，它们基于对多模态感官输入的理解，在特定环境中生成有效动作。随着大型语言模型（LLMs）和视觉语言模型（VLMs）的出现，提出了许多MAA系统，涵盖从基础研究到应用的各个领域。虽然这些研究领域通过与各自领域的传统技术（例如，视觉问答和视觉语言导航）整合而迅速发展，但它们共享共同的兴趣，如数据收集、基准测试和伦理观点。在本文中，我们专注于MAA的一些代表性研究领域，即多模态性、游戏（VR/AR/MR）、机器人技术和医疗保健，我们旨在提供这些领域中讨论的共同问题的综合知识。因此，我们期望学习MAA的基础知识并深入了解以进一步推进它们的研究。具体的学习成果包括：

MAA概述：深入其原理和在当代应用中的角色，为研究人员提供对其重要性和用途的全面把握。

方法论：通过在游戏、机器人技术和医疗保健中的案例研究，详细说明LLMs和VLMs如何增强MAAs。

性能评估：使用相关数据集评估MAAs的指导，重点关注其有效性和泛化能力。

伦理考虑：讨论部署智能体AI的社会影响和伦理领导者板块，强调负责任的发展实践。

新兴趋势和未来领导者板块：对每个领域中的最新发展进行分类，并讨论未来的发展方向。

基于计算机的行动和通用智能体（GAs）对许多任务都很有用。为了让GA真正对用户有价值，它可以自然地与之交互，并泛化到广泛的上下文和模态。我们的目标是培养一个充满活力的研究生态系统，并在智能体AI社区中创建共享的身份和目标感。MAA有可能在包括来自人类的输入在内的各种上下文和模态中得到广泛应用。因此，我们相信这个智能体AI领域可以吸引不同领域的研究人员，促进一个充满活力的智能体AI社区和共享目标。

由学术界和工业界的杰出专家领导，我们期望本文成为一个互动和丰富的体验，包括智能体指令、案例研究、任务会议和实验讨论，确保为所有研究人员提供全面和引人入胜的学习体验。

本文旨在提供关于智能体AI领域当前研究的一般和全面的知识。为此，本文的其余部分组织如下。第2节概述了智能体AI如何从与相关新兴技术整合中受益，特别是大型基础模型。第3节描述了我们为训练智能体AI提出的新范式和框架。第4节提供了在智能体AI训练中广泛使用的方法论的概述。第5节对各种类型的智能体进行了分类和讨论。第6节介绍了智能体AI在游戏、机器人技术和医疗保健中的应用。第7节探讨了研究社区为开发一个多才多艺的智能体AI所做的努力，该智能体AI能够跨各种模态、领域应用，并弥合仿真与现实之间的差距。第8节讨论了智能体AI的潜力，它不仅依赖于预训练的基础模型，还通过利用与环境和用户的交互不断学习和自我改进。第9节介绍了我们为多模态智能体AI训练设计的新数据集。第11节讨论了AI智能体的伦理考虑、局限性和社会影响的热门话题。

2 智能体AI整合

基于LLMs和VLMs的基础模型，正如之前研究所提出的，其在具身AI领域的性能仍然有限，特别是在理解、生成、编辑和交互方面，对于未见环境或场景（Huang等人，2023a；Zeng等人，2023）。因此，这些限制导致AI智能体的输出次优。当前以智能体为中心的AI建模方法侧重于直接可访问和明确定义的数据（例如文本或世界状态的字符串表示），通常使用从大规模预训练中学到的领域和环境独立模式来预测每个环境的行动输出（Xi等人，2023；Wang等人，2023c；Gong等人，2023a；Wu等人，2023）。在（Huang等人，2023a）中，我们研究了通过结合大型基础模型进行知识引导的协作和交互场景生成任务，并展示了有希望的结果，表明知识基础的LLM智能体能提高2D和3D场景理解、生成和编辑的性能，以及与其他人类-智能体交互（Huang等人，2023a）。通过整合智能体AI框架，大型基础模型能够更深入地理解用户输入，形成复杂和适应性强的人机交互系统。LLM和VLM在生成性AI、具身AI、多模态学习的知识增强、混合现实生成、文本到视觉编辑、游戏或机器人任务中的2D/3D模拟中的人类交互等不可见的紧急能力。智能体AI在基础模型方面的最新进展是解锁具身智能体通用智能的催化剂。大型行动模型或代理视觉语言模型为通用具身系统（如规划、问题解决和在复杂环境中学习）开辟了新的可能性。智能体AI在元宇宙中的进一步测试，以及AGI的早期版本。

2.1 无限智能体

AI智能体有能力根据其训练和输入数据进行解释、预测和响应。虽然这些能力先进且持续改进，但重要的是要认识到它们的局限性以及它们所训练的基础数据的影响。AI智能体系统通常具备以下能力：1）预测建模：AI智能体可以根据历史数据和趋势预测可能的结果或建议下一步行动。例如，它们可能预测文本的延续、问题的答案、机器人的下一个动作或场景的解决。2）决策制定：在某些应用中，AI智能体可以基于其推断做出决策。通常，智能体会根据最有可能实现指定目标的方案来做出决策。对于像推荐系统这样的AI应用，智能体可以根据其对用户偏好的推断决定推荐哪些产品或内容。3）处理歧义：AI智能体通常可以通过根据上下文和训练推断最可能的解释来处理歧义输入。然而，它们这样做的能力受到其训练数据和算法范围的限制。4）持续改进：虽然一些AI智能体能够从新数据和交互中学习，但许多大型语言模型在训练后不会持续更新它们的知识库或内部表示。它们的推断通常仅基于它们上次训练更新时可用的数据。

我们在图2中展示了增强的交互智能体，用于多模态和跨现实不可知的整合，具有紧急机制。一个AI智能体需要为每个新任务收集广泛的训练数据，这在许多领域可能代价昂贵或不可能。在这项研究中，我们开发了一个无限智能体，它学习将记忆信息从一般基础模型（例如，GPT-X，DALL-E）转移到新领域或场景中，用于场景理解、生成和物理或虚拟世界中的交互编辑。

这种无限智能体在机器人技术中的应用是RoboGen（Wang等人，2023d）。在这项研究中，作者提出了一个自动运行任务提议、环境生成和技能学习周期的管道。RoboGen是将大型模型中嵌入的知识转移到机器人技术的努力。

2.2 带有大型基础模型的智能体AI

最近研究表明，大型基础模型在创建作为智能体在环境强加约束中行动的基准数据方面发挥着至关重要的作用。例如，使用基础模型进行机器人操纵（Black等人，2023；Ko等人，2023）和导航（Shah等人，2023a；Zhou等人，2023a）。例如，Black等人使用图像编辑模型作为高级规划器，生成未来子目标的图像，从而引导低级策略（Black等人，2023）。对于机器人导航，Shah等人提出了一个系统，该系统使用LLM从文本中识别地标，并使用VLM将这些地标与视觉输入关联起来，通过自然语言指令增强导航（Shah等人，2023a）。

对响应语言和环境因素的条件人类运动的生成也越来越感兴趣。一些AI系统已被提出，以生成根据特定语言指令（Kim等人，2023；Zhang等人，2022；Tevet等人，2022）量身定制的运动和动作，并适应各种3D场景（Wang等人，2022a）。这一研究强调了生成模型在增强AI智能体在多样化场景中的适应性和响应性方面的不断增强的能力。

2.2.1 幻觉

生成文本的智能体通常容易出现幻觉，即生成的文本无意义或与提供源内容不符的情况（Raunak等人，2021；Maynez等人，2020）。幻觉可以分为两类，内在和外在（Ji等人，2023）。内在幻觉是与源材料相矛盾的幻觉，而外在幻觉是生成的文本包含源材料中未包含的额外信息。

一些有希望的减少语言生成中幻觉率的方法包括使用增强检索生成（Lewis等人，2020；Shuster等人，2021）或其他通过外部知识检索来增强自然语言输出的方法（Dziri等人，2021；Peng等人，2023）。一般来说，这些方法通过检索额外的源材料并提供检查生成响应与源材料之间矛盾的机制来增强语言生成。

在多模态智能体系统的背景下，VLMs也被证明会出现幻觉（Zhou等人，2023b）。基于视觉的语言生成出现幻觉的一个常见原因是过度依赖训练数据中对象和视觉线索的共现。完全依赖预训练的LLMs或VLMs并使用有限的环境特定微调的AI智能体可能特别容易受到幻觉的影响，因为它们依赖于预训练模型的内部知识库来生成动作，并且可能无法准确理解它们部署的世界状态的动态。

2.2.2 偏见和包容性

基于LLMs或LMMs（大型多模态模型）的AI智能体由于设计和训练过程中固有的几个因素而存在偏见。在设计这些AI智能体时，我们必须注意包容性，并意识到所有最终用户和利益相关者的需求。在AI智能体的背景下，包容性指的是所采用的措施和原则，以确保智能体的响应和交互对来自不同背景的广泛用户是包容的、尊重的和敏感的。我们列出了智能体偏见和包容性的关键方面如下。

训练数据：基础模型是在从互联网收集的大量文本数据上训练的，包括书籍、文章、网站和其他文本来源。这些数据经常反映人类社会中存在的偏见，模型可能会无意中学习并再现这些偏见。这包括与种族、性别、族裔、宗教和其他个人属性相关的刻板印象、偏见和倾斜的观点。特别是，通过在互联网数据上训练，通常只使用英文文本，模型隐含地学习了西方、受过教育、工业化、富裕和民主（WEIRD）社会的文化规范，这些社会在互联网上的存在比例过大。然而，必须认识到由人类创建的数据集不可能完全没有偏见，因为它们经常反映社会偏见和最初生成和/或编译数据的个体的倾向。

历史和文化偏见：AI模型是在来自不同文化的各种内容的大型数据集上训练的。因此，训练数据通常包括历史文本或来自不同文化的材料。特别是，来自历史来源的训练数据可能包含代表特定社会文化规范、态度和偏见的冒犯性或贬义语言。这可能导致模型延续过时的刻板印象或不完全理解当代文化转变和细微差别。

语言和上下文限制：语言模型可能难以理解和准确表示语言的细微差别，如讽刺、幽默或文化参考。这可能导致在某些上下文中的误解或有偏见的响应。此外，有许多口语方面的内容并未通过纯文本数据捕获，导致人类对语言的理解与模型理解语言之间可能存在潜在的脱节。

政策和指导方针：AI智能体在严格的政策和指导方针下运作，以确保公平和包容性。例如，在生成图像时，有规则要多样化对人的描绘，避免与种族、性别和其他属性相关的刻板印象。

过度概括：这些模型倾向于根据训练数据中看到的模式生成响应。这可能导致过度概括，其中模型可能产生看似对某些群体的刻板印象或做出广泛假设的响应。

持续监测和更新：AI系统持续监测和更新，以解决任何新出现的偏见或包容性问题。用户反馈和AI伦理研究的持续进展在这一过程中起着至关重要的作用。

放大主导观点：由于训练数据通常包括来自主导文化或群体的更多内容，模型可能更倾向于这些观点，潜在地代表或错误地代表少数派观点。

道德和包容性设计：AI工具应该以道德考虑和包容性为核心原则进行设计。这包括尊重文化差异，促进多样性，并确保AI不会延续有害的刻板印象。

用户指南：用户也被指导如何以促进包容性和尊重的方式与AI互动。这包括避免可能导致有偏见或不适当的输出的请求。此外，它可以帮助减少模型从用户交互中学习有害材料。

尽管有这些措施，AI智能体仍然表现出偏见。智能体AI研究和开发中的持续努力集中在进一步减少这些偏见，并增强智能体AI系统的包容性和公平性。减轻偏见的努力：

多样化和包容性训练数据：努力在训练数据中包括更多样化和包容性的各种来源。

偏见检测和纠正：持续研究侧重于检测和纠正模型响应中的偏见。

道德指导方针和政策：模型通常受道德指导方针和政策的约束，旨在减轻偏见并确保尊重和包容的交互。

多样化代表：确保AI智能体生成或提供的内容包括广泛的人类经验、文化、种族和身份。这在图像生成或叙事构建等场景中特别相关。

偏见减轻：积极努力减少AI响应中的偏见。这包括与种族、性别、年龄、残疾、性取向和其他个人特征相关的偏见。目标是提供公平和平衡的响应，不延续刻板印象或偏见。

文化敏感性：AI设计为对文化敏感，承认和尊重文化规范、实践和价值观的多样性。这包括理解和适当回应文化参考和细微差别。

可访问性：确保AI智能体对不同能力的用户都是可访问的，包括那些有残疾的人。这可能涉及纳入使视觉、听觉、运动或认知障碍人士更容易进行交互的功能。

基于语言的包容性：为多种语言和方言提供支持，以迎合全球用户群体，并在语言的细微差别和变化中保持敏感（Liu等人，2023b）。

道德和尊重的交互：智能体被编程为与所有用户以道德和尊重的方式进行交互，避免可能被视为冒犯、有害或不尊重的响应。

用户反馈和适应：整合用户反馈，不断改进AI智能体的包容性和有效性。这包括从交互中学习，以更好地理解和服务多样化的用户群体。

遵守包容性指南：遵守AI智能体中为包容性设定的既定指南和标准，通常由行业团体、伦理委员会或监管机构设定。

尽管有这些努力，重要的是要意识到响应中偏见的潜力，并以批判性思维来解释它们。随着AI智能体技术和道德实践的持续改进，旨在随着时间的推移减少这些偏见。智能体AI中包容性的总体目标之一是创建一个尊重和可访问的智能体，无论用户背景或身份如何。

2.2.3 数据隐私和使用

AI智能体的一个关键伦理考虑涉及理解这些系统如何处理、存储和可能检索用户数据。我们讨论以下关键方面：

数据收集、使用和目的。当使用用户数据来提高模型性能时，模型开发人员可以访问AI智能体在生产中与用户交互时收集的数据。一些系统允许用户通过用户帐户或向服务提供商提出请求来查看他们的数据。了解AI智能体在这些交互期间收集了哪些数据非常重要。这可能包括文本输入、用户使用模式、个人偏好，有时还包括更敏感的个人信息。用户还应该了解从他们交互中收集的数据的使用方式。如果AI对某个人或群体持有错误的信息，一旦识别出来，应该有机制让用户帮助更正。这对于准确性和尊重所有用户和群体都很重要。检索和分析用户数据的常见用途包括改善用户交互、个性化响应和系统优化。对于开发人员来说，非常重要的是确保数据不被用于用户未同意的目的，如未经请求的营销。

存储和安全。开发人员应该知道用户交互数据存储在哪里，以及采取了哪些安全措施来保护数据免受未经授权的访问或违规。这包括加密、安全服务器和数据保护协议。确定代理数据是否与第三方共享，以及在什么条件下共享，非常重要。这应该是透明的，通常需要用户同意。

数据删除和保留。用户了解用户数据存储多长时间以及如何请求删除数据也很重要。许多数据保护法律赋予用户被遗忘的权利，意味着他们可以请求删除他们的数据。AI智能体必须遵守像欧盟的GDPR或加利福尼亚的CCPA这样的数据保护法律。这些法律管理数据处理实践和用户对其个人数据的权利。

数据可携带性和隐私政策。此外，开发人员必须创建AI智能体的隐私政策，以记录并向用户解释如何处理他们的数据。这应该详细说明数据收集、使用、存储和用户权利。开发人员应确保在收集数据时获得用户同意，特别是对于敏感信息。用户通常有选择退出或限制他们提供的数据的选项。在某些司法管辖区，用户甚至可能有权要求以可以转移到另一个服务提供商的格式获取他们的数据副本。

匿名化。用于更广泛分析或AI训练的数据应该理想地匿名化，以保护个人身份。开发人员必须了解他们的AI智能体如何在交互中检索和使用历史用户数据。这可能用于个性化或提高响应的相关性。

总结，理解AI智能体的数据隐私涉及了解用户数据如何被收集、使用、存储和保护，并确保用户了解他们关于访问、更正和删除其数据的权利。了解用户和AI智能体的数据检索机制对于全面理解数据隐私也至关重要。

2.2.4 可解释性和解释性

模仿学习 → 解耦。智能体通常使用强化学习（RL）或模仿学习（IL）中的连续反馈循环进行训练，从随机初始化的策略开始。然而，这种方法在获得不熟悉环境中的初始奖励方面面临挑战，特别是当奖励稀缺或仅在长步交互结束时可用时。因此，一个更优的解决方案是使用通过IL训练的无限记忆智能体，它可以从专家数据中学习策略，通过紧急基础设施改善探索和利用未见环境空间，如图3所示。具有帮助智能体更好地探索和利用未见环境空间的专家特征。智能体AI，可以直接从专家数据中学习策略和新的范式流程。

传统的IL有一个智能体模仿专家演示者的行为来学习策略。然而，直接学习专家策略并不总是最佳方法，因为智能体可能无法很好地泛化到未见情况。为了解决这个问题，我们提出学习一个具有上下文提示或隐式奖励函数的智能体，以捕获专家行为的关键方面，如图3所示。这为具有无限记忆的智能体配备了物理世界行为数据，用于任务执行，从专家演示中学习。它有助于克服现有模仿学习的缺点，如需要大量的专家数据和在复杂任务中潜在的错误。智能体AI的关键思想有两个部分：1）收集物理世界专家演示作为状态-动作对的无限智能体；2）模仿智能体生成器的虚拟环境。模仿智能体产生模仿专家行为的动作，而智能体通过减少专家动作与通过学习策略生成的动作之间的差异的损失函数来学习从状态到动作的策略映射。

解耦 → 泛化。智能体不是依赖于特定任务的奖励函数，而是从专家演示中学习，提供各种状态-动作对，涵盖各种任务方面。然后，智能体学习一个将状态映射到动作的策略，通过模仿专家的行为。模仿学习中的解耦指的是将学习过程与特定任务的奖励函数分开，允许策略在不同任务中泛化，而不需要显式依赖于特定任务的奖励函数。通过解耦，智能体可以从专家演示中学习，并学习一个能够适应各种情况的策略。解耦使迁移学习成为可能，其中一个领域中学习的策略可以适应其他领域，只需最小的微调。通过学习一个不与特定奖励函数绑定的通用策略，智能体可以利用在一个任务中获得的知识，在其他相关任务中表现良好。由于智能体不依赖于特定的奖励函数，它可以适应奖励函数或环境的变化，而无需显著的重新训练。这使得学习到的策略更加健壮和泛化，适用于不同的环境。在这种情况下，解耦指的是学习过程中两个任务的分离：学习奖励函数和学习最优策略。
图3：使用智能体识别与图像相关的文本的紧急交互机制的示例。任务涉及使用来自网络的多模态AI智能体和人类注释的知识交互样本，以纳入外部世界信息。

泛化 → 紧急行为。泛化解释了如何从更简单的组件或规则中产生紧急属性或行为。关键思想在于识别支配系统行为的基本元素或规则，例如单个神经元或基本算法。因此，通过观察这些简单组件或规则如何相互作用。这些组件的相互作用通常会导致复杂行为的出现，这些行为通过检查单个组件本身是无法预测的。在不同复杂性水平上的泛化允许系统学习适用于这些水平的一般原则，导致紧急属性的出现。这使系统能够适应新情况，展示从更简单规则中出现的更复杂行为的紧急性。此外，跨不同复杂性水平的泛化能力有助于从一个领域向另一个领域转移知识，这有助于在新环境中适应时，在新情境中出现复杂行为。

2.2.5 推理增强

AI智能体的推理能力在于其根据训练和输入数据进行解释、预测和响应的能力。虽然这些能力先进且持续改进，但重要的是要认识到它们的局限性以及它们所训练的基础数据的影响。特别是在大型语言模型的背景下，它指的是其根据所训练的数据和接收到的输入进行结论推断、预测和生成响应的能力。AI智能体中的推理增强指的是通过额外的工具、技术或数据来提高AI的自然推理能力，以提高其性能、准确性和实用性。在复杂的决策场景或处理微妙或专业内容时，这可能特别重要。我们特别指出推理增强的以下重要来源：

数据丰富。整合额外的、通常是外部的数据源，以提供更多上下文或背景，可以帮助AI智能体做出更明智的推断，特别是在其训练数据可能有限的领域。例如，AI智能体可以从对话或文本的上下文中推断出含义。它们分析给定信息，并利用它来理解用户查询的意图和相关细节。这些模型擅长识别数据中的模式。它们利用这种能力，根据在训练过程中学到的模式，对语言、用户行为或其他相关现象进行推断。

算法增强。改进AI的基础算法以进行更好的推理。这可能涉及使用更先进的机器学习模型，整合不同类型的AI（如将NLP与图像识别结合起来），或更新算法以更好地处理复杂任务。在语言模型中的推理涉及理解和生成人类语言。这包括把握细微差别，如语气、意图和不同语言结构的微妙之处。

人类参与（HITL）。在需要人类判断的领域，如伦理考虑、创意任务或模糊场景中，引入人类输入以增强AI的推理可能特别有用。人类可以提供指导、纠正错误或提供智能体本身无法推断的见解。

实时反馈整合。使用来自用户或环境的实时反馈来增强推理是提高性能的另一种有前途的方法。例如，AI可以根据实时用户响应或动态系统中的变化条件调整其建议。或者，如果智能体在模拟环境中采取的行动违反了某些规则，智能体可以动态地获得反馈，以帮助纠正自己。

跨领域知识转移。利用一个领域的知识或模型来改善另一个领域的推理可能特别有助于在专业学科内产生输出。例如，为语言翻译开发技术可能被应用于代码生成，或从医学诊断中获得的见解可以增强机械的预测性维护。

针对特定用例的定制。针对特定应用程序或行业的AI推理能力的定制可能涉及在特定领域数据上训练AI或微调其模型，以更好地适应特定任务，如法律分析、医学诊断或金融预测。由于一个领域内的语言或信息可能与另一个领域大不相同，因此在特定领域的信息上微调智能体可能是有益的。

伦理和偏见考虑。重要的是确保增强过程不会引入新的偏见或伦理问题。这涉及到对额外数据来源的仔细考虑或新推理增强算法对公平性和透明度的影响。在进行推理时，特别是在涉及敏感话题时，AI智能体必须有时需要考虑伦理问题。这涉及避免有害的刻板印象、尊重隐私并确保公平。

持续学习和适应。定期更新和完善AI的能力，以跟上新的发展、不断变化的数据格局和不断演变的用户需求。

总结，AI智能体中的推理增强涉及通过额外的数据、改进的算法、人类输入和其他技术来增强它们的自然推理能力的方法。根据用例，这种增强通常对于处理复杂任务和确保智能体输出的准确性至关重要。

2.2.6 监管

最近，智能体AI取得了显著进展，其在具身系统中的整合为通过更沉浸式、动态和引人入胜的体验与智能体交互开辟了新的可能性。为了加速这一进程并减轻智能体AI开发中的繁琐工作，我们提议开发下一代AI赋能的智能体交互管道。开发一个人机协作系统，人类和机器可以在其中进行有意义地通信和交互。该系统可以利用LLM或VLM的对话能力，与人类玩家进行交流，并识别人类需求。然后，它将根据请求执行适当的行动来帮助人类玩家。

在使用LLM/VLM进行人机协作系统时，重要的是要注意这些系统作为黑盒运行，生成不可预测的输出。这种不确定性在物理设置中可能变得至关重要，例如操作实际的机器人。解决这一挑战的方法之一是通过提示工程限制LLM/VLM的关注点。例如，在机器人任务规划指令中，提供环境信息的提示已被报告比仅依赖文本产生更稳定的输出（Gramopadhye和Szafir，2022）。这一报告得到了Minsky的AI框架理论的支持（Minsky，1975），该理论表明LLM/VLM要解决的问题空间由给定的提示定义。另一种方法是设计提示，使LLM/VLM包括解释性文本，使用户能够理解模型已关注或识别的内容。此外，实施一个更高层次，允许在人类指导下进行预执行验证和修改，可以促进在这种指导下工作的系统的运作（图4）。

2.3 智能体AI用于紧急能力

尽管交互式智能体AI系统的采用日益增长，但大多数提出的方法在未见环境或场景中的泛化性能方面仍面临挑战。当前的建模实践要求开发人员为每个领域准备大型数据集以微调/预训练模型；然而，这个过程成本高昂，如果领域是新的，甚至是不可能的。为了解决这个问题，我们构建了利用通用基础模型（如ChatGPT、Dall-E、GPT-4等）的知识记忆的交互式智能体，用于新场景，特别是用于生成人类和智能体之间的协作空间。我们发现了一个紧急机制——我们称之为知识推理交互的混合现实——它促进了与人类的协作，以解决复杂现实世界环境中的具有挑战性的任务，并使探索未见环境以适应虚拟现实成为可能。对于这种机制，智能体学习了i）跨模态的微观反应：从显式网络源收集每个交互任务的相关个体知识（例如，理解未见场景）通过隐式推断预训练模型的输出；ii）现实不可知的宏观行为：提高语言和多模态领域的交互维度和模式，并根据角色、特定目标变量、混合现实中协作信息的多样化影响进行更改。我们研究了知识引导的交互协同效应任务，以协作场景生成结合各种OpenAI模型，并展示了交互式智能体系统如何进一步增强大型基础模型的有希望的结果。

3 智能体AI范式

在本节中，我们讨论了智能体AI训练的新范式和框架。我们希望通过我们提出的框架实现几个目标：

利用现有的预训练模型和预训练策略，有效地引导我们的智能体，使其对重要模态（如文本或视觉输入）有有效的理解。

支持充分的长期任务规划能力。

整合一个框架，允许编码和检索学习到的知识。

允许环境反馈被用来有效地训练智能体采取哪些行动。

我们在图5中展示了这样一个系统的高级新智能体图，概述了这样一个系统的重要子模块。

3.1 LLMs和VLMs

我们可以使用LLM或VLM模型来引导智能体的组件，如图5所示。特别是，LLMs已被证明在任务规划（Gong等人，2023a）、包含重要的世界知识（Yu等人，2023b）以及展示令人印象深刻的逻辑推理能力（Creswell等人，2022）方面表现良好。此外，像CLIP这样的VLMs（Radford等人，2021）提供了一个与语言对齐的通用视觉编码器，以及零样本视觉识别能力。例如，最先进的开源多模态模型，如LLaVA（Liu等人，2023c）和InstructBLIP（Dai等人，2023），依赖于冻结的CLIP模型作为视觉编码器。

3.2 智能体变换器定义

与其使用冻结的LLMs和VLMs作为AI智能体，也可以使用单一的智能体变换器模型，该模型以视觉标记和语言标记作为输入，类似于Gato（Reed等人，2022）。除了视觉和语言，我们增加了第三种一般类型的输入，我们称之为智能体标记。从概念上讲，智能体标记用于保留模型输入和输出空间的特定子空间，用于智能体行为。对于机器人技术或游戏玩法，这可能表示控制器的输入动作空间。当训练智能体使用特定工具，如图像生成或图像编辑模型，或进行其他API调用时，也可以使用智能体标记。如图7所示，我们可以将智能体标记与视觉和语言标记结合起来，为训练多模态智能体AI生成统一接口。与使用大型专有LLMs作为智能体相比，使用智能体变换器有几个优点。首先，该模型可以轻松定制以适应可能难以用自然语言表示的特定智能体任务（例如控制器输入或其他特定动作）。因此，智能体可以从环境交互和领域特定数据中学习，以提高性能。其次，通过访问智能体标记的概率，可以更容易地理解模型为何采取或不采取特定行动。第三，某些领域，如医疗保健和法律，有严格的数据隐私要求。最后，一个相对较小的智能体变换器可能显著便宜于一个更大的专有语言模型。

3.3 智能体变换器创建

如上文图5所示，我们可以使用LLM和VLM引导的智能体，以及利用大型基础模型生成的数据来训练智能体变换器模型，学习执行特定目标。在这个过程中，智能体模型被训练为专门针对特定任务和领域的定制。这种方法允许您利用现有的基础模型学习到的特征和知识。我们在下面两步中展示了这个过程的简化概述：

在领域内定义目标。为了训练智能体变换器，需要明确定义智能体在每个特定环境的上下文中的目标和动作空间。这包括确定智能体需要执行哪些特定任务或动作，并为每个分配唯一的智能体标记。此外，任何可以用于识别任务成功完成的自动规则或程序都可以显著提高可用于训练的数据量。否则，将需要基础模型生成或人工注释的数据来训练模型。

持续改进。持续监控模型的性能并收集反馈是过程中的重要步骤。反馈应用于进一步的微调和更新。同样重要的是确保模型不会延续偏见或不道德的结果。这需要仔细检查训练数据，定期检查输出中的偏见，并在需要时训练模型以识别和避免偏见。一旦模型达到令人满意的性能，就可以部署用于预期的应用。持续监控仍然至关重要，以确保模型按预期执行，并促进必要的调整。有关此过程的更多详细信息、训练数据来源和有关智能体AI持续学习的详细信息，请参见第8节。

4 智能体AI学习

4.1 策略和机制

交互式AI在不同领域的策略，扩展了调用大型基础模型的范式，通过训练的智能体积极寻求收集用户反馈、行动信息、有用的知识，用于生成和交互。有时，LLM/VLM模型不需要再次训练，我们可以通过在测试时提供改进的上下文提示来提高它们的性能，用于智能体。另一方面，它总是涉及通过三重系统进行知识/推理/常识/推理交互建模 - 一个执行多模态查询的知识检索，第二个执行相关智能体的交互生成，最后一个是训练一个新的、信息丰富的自监督训练或通过强化学习或模仿学习改进的方式。

4.1.1 强化学习（RL）

有着丰富的利用强化学习（RL）训练交互式智能体展现智能行为的历史。RL是一种基于奖励（或惩罚）学习状态和动作之间最佳关系的方法。RL是一个高度可扩展的框架，已应用于众多应用，包括机器人技术，但它通常面临几个挑战，LLM/VLMs已显示出它们缓解或克服其中一些困难的潜力：

奖励设计 策略学习的效率在很大程度上取决于奖励函数的设计。设计奖励函数不仅需要RL算法的知识，还需要对任务性质的深入理解，因此通常需要基于专家经验制定该函数。几项研究探索了使用LLM/VLM进行奖励设计的方法（Yu等人，2023a；Katara等人，2023；Ma等人，2023）。

数据收集和效率 鉴于其探索性质，基于RL的政策学习需要大量的数据（Padalkar等人，2023）。当政策涉及管理长序列或整合复杂动作时，对大量数据的需求尤为明显。这是因为这些场景需要更微妙的决策制定和从更广泛的情况中学习。在最近的研究中，为了支持政策学习，已经努力增强数据生成（Kumar等人，2023；Du等人，2023）。此外，在一些研究中，这些模型已经被整合到奖励函数中以改善政策学习（Sontakke等人，2023）。与这些发展平行的是，另一系列研究集中于使用VLMs（Tang等人，2023；Li等人，2023d）和LLMs（Shi等人，2023）在学习过程中实现参数效率。

长期步骤 与数据效率问题相关，随着动作序列长度的增加，RL变得更加具有挑战性。这是由于行动和奖励之间关系的模糊性，即信用分配问题，以及需要探索的状态数量的增加，这需要大量的时间和数据。对于长期和复杂任务的一种典型方法是将它们分解为一系列子目标，并应用预训练的政策来解决每个子目标（例如，Takamatsu等人，2022）。这个想法属于任务和运动规划（TAMP）框架（Garrett等人，2021）。TAMP由两个主要组成部分组成：任务规划，即确定高级动作序列；运动规划，涉及寻找物理上一致的、无碰撞的轨迹以实现任务计划的目标。LLMs非常适合TAMP，最近的研究报告经常采用一种方法，即使用LLMs执行高级任务规划，而低级控制则通过基于RL的政策解决（Xu等人，2023；Sun等人，2023a；Li等人，2023b；Parakh等人，2023）。LLMs的高级能力使它们能够有效地将即使是抽象指令分解为子目标（Wake等人，2023c），有助于提高机器人系统中的语言理解能力。

4.1.2 模仿学习（IL）

虽然RL旨在通过探索性行为和通过与环境的交互最大化奖励来训练策略，但模仿学习（IL）寻求利用专家数据来模仿经验丰富的智能体或专家的行动。例如，在机器人技术中，基于IL的主要框架之一是行为克隆（BC）。BC是一种通过直接复制来训练机器人模仿专家行动的方法。在这种方法中，记录了专家在执行特定任务中的行动，机器人被训练在类似情况下复制这些行动。基于BC的方法经常结合LLM/VLMs技术，实现了更高级的端到端模型。例如，Brohan等人提出了RT-1（Brohan等人，2022）和RT-2（Brohan等人，2023），基于变换器的模型，它们以一系列图像和语言作为输入，输出基础和手臂的动作序列。这些模型被报告显示出高泛化性能，这是由于在大量训练数据上训练的结果。

4.1.3 传统RGB

利用图像输入学习智能体行为多年来一直是一个感兴趣的领域（Mnih等人，2015）。使用RGB输入的固有挑战是维度的诅咒。为了解决这个问题，研究人员要么使用更多的数据（Jang等人，2022；Ha等人，2023），要么在模型设计中引入归纳偏差以提高样本效率。特别是，作者将3D结构纳入模型架构以进行操作（Zeng等人，2021；Shridhar等人，2023；Goyal等人，2023；James和Davison，2022）。对于机器人导航，作者（Chaplot等人，2020a，b）利用地图作为表示。地图可以是通过聚合所有先前RGB输入的神经网络学习得到的，也可以通过3D重建方法如神经辐射场（Rosinol等人，2022）获得。

为了获得更多的数据，研究人员使用图形模拟器合成合成数据（Mu等人，2021；Gong等人，2023b），并尝试缩小仿真到现实的差距（Tobin等人，2017；Sadeghi和Levine，2016；Peng等人，2018）。最近，有一些集体努力策划大规模数据集，旨在解决数据稀缺问题（Padalkar等人，2023；Brohan等人，2023）。另一方面，为了提高样本复杂性，数据增强技术也得到了广泛的研究（Zeng等人，2021；Rao等人，2020；Haarnoja等人，2023；Lifshitz等人，2023）。

4.1.4 上下文学习

上下文学习被证明是一种有效的方法，可以在NLP中解决任务，这得益于像GPT-3这样的大型语言模型的出现（Brown等人，2020；Min等人，2022）。少数示例提示被视为通过在LLM提示中提供任务示例来有效地使模型输出上下文化，用于NLP中的各种任务。上下文示例的多样性和质量可能会提高模型输出的质量（An等人，2023；Dong等人，2022）。在多模态基础模型的背景下，像Flamingo和BLIP-2这样的模型（Alayrac等人，2022；Li等人，2023c）在只给出少量示例的情况下，已被证明在各种视觉理解任务中有效。通过在环境中整合特定于环境的反馈，可以进一步改进智能体在环境中的上下文学习，以响应某些行动（Gong等人，2023a）。

4.1.5 智能体系统中的优化

智能体系统的优化可以分为空间和时间方面。空间优化考虑智能体如何在物理空间内操作以执行任务。这包括机器人之间的协调、资源分配和保持有序的空间。

为了有效地优化智能体AI系统，特别是那些大量智能体并行行动的系统，以前的工作集中在使用大型批量强化学习（Shacklett等人，2023）。由于特定任务的多智能体交互数据集很少，自玩游戏强化学习使一队智能体能够随着时间的推移而提高。然而，这也可能导致非常脆弱的智能体，它们只能在自玩游戏下工作，而不是与人类或其他独立智能体一起，因为它们过度适应自玩游戏训练范式。为了解决这个问题，我们可以发现一组多样化的约定（Cui等人，2023；Sarkar等人，2023），并训练一个智能体，它了解广泛的约定。基础模型还可以帮助与人类或其他独立智能体建立约定，实现与新智能体的顺畅协调。

另一方面，时间优化侧重于智能体如何随着时间执行任务。这包括任务调度、排序和时间线效率。例如，优化机器人手臂的轨迹是高效优化连续任务之间运动的一个例子（Zhou等人，2023c）。在任务调度层面，像LLM-DP（Dagan等人，2023）和ReAct（Yao等人，2023a）这样的方法已被提出，通过交互式地整合环境因素来解决有效任务规划。

4.2 智能体系统（零样本和少样本水平）

4.2.1 智能体模块

我们对智能体范式的探索包括使用LLMs或VLMs开发交互式多模态智能体的智能体AI“模块”。我们的初始智能体模块促进训练或上下文学习，并采用简约设计，以展示智能体在调度和协调方面的有效能力。我们还探索了初始基于提示的内存技术，以促进更好的规划，并在领域内提供对未来行动的方法。例如，我们的“MindAgent”基础设施由5个主要模块组成：1）环境感知与任务规划，2）智能体学习，3）内存，4）通用智能体动作预测，5）认知，如图5所示。

4.2.2 智能体基础设施

基于智能体的AI是在娱乐、研究和工业领域内迅速增长的社区。大型基础模型的发展显著提高了智能体AI系统的性能。然而，以这种方式创建智能体受到创建高质量数据集和总体成本日益增加的限制。在微软，通过使用先进的硬件、多样化的数据来源和强大的软件库，构建高质量的智能体基础设施显著影响了多模态智能体协作伙伴。随着微软继续推动智能体技术的发展，AI智能体平台有望在未来几年内成为多模态智能领域的主导力量。尽管如此，智能体AI交互目前仍然是一个复杂的过程，需要结合多种技能。在大型生成性AI模型领域的最新进展有潜力大大减少交互内容的当前高成本和时间，无论是对于大型工作室，还是赋予较小的独立内容创作者设计超出他们目前能力的高质量体验。当前多模态智能体中的人类-机器交互系统主要是基于规则的。它们确实对人类/用户行为有智能行为，并在一定程度上具有网络知识。然而，这些交互通常受到软件开发成本的限制，以在系统中启用特定行为。此外，当前模型并未设计为在用户无法完成特定任务的情况下帮助人类实现目标。因此，需要一个智能体AI系统基础设施，以分析用户行为并在需要时提供适当的支持。

4.3 智能体基础模型（预训练和微调水平）

使用预训练的基础模型提供了显著的优势，因为它们在各种用例中具有广泛的适用性。这些模型的整合使得能够为各种应用程序开发定制解决方案，避免了为每个特定任务进行广泛的标记数据集的需求。

在导航领域，一个著名的例子是LM-Nav系统（Shah等人，2023a），它以新颖的方式整合了GPT-3和CLIP。它有效地使用由语言模型生成的文本地标，将它们锚定在机器人获取的图像中进行导航。这种方法展示了文本和视觉数据的无缝融合，显著增强了机器人导航的能力，同时保持了广泛的适用性。

在机器人操作方面，一些研究提出了使用现成的LLMs（例如，ChatGPT）同时使用开放词汇表对象检测器。结合LLM和高级对象检测器（例如，Detic（Zhou等人，2022））可以促进对人类指令的理解，同时将文本信息与场景信息结合（Parakh等人，2023）。此外，最新的进展展示了使用提示工程与高级多模态模型（如GPT-4V（ision））（Wake等人，2023b）的潜力。这种技术为多模态任务规划开辟了途径，强调了预训练模型在各种环境中的多功能性和适应性。

5 智能体AI分类

5.1 通用智能体领域

基于计算机的行动和通用智能体（GAs）对许多任务都很有用。在大型基础模型和交互式AI领域的最新进展，为GAs提供了新功能。然而，为了让GA真正对用户有价值，它必须是自然的交互对象，并且能够泛化到广泛的上下文和模态。我们在第6节中详细介绍了与这些主题相关的智能体基础AI的主要章节：

多模态智能体AI（MMA）是我们的研究和行业社区与更广泛的研究和技术社区在智能体AI中进行互动的新论坛。在大型基础模型和交互式AI领域的最新进展，为通用智能体（GAs）提供了新功能，例如在受限环境中预测用户行为和任务规划（例如，MindAgent（Gong等人，2023a）、细粒度多模态视频理解（Luo等人，2022）、机器人技术（Ahn等人，2022b；Brohan等人，2023）），或为用户提供聊天伴侣，该伴侣结合了知识反馈（例如，医疗系统的网站客户支持（Peng等人，2023））。下面展示了代表性作品和最新代表性作品的更多细节。我们希望讨论我们对未来MMA的愿景，并激励未来的研究人员在这个领域工作。本文和我们的论坛涵盖了以下主要主题，但不限于这些：

主题主题：多模态智能体AI，通用智能体AI

次要主题：具身智能体、行动智能体、基于语言的智能体、视觉和语言智能体、知识和推理智能体、游戏、机器人技术、医疗保健等领域的智能体。

扩展主题：视觉导航、模拟环境、重新排列、智能体基础模型、VR/AR/MR、具身视觉和语言。

接下来，我们列出了代表性智能体类别的特定列表，如下所示：

5.2 具身智能体

我们的生物大脑存在于身体中，我们的身体在不断变化的世界中移动。具身人工智能的目标是创建智能体，如机器人，它们学习创造性地解决需要与环境交互的具有挑战性的任务。虽然这是一个重大挑战，但深度学习和大量数据集（如ImageNet）的日益可用性使AI在以前认为棘手的各种任务上表现出超人的性能。计算机视觉、语音识别和自然语言处理在被动输入输出任务（如语言翻译和图像分类）上经历了变革性的革命，强化学习也在交互任务（如游戏玩法）上取得了世界级的性能。这些进步加速了具身AI的发展，使越来越多的用户能够快速取得进展，朝着能够与机器交互的智能体发展。

5.2.1 行动智能体

行动智能体指的是需要在模拟物理环境或现实世界中执行物理动作的智能体。特别是，它们需要积极参与与环境的活动。我们根据应用领域将行动智能体广泛分类为两类：游戏AI和机器人技术。

在游戏AI中，智能体会与游戏环境和其他独立实体进行交互。在这些设置中，自然语言可以促进智能体和人类之间的顺畅沟通。根据游戏的不同，可能有一个特定的任务要完成，提供了一个真正的奖励信号。例如，在竞争性的外交游戏中，使用人类对话数据训练语言模型以及使用RL的动作策略可以实现人类级别的游戏（Meta基础AI研究（FAIR）外交团队等人，2022）。

还有一些设置，我们智能体作为城镇中的普通居民（Park等人，2023a），而不是试图优化特定目标。在这些设置中，基础模型是有用的，因为它们可以通过模仿人类行为来模拟更自然的交互。当结合外部记忆时，它们产生了令人信服的智能体，可以进行对话、日常安排、建立关系，并拥有虚拟生活。

5.2.2 交互智能体

交互智能体简单地指可以与世界交互的智能体，这是比行动智能体更广泛的智能体类别。它们的交互形式并不一定需要物理动作，但可能涉及向用户传达信息或修改环境。例如，具身交互智能体可以通过对话回答用户关于某个主题的问题，或帮助用户解析现有信息，类似于聊天机器人。通过将智能体的能力扩展到包括信息共享，智能体AI的核心设计和算法可以有效地适应一系列应用程序，如诊断（Lee等人，2023）和知识检索（Peng等人，2023）智能体。

5.3 模拟和环境智能体

通过与环境的交互进行试错体验，是AI智能体学习如何在环境中行动的有效方法。代表性的方法是RL，它需要大量的失败经验来训练智能体。尽管存在使用物理智能体的方法（Kalashnikov等人，2018），但使用物理智能体既耗时又昂贵。此外，在物理环境中训练通常是可行的，当在实际环境中失败可能是危险的（例如，自动驾驶、水下车辆）。因此，使用模拟器来学习策略是一种常见的方法。

已经提出了许多模拟平台，用于具身AI研究，从导航（Tsoi等人，2022；Deitke等人，2020；Kolve等人，2017）到对象操纵（Wang等人，2023d；Mees等人，2022；Yang等人，2023a；Ehsani等人，2021）。一个例子是Habitat（Savva等人，2019；Szot等人，2021），它提供了一个3D室内环境，人类和机器人智能体可以在其中执行各种任务，如导航、指令跟随和问题回答。另一个代表性的模拟平台是VirtualHome（Puig等人，2018），支持3D室内环境中人类化身的对象操纵。在游戏领域，Carroll等人引入了“Overcooked-AI”，这是一个基准环境，旨在研究人类和AI之间的合作任务（Carroll等人，2019）。同样，一些工作旨在纳入智能体和环境交互之外的真实人类干预（Puig等人，2023；Li等人，2021a；Srivastava等人，2022）。这些模拟器有助于在实际环境中涉及智能体和机器人交互的策略学习，以及利用人类演示行为的基于IL的策略学习。

在某些场景中，学习策略的过程可能需要在模拟器中整合专业功能。例如，在学习基于图像的策略时，通常需要现实感渲染，以促进适应真实环境（Mittal等人，2023；Zhong等人，2023）。使用现实感渲染引擎对于生成反映各种条件的图像非常有效，如光照环境。此外，需要物理引擎的模拟器来模拟与对象的物理交互（Liu和Negru，2021）。将物理引擎整合到模拟中已被证明有助于获得适用于现实世界场景的技能（Saito等人，2023）。

5.4 生成智能体

在大型生成性AI模型领域的最新进展有潜力大大减少当前交互内容的高成本和时间，无论是对于大型游戏工作室，还是赋予较小的独立工作室创造超出他们目前能力的高质量体验。此外，将大型AI模型嵌入到沙盒环境中将允许用户创建自己的体验并以目前无法实现的方式表达他们的创造力。

这个智能体的目标不仅仅是向场景中添加交互式3D内容，还包括：

向对象添加任意行为和交互规则，使用户可以使用最少的提示创建自己的VR规则。

通过使用多模态GPT4-v模型以及其他涉及视觉AI模型的模型链，从一张纸上的草图生成整个级别的几何形状。

使用扩散模型重新制作场景中的内容。

根据简单的用户提示创建自定义着色器和视觉特效。

短期内的一个潜在应用是VR创建一个故事板/原型工具，允许单个用户比目前可行的方式快一个数量级地创建一个粗糙（但功能齐全）的体验/游戏的草图。然后，这个原型可以利用这些工具进行扩展和改进，使其更加完善。

5.4.1 AR/VR/混合现实智能体

AR/VR/混合现实（统称为XR）设置目前需要熟练的艺术家和动画师来创建角色、环境和对象，用于模拟虚拟世界中的交互。这是一个耗资巨大的过程，涉及概念艺术、3D建模、纹理、绑定和动画。XR智能体可以通过促进创作者之间的交互和构建工具来帮助构建最终的虚拟环境。

我们早期的实验已经展示了GPT模型可以在Unity引擎内（无需额外微调）在少数示例的情况下用于调用引擎特定方法，使用API调用从互联网下载3D模型并将它们放置到场景中，并为它们分配行为状态树和动画（Huang等人，2023a）。这种行为可能源于使用Unity的开源游戏存储库中存在的类似代码。因此，GPT模型能够根据简单的用户提示在场景中加载许多对象，构建丰富的视觉场景。

这类智能体的目标是构建一个平台和一套工具，提供大型AI模型（包括GPT家族模型以及扩散图像模型）与渲染引擎之间的高效接口。我们在这里探索两个主要途径：

将大型模型整合到智能体基础设施中的各种编辑工具中，以显著加速开发。

通过生成遵循用户指令的代码并在运行时编译，从用户体验中控制渲染引擎，使用户能够以任意方式编辑他们正在交互的VR/模拟，甚至引入新的智能体机制。

引入一个专注于XR设置的AI协作伙伴将对XR创作者有用，他们可以使用协作伙伴完成繁琐的任务，如提供简单的资产或编写代码样板，让创作者专注于他们的创意愿景并快速迭代想法。

此外，智能体可以帮助用户通过添加新资产、改变环境的动态性或构建新设置来交互式地修改环境。这种在运行时的动态生成也可以由创作者指定，使用户体验感觉新鲜，并随着时间的推移不断发展。

5.5 知识和逻辑推理智能体

推理和应用知识的能力是人类认知的一个定义特征，特别是在逻辑演绎和理解心理理论等复杂任务中尤为明显。对知识进行推理确保AI的响应和行动与已知事实和逻辑原则一致。这种一致性是维护AI系统信任和可靠性的关键机制，特别是在医疗诊断或法律分析等关键应用中。在这里，我们介绍了结合知识和推理的智能体，它们解决了智能和推理的具体方面。

5.5.1 知识智能体

知识智能体以两种方式推理其获得的知识系统：隐式和显式。隐式知识通常是像GPT系列这样的大型语言模型在大量文本数据上训练后所包含的，这些模型可以生成给人留下理解印象的响应，因为它们利用了在训练过程中隐式学习到的模式和信息。相反，显式知识是结构化的，并且可以直接查询，例如在知识库或数据库中找到的信息，这传统上被用来通过引用可验证的外部资源来增强AI推理能力。

尽管语言模型取得了进步，但它们的隐式知识是静态的，随着世界的发展而变得过时（Lewis等人，2020；Peng等人，2023）。这种限制需要整合持续更新的显式知识源，确保AI系统能够提供准确和及时的响应。隐式和显式知识的融合为AI智能体提供了更细微的理解和按上下文应用知识的能力，类似于人类智能（Gao等人，2022）。这种整合对于打造知识中心的AI智能体至关重要，它们不仅拥有信息，而且能够理解、解释和运用它，从而缩小了广泛学习和深刻知识之间的鸿沟（Marcus和Davis，2019；Gao等人，2020）。这些智能体旨在以灵活性和关于世界的动态信息进行推理，增强它们的鲁棒性和适应性（Marcus，2020）。

5.5.2 逻辑智能体

通常，逻辑智能体是一个系统组件，旨在应用逻辑推理来处理数据或解决特定于逻辑推理或逻辑任务的任务。在大型基础模型如GPT-4的背景下，逻辑智能体指的是专门设计来处理逻辑推理任务的组件或子模块。这些任务通常涉及理解和操作抽象概念、从给定前提中推导结论或解决需要结构化、逻辑方法的问题。广义上，像GPT-4这样的基础模型是在大量文本数据上训练的，并且学习执行广泛的任务，包括需要某种形式的逻辑推理的任务。因此，它们的逻辑推理能力被整合到整体架构中，它们通常没有明显孤立的“逻辑智能体”。虽然GPT-4和类似的模型可以执行涉及逻辑的任务，但它们的方法基本上与人类或传统基于逻辑的系统的运作方式不同。它们不遵循正式的逻辑规则或对逻辑有明确的理解；相反，它们基于从训练数据中学到的模式生成响应。因此，它们在逻辑任务中的表现可能是令人印象深刻的，但也可能是不一致的，或受到训练数据的性质和模型设计固有限制的限制。将单独的逻辑子模块嵌入架构的一个例子是（Wang等人，2023e），它通过解析文本为逻辑片段，并在标记嵌入中显式建模逻辑层次，修改了LLMs在预训练中使用的标记嵌入过程。

5.5.3 情感推理智能体

情感理解和共情是许多人类-机器交互中智能体的重要技能。例如，创建吸引人的对话智能体的一个重要目标是让智能体在最小化社会不适当或冒犯性输出的同时，表现出更多的情感和共情。为了推进对话智能体的这一目标，我们发布了具有共情能力的神经图像评论（NICE）数据集（Chen等人，2021），包含近二百万张图像和相应的人类生成评论以及一组人类情感注释。我们还提供了一种新的预训练模型 - 模拟情感生成图像评论（MAGIC）（Chen等人，2021），旨在为图像生成评论，条件是捕捉风格和情感的语言表示，并帮助生成更具共情、情感、吸引力和社会适当的评论。我们的实验表明，这种方法在训练更像人类和吸引人的图像评论智能体方面是有效的。开发具有情感理解能力的共情意识智能体是交互智能体的有希望的方向，重要的是要创建能够在广泛的群体和人群中理解情感的智能体，特别是考虑到许多当前的语言模型在情感理解和共情推理能力方面存在偏见（Mao等人，2022；Wake等人，2023d）。

5.5.4 神经符号智能体

神经符号智能体在神经元和符号的混合系统上运作（d'Avila Garcez和Lamb，2020）。解决自然语言中陈述的问题是一个挑战，因为它需要显式捕获输入中隐含的离散符号结构信息。然而，大多数通用神经序列模型并没有显式捕获这样的结构信息，限制了它们在这些任务上的性能。（Chen等人，2020）提出了一种新的编码器-解码器模型，基于结构化神经表示智能体，TP-N2F的编码器采用TPR“绑定”将自然语言符号结构编码到向量空间，解码器使用TPR“解绑”在符号空间中生成由关系元组表示的顺序程序，每个元组包括一个关系（或操作）和多个参数。

遵循指令的视觉-语言（VL）模型，如GPT-4，提供了一个灵活的接口，支持广泛的多模态任务，以零样本方式。然而，操作整个图像的接口并不直接使用户能够“指向”并访问图像内的特定区域。这种能力不仅对支持参考基础的VL基准测试很重要，对于需要精确图像内推理的实际应用也很重要。在（Park等人，2023b）中，我们构建了一个本地化视觉常识模型，允许用户指定（多个）区域作为输入。我们通过从大型语言模型（LLM）中采样本地常识知识来训练我们的模型：具体来说，我们提示一个LLM收集给定全局文字图像描述和本地文字区域描述的常识知识，这些描述是由一组VL模型自动生成的。这个流程是可扩展和完全自动化的，因为不需要对齐的或人类编写的图像和文本对。通过一个单独训练的评论模型选择高质量的示例，我们发现仅从图像扩展的本地常识语料库训练可以成功地将现有的VL模型蒸馏，以支持参考作为输入界面。实证结果和零样本设置中的人类评估表明，我们的蒸馏方法产生的VL推理模型比通过生成的指代表达式更精确。

5.6 LLMs和VLMs智能体

一些工作利用LLMs作为智能体执行任务规划（Huang等人，2022a；Wang等人，2023b；Yao等人，2023a；Li等人，2023a），并利用LLMs的大规模互联网规模领域知识和零样本规划能力执行代理任务，如规划和推理。最近的研究还利用LLMs进行机器人任务规划（Ahn等人，2022a；Huang等人，2022b；Liang等人，2022），通过将自然语言指令分解为子任务序列，无论是以自然语言形式还是Python代码形式，然后使用低级控制器执行这些子任务。此外，（Huang等人，2022b），（Liang等人，2022）和（Wang等人，2023a）还结合环境反馈来提高任务性能。还有一些工作展示了通用的、在大规模文本、图像和视频数据上训练的视觉对齐的大型语言模型的潜力，作为创建多模态智能体的基础，这些智能体是具身的，可以在各种环境中行动（Baker等人，2022；Driess等人，2023；Brohan等人，2023）。

6 智能体AI应用任务

6.1 游戏智能体

游戏为测试LLMs和VLMs的代理行为提供了独特的沙盒，推动了它们协作和决策能力的边界。我们特别描述了三个领域，这些领域突出了智能体与人类玩家和其他智能体交互的能力，以及它们在环境中采取有意义行动的能力。

6.1.1 NPC行为

在现代游戏系统中，非玩家角色（NPC）的行为主要由开发人员制定的预定义脚本决定。这些脚本包括基于游戏环境中的各种触发器或玩家行为的各种反应和交互。然而，这种脚本性质通常导致NPC行为可预测或重复，无法响应玩家的行动或游戏的动态环境。这种僵化阻碍了动态游戏环境中预期的沉浸体验。因此，人们越来越有兴趣利用LLMs为NPC行为引入自主性和适应性，使交互更加细腻和引人入胜。AI驱动的NPC可以学习玩家行为，适应不同的策略，并提供更具挑战性和不可预测性的游戏玩法体验。大型语言模型（LLMs）可以显著地促进游戏中NPC行为的演变。通过处理大量文本，LLMs可以学习模式并生成更多样化和类似人类的响应。它们可以被用来创建动态对话系统，使与NPC的交互更加引人入胜和不可预测。此外，LLMs可以根据玩家反馈和游戏数据进行训练，不断改进NPC行为，使它们更加符合玩家期望和游戏动态。

6.1.2 人类-NPC交互

人类玩家和NPC之间的交互是游戏体验的关键方面。传统的交互范式主要是一维的，NPC以预设的方式对玩家输入做出反应。这种限制扼杀了更有机和丰富的交互，类似于虚拟世界中的人类-人类交互。LLM和VLM技术的出现有望转变这一范式。通过利用这些技术，游戏系统可以分析和学习人类行为，提供更类似人类的交互。这不仅增强了游戏的现实感和参与度，还为探索和理解受控但复杂环境中的人机交互提供了平台。

6.1.3 基于智能体的游戏分析

游戏是日常生活的一部分，估计有世界人口的一半参与其中4。此外，它对心理健康有积极影响5。然而，当代游戏系统在与人类玩家的交互方面存在缺陷，因为它们的行为主要是由游戏开发人员手工制作的。这些预编程行为常常无法适应玩家的需求。因此，有必要在游戏系统中引入新的AI系统，这些系统可以分析玩家行为并在必要时提供适当的支持。智能交互系统有潜力彻底改变玩家与游戏系统的交互方式。NPC与玩家的交互不再受到游戏开发人员设计的限制规则的约束。它们有潜力无缝适应玩家的体验，提供及时反馈以丰富游戏体验，提升人机交互的协同作用。

6.1.4 游戏场景合成

场景合成是创建和增强沉浸式游戏环境的重要组成部分。它涉及自动或半自动生成游戏中的三维（3D）场景和环境。这个过程包括生成地形、放置对象、创建逼真的照明，有时甚至是动态天气系统。

现代游戏通常具有广阔的开放世界环境。手动设计这些景观可能非常耗时和资源密集。利用程序化或AI驱动技术自动生成地形可以以较少的手动努力产生复杂、逼真的景观。LLMs和VLMs可以利用互联网规模的知识制定规则，设计出视觉上令人印象深刻且独特的非重复景观。此外，LLMs和VLMs可以用于确保生成资产的语义一致性和可变性。在场景中放置建筑物、植被和其他元素，以一种现实和美学愉悦的方式，对于沉浸感至关重要。

VLMs和LLMs可以通过遵守预定义或学习到的规则和美学来协助对象放置，从而加快关卡设计过程。VLMs和LLMs可以进一步训练，以理解设计和美学的原则，帮助程序化生成内容。它们可以帮助制定规则或指导方针，程序化算法可以遵循这些规则来生成对象和场景，这些场景在视觉上都是吸引人的，并且在上下文中是适当的。

逼真的照明和大气效果对于创造一个可信和引人入胜的游戏环境至关重要。先进的算法可以模拟自然照明条件和动态天气效果，增强场景的现实感和氛围。

LLMs可以通过几种创新的方式帮助开发更逼真的照明和大气效果系统。VLMs可以分析大量真实世界的照明和大气条件数据，帮助开发更逼真的算法来模拟游戏中的这些效果。通过理解自然照明和天气的模式和细节，这些模型可以促进开发算法，以密切模仿现实。LLMs和VLMs还可以用于开发系统，根据玩家行为、游戏状态或外部输入实时调整照明和大气效果。它们可以处理玩家的自然语言命令来修改游戏环境，提供更具互动性和沉浸感的体验。

6.1.5 实验和结果

零样本/少样本学习与LLM或LVM。正如我们在图8和图9中所示，我们使用GPT-4V进行高级描述和动作预测。图8展示了GPT-4V在生成和编辑动作描述方面的一些定性示例。增强的智能文本为使用游戏动作先验生成3D场景开辟了一种新方法，有助于提高场景的自然性。因此，GPT-4V生成了适合游戏视频的相关高级描述。
图11：在Minecraft场景中使用小型智能体预训练模型进行低级下一步动作预测。

小型智能体预训练模型。为了展示我们的智能体视觉-语言架构，我们首先研究了它在游戏智能体广泛使用的领域中的应用，通过在Minecraft数据上进行预训练。如图7所示，给定一个输入动作智能体、视频的关键帧和相应的文本，可以采用标准编码器-解码器将智能体动作和图像转换为动作文本标记和图像补丁标记，然后使用智能体-视觉-语言解码器将其转换为动作预测句子。整体架构如图7所示。我们使用几个Minecraft演示来评估我们的方法。Minecraft视频数据由5分钟的片段组成，我们用于预训练的数据包含78K个视频，我们使用了5K个视频（占预训练数据的6%）进行第一轮预训练。我们在16个NVIDIA v100 GPU上训练了一个2.5亿参数的模型一天，并在图10和图11中可视化了我们的模型输出。图10显示了我们的相对小型智能体架构可以为在训练期间未见过的Minecraft场景产生合理的输出。图11显示了模型的预测与真实玩家动作的比较，表明我们的小型智能体模型具有潜在的低级理解能力。

多智能体基础设施。如图5所示的智能体范式，我们为一个名为“CuisineWorld”（Gong等人，2023a）的新游戏场景设计了一个新颖的基础设施。我们在图12中详细介绍了我们的方法。我们的基础设施利用GPT-4作为中央规划器，允许跨多个游戏领域进行多智能体协作。我们研究了系统的多智能体规划能力，并将基础设施部署到现实世界的视频游戏中，以展示其多智能体和人类-AI协作的有效性。此外，我们还介绍了“CuisineWorld”，这是一个基于文本的多智能体协作基准，提供了一个新的自动度量协作得分（CoS），以量化协作效率。

请参阅附录，以获取有关游戏描述、高级动作预测和GPT-4V提示的更多示例和详细信息。我们在附录B中展示了Bleeding Edge的示例，在附录C中展示了Microsoft Flight Simulator，在附录D中展示了ASSASSIN's CREED ODYSSEY，在附录E中展示了GEARS of WAR 4，在附录F中展示了Starfield。我们还在附录A中提供了一个详细的截图，展示了用于生成Minecraft示例的GPT4V的提示过程。

6.2 机器人技术

机器人是代表性的智能体，需要与其环境有效交互。在本节中，我们将介绍高效机器人操作的关键要素，回顾最新LLM/VLM技术已应用的研究主题，并分享我们最近研究的发现。

视觉运动控制。视觉运动控制指的是将视觉感知和运动动作整合到机器人系统中，以有效执行任务。这种整合至关重要，因为它使机器人能够解释来自环境的视觉数据，并相应地调整其运动动作以准确与环境交互。例如，在装配线上，配备视觉运动控制的机器人可以感知物体的位置和方向，并准确调整其操纵器与这些物体交互。这种能力对于确保机器人操作的精度和有效性至关重要，无论是在工业自动化还是协助老年人日常家务的各种应用中。此外，视觉运动控制在动态环境中适应变化时也是必不可少的，其中环境状态可能迅速变化，需要根据视觉反馈实时调整运动动作。

此外，在安全操作的背景下，视觉信息对于检测执行错误和确认每个机器人动作的前提和后提条件至关重要。在不受控制的环境中，如未知的家庭环境，机器人更有可能面临由于不可预测的因素（如家具形状变化、不同的照明和滑动）而导致的意外结果。仅以前馈方式执行预先计划的行动计划在这些设置中可能带来重大风险。因此，使用视觉反馈在每个步骤中不断验证结果是确保机器人系统稳健可靠操作的关键。

语言条件操纵。语言条件操纵涉及机器人系统根据语言指令解释和执行任务的能力。这对于创建直观和用户友好的人类-机器人交互界面至关重要。通过自然语言命令，用户可以以类似于人与人之间的通信方式指定目标和任务给机器人，从而降低操作机器人系统的障碍。在实际情况下，例如，用户可以指示服务机器人“从桌子上拿起红苹果”，机器人将解析该指令，识别所指的对象并执行拿起它的任务（Wake等人，2023c）。核心挑战在于开发强大的自然语言处理和理解算法，能够准确解释广泛的指令，从直接命令到更抽象的指令，使机器人能够将这些指令转换为可执行的任务。此外，确保机器人能够将这些指令泛化到不同的任务和环境中是提高它们在现实世界应用中的多样性和实用性的关键。

技能优化。最近的研究强调了LLMs在机器人任务规划中的有效性。然而，特别是涉及像抓取这样的物理交互的任务的最优执行，需要对环境有更深入的理解，这超出了仅仅解释人类指令。例如，机器人抓取需要精确的接触点（Wake等人，2023e）和臂姿势（Sasabuchi等人，2021）以有效执行后续动作。

6.2.1 LLM/VLM智能体机器人

最近的研究已经展示了LLM/VLM在涉及与环境和人类交互的机器人智能体方面的潜力。旨在利用最新LLM/VLM技术的研究主题包括：

多模态系统：最近的研究一直在积极开发整合最新LLM和VLM技术的端到端系统，作为输入信息的编码器。特别是，有一个显著的趋势是修改这些基础模型以处理多模态信息（Jiang等人，2022；Brohan等人，2023，2022；Li等人，2023d；Ahn等人，2022b；Shah等人，2023b；Li等人，2023e）。这种适应旨在指导机器人动作，基于语言指令和视觉提示，从而实现有效的具身化。

任务规划和技能训练：与端到端系统不同，基于任务和运动规划（TAMP）的系统首先计算高级任务计划，然后通过低级机器人控制实现它们，称为技能。

先进的语言处理能力LLMs已经证明了解释指令并将它们分解为机器人动作步骤的能力，极大地推进了任务规划技术（Ni等人，2023；Li等人，2023b；Parakh等人，2023；Wake等人，2023c）。对于技能训练，一些研究探索了使用LLMs/VLMs设计奖励函数（Yu等人，2023a；Katara等人，2023；Ma等人，2023）、生成数据以促进策略学习（Kumar等人，2023；Du等人，2023）或作为奖励函数的一部分（Sontakke等人，2023）。结合RL和IL等培训框架，这些努力将有助于开发高效的机器人控制器。

现场优化：在机器人技术中执行长期任务步骤可能很困难，因为不可预测和不可预测的环境条件。因此，机器人领域的一个重要挑战是动态适应和改进机器人技能，通过整合任务计划与实时环境数据。例如，（Ahn等人，2022b）提出了一种方法，通过视觉信息计算动作的可行性（即，可供性），并将其与计划任务进行比较。此外，还有一些方法专注于使LLMs能够输出任务步骤的前提和后提条件（例如，对象的状态及其相互关系），以优化其执行（Zhou等人，2023c）并检测前提错误以进行任务计划的必要修订（Raman等人，2023）。这些策略旨在通过整合环境信息并在任务计划或控制器层面调整机器人的动作，实现环境基础的机器人执行。

对话智能体：在创建对话机器人时，LLMs可以促进与人类的自然、上下文敏感的交互（Ye等人，2023a；Wake等人，2023f）。这些模型处理和生成模仿人类对话的响应，允许机器人参与有意义的对话。此外，LLMs在估计话语的概念（Hensel等人，2023；Teshima等人，2022）和情感属性（Zhao等人，2023；Yang等人，2023b；Wake等人，2023d）方面发挥着重要作用。这些属性有助于理解人类意图和有意义的手势生成，从而有助于人机通信的自然性和有效性。

导航智能体：机器人导航有着悠久的研究历史，专注于地图基础路径规划和同时定位和地图构建（SLAM）等核心方面，用于创建环境地图。这些功能已成为广泛使用的机器人中间件的标准，如机器人操作系统（ROS）（Guimarães等人，2016）。

虽然经典的导航技术在许多机器人应用中仍然普遍，但它们通常依赖于静态或预先创建的地图。最近，人们对于能够使机器人在更具挑战性的环境中导航的先进技术越来越感兴趣，利用了计算机视觉和自然语言处理领域的突破。一个代表性的任务是对象导航（Chaplot等人，2020a；Batra等人，2020；Gervet等人，2023；Ramakrishnan等人，2022；Zhang等人，2021），在这项任务中，机器人使用对象名称而不是地图坐标进行导航，这要求在环境中对对象名称进行视觉基础化。此外，最近还关注了在完全不熟悉的新环境中基于零样本基础模型进行导航的技术，即所谓的零样本对象导航（Gadre等人，2023；Dorbala等人，2023；Cai等人，2023）。此外，视觉-语言导航（VLN）（Anderson等人，2018a）是一个代表性任务，任务涉及通过自然语言指令在以前未见过的真实世界环境中导航代理（Shah等人，2023a；Zhou等人，2023a；Dorbala等人，2022；Liang等人，2023；Huang等人，2023b）。VLN解释句子而不是对象名称，例如“走到你左边的浴室。”，因此它需要更高的功能来解析输入文本（Wang等人，2019）。

基础模型的出现有助于发展这种适应性、即时导航技术，通过增强对人类语言指令的理解以及对环境信息的视觉解释。6.2.2节提供了代表性VLN研究的更详细解释。

6.2.2 实验和结果

越来越多的证据表明，最近的VLMs和LLMs在符号任务规划（例如，要做什么）方面具有有希望的能力。然而，每个任务都需要低级控制策略（例如，如何做）才能实现环境与智能体之间的成功交互。虽然强化学习和模仿学习是学习数据驱动策略的有希望的方法，但另一种有希望的方法是从人类那里直接获取策略，通过现场演示，这种方法称为从观察中学习（Wake等人，2021a；Ikeuchi等人，0）。在本节中，我们介绍了一项研究，我们使用ChatGPT进行任务规划，并通过将其参数化为可供性信息来丰富计划，以促进有效和精确的执行（图13）。

该管道由两个模块组成：任务规划和参数化。在任务规划中，系统输入语言指令和工作环境描述。这些指令以及一组预定义的机器人动作和输出规范被编译成一个综合提示，提供给ChatGPT，然后生成一系列分解任务及其文本描述（图13；左侧面板）。值得注意的是，我们采用了少样本方法，即ChatGPT没有在这项任务上进行训练，这在应用性方面提供了优势，因为它消除了硬件依赖的数据收集和模型训练的需要。此外，输出中的文本描述使用户能够检查并根据需要调整结果，这是安全和稳健操作的关键功能。图14显示了在VirtualHome（Puig等人，2018）上进行的代理模拟的定性结果。结果展示了合理的任务计划及其在调整输出方面的灵活性，表明了我们方法的广泛适用性。

虽然任务规划器确保了任务序列之间的连贯性，但在现实中成功的操作需要详细的参数。例如，抓取类型对于携带容器时溢出内容至关重要，这样的参数通常在模拟器中被忽略（见图14中抓取派的场景）。因此，在我们的机器人系统中，用户被要求直观地演示每个动作（图13；右侧面板）。任务有预定义的参数，这些参数对于执行是必要的，我们的视觉系统从视频中提取这些参数（Wake等人，2021b）。值得注意的是，我们的机器人系统不是为精确复制人类动作（即远程操作）而设计的，而是要处理变化多端的真实世界条件，例如对象位置的变化。因此，从人类演示中提取的参数不是精确的运动路径，而是指导有效环境移动的可供性信息（例如，用于避免碰撞的航点（Wake等人，2023a）、抓取类型（Wake等人，2023e）和上肢姿势（Sasabuchi等人，2021；Wake等人，2021a））。上肢的姿势在具有高自由度的机器人中至关重要，旨在为与操作机器人共存的人类假设可预测的姿势。赋予可供性的一系列任务被转换为通过强化学习获得的一系列可重用机器人技能，并由机器人执行（Takamatsu等人，2022）。

LLM支持的任务规划可以通过与VLMs整合扩展到更通用的机器人系统中。在这里，我们展示了一个例子，我们使用GPT-4V（ision）在多模态输入环境中扩展了前述任务规划器（图15），人类执行的动作旨在由机器人复制。在本文中，只显示了提示的部分内容。完整的提示可在microsoft.github.io/GPT4Vision-Robot-Manipulation-Prompts上找到。

该管道采用演示视频和文本，然后输出一系列机器人动作。视觉分析器旨在理解视频中人类执行的动作。我们使用GPT-4V并提供了一个提示，以人类之间的通信风格生成文本指令。图16展示了视频分析器的输出示例。接下来，场景分析器根据指令和视频数据的第一帧（或环境的图像）将预期工作环境编译为文本信息。这些环境信息包括由GPT-4V识别的对象名称列表、对象的可抓取属性以及对象之间的空间关系。尽管这些计算过程在GPT-4V内部是一个黑盒，但信息是基于GPT-4V的知识和图像/文本输入输出的。图17显示了我们的场景分析器的示例输出。如图所示，GPT-4V成功地选择了与操纵相关的对象。例如，在人类将垃圾箱重新定位到桌子上时，桌子被包含在输出中，而在打开冰箱的任务中，桌子被忽略了。这些结果表明，场景分析器根据人类的动作对场景信息进行了编码。我们提示GPT-4V解释对象选择过程的结果以及这些选择背后的原因。在实践中，我们发现这种方法产生了合理的输出。最后，基于给定的文本指令和环境信息，任务规划器输出一系列任务（Wake等人，2023c）。

6.3 医疗保健

在医疗保健领域，LLMs和VLMs可以作为诊断智能体、患者护理助手甚至治疗助手，但它们带来了独特的挑战和责任。AI智能体改善患者护理和挽救生命的巨大潜力同样存在被滥用或仓促部署可能危及全球数千万人的危险可能性。我们讨论了AI智能体在医疗保健背景下的一些有希望的途径，并讨论了面临的一些关键挑战。

诊断智能体。使用LLMs作为患者诊断的医疗聊天机器人最近引起了极大的关注，因为对医疗专家的需求很高，LLMs有助于分诊和诊断患者（Lee等人，2023）。对话智能体，特别是能够有效地向来自不同患者群体的广泛人群传达重要医疗信息的智能体，有潜力为历史上处于不利地位或边缘化的群体提供公平的医疗保健访问。此外，全球的医生和医疗系统普遍负担过重和资源不足，导致全球数亿人无法获得足够的医疗护理（世界卫生组织和世界银行，2015）。诊断智能体提供了一个特别有利的途径，可以改善数百万医疗保健，因为它们可以被构建为理解多种语言、文化和健康状况。最初的结果表明，具有医疗知识的LMMs可以通过利用大规模网络数据进行训练（Li等人，2023f）。尽管这是一个令人兴奋的方向，但诊断智能体的前景并非没有风险。我们在下一节中强调了医疗背景下幻觉的风险，以及潜在的解决方案路径。

知识检索智能体。在医疗背景下，模型幻觉特别危险，甚至可能导致严重的患者伤害或死亡，这取决于错误的严重程度。例如，如果患者错误地接受了他们实际上患有的疾病的诊断，认为他们没有疾病，可能会导致灾难性的结果。这些包括推迟或不适当的治疗，或者在某些情况下，完全缺乏必要的医疗干预。未诊断或误诊疾病可能带来的严重性可能导致医疗保健费用增加、延长治疗导致进一步的身体压力，以及在极端情况下，严重的伤害甚至死亡。因此，使用智能体更可靠地检索知识（Peng等人，2023）或以基于检索的方式生成文本（Guu等人，2020）的方法是具有前景的方向。将诊断智能体与医疗知识检索智能体配对，有可能显著减少幻觉，同时提高诊断对话智能体的响应质量和精确度。

远程医疗和远程监测。基于智能体的AI在远程医疗和远程监测领域也具有巨大的潜力，可以改善医疗保健的获取，改善医疗保健提供者和患者之间的沟通，以及提高效率和降低频繁的医生-患者互动的成本（Amjad等人，2023）。初级保健临床医生花费大量时间筛选患者消息、报告和电子邮件，这些通常对他们来说并不相关或不必要。有巨大的潜力可以支持智能体帮助从医生、患者和其他医疗保健提供者那里进行消息分诊，并帮助突出所有各方的重要消息。通过使智能体AI系统能够与患者、临床医生和其他AI智能体协调，有巨大的潜力可以彻底改变远程医疗和数字健康行业。

6.3.1 当前医疗保健能力

图像理解。我们在图19中展示了现代多模态智能体如GPT-4V在医疗保健领域的当前能力和局限性。我们可以看到，尽管GPT-4V具有显著的医院护理设备和程序的内部知识，但它并不总是对用户的更具指示性或诊断性的查询做出响应。

视频理解。我们从两个方面研究了VLM智能体在医疗视频理解中的性能。首先，我们调查了VLM智能体在临床空间中识别重要患者护理活动的能力。其次，我们探索了VLM在更技术性视频（如超声波）中的使用。具体来说，在图20中，我们展示了GPT-4V在医院护理和医疗视频分析方面的当前能力和局限性。

6.4 多模态智能体

视觉和语言理解的整合对于发展复杂的多模态AI智能体至关重要。这包括图像字幕、视觉问题回答、视频语言生成和视频理解等任务。我们旨在深入研究这些视觉-语言任务，探索它们在AI智能体背景下呈现的挑战和机遇。

6.4.1 图像-语言理解与生成

图像-语言理解是一项涉及用语言解释给定图像中的视觉内容并生成相关语言描述的任务。这项任务对于发展能够以更类似人类的方式与世界交互的AI智能体至关重要。其中一些最受欢迎的任务包括图像字幕（Lin等人，2014；Sharma等人，2018；Young等人，2014；Krishna等人，2016）、指代表达（Yu等人，2016；Karpathy等人，2014）和视觉问题回答（Antol等人，2015；Ren等人，2015；Singh等人，2019）。

最近，引入了一些知识密集型的视觉问题回答任务，如OKVQA（Marino等人，2019）、KBVQA（Wang等人，2015）、FVQA（Wang等人，2017）和WebQA（Chang等人，2021）。多模态智能体应该能够识别图像中的对象，理解它们之间的空间关系，生成关于场景的准确描述性句子，并使用推理技能处理知识密集型视觉推理。这不仅需要对象识别能力，还需要对空间关系、视觉语义的深入理解，以及将这些视觉元素映射到语言结构中的能力，并整合世界知识。

6.4.2 视频和语言理解与生成

视频-语言生成。视频字幕或视频讲故事是为视频帧流生成一系列连贯句子的任务。受到在视频和语言任务中成功使用的递归大型基础模型的启发，变体的智能体驱动增强模型在视频-语言生成任务上显示出有希望的结果。基本挑战在于，神经编码器-解码器模型的强性能并没有很好地泛化到视觉故事讲述中，因为这项任务需要完全理解每张图像的内容以及不同帧之间的关系。该领域的一个重要目标是创建一个智能体感知的文本合成模型，它可以有效地编码帧序列并生成主题连贯的多句子段落。

视频理解。视频理解将图像理解的范围扩展到动态视觉内容。这涉及到对视频中的帧序列的解释和推理，通常与伴随的音频或文本信息结合。一个智能体应该能够与视觉、文本以及音频模态的各种形式进行交互，展示其对视频内容的高级理解。该领域的任务包括视频字幕、视频问题回答和活动识别等。视频理解的挑战是多方面的。它们包括视觉和语言内容的时间对齐、处理长时间序列的帧以及解释随着时间展开的复杂活动。关于音频，智能体可以处理口语单词、背景噪音、音乐和语调，以理解视频内容的情绪、环境和微妙之处。

6.4.3 实验和结果

知识密集型模型：正如INK（Park等人，2022）和KAT（Gui等人，2022a）中介绍的，这是一个结合了人类注释所需知识的密集型神经知识任务，以支持知识密集型检索任务。

多模态智能体：对像Chameleon（Lu等人，2023）和MM-React（Yang等人，2023c）这样的多模态语言模型越来越感兴趣。

视觉指令调整：VCL（Gui等人，2022b）、Mini-GPT4（Zhu等人，2023）、MPLUG-OWL（Ye等人，2023b）、LSKD（Park等人，2023c）生成图像级指令调整数据集。

知识密集型智能体。如图22和图23所示，基于知识的可视化问题回答和视觉-语言检索任务是多模态机器学习中具有挑战性的任务，需要超出图像内容的外部知识。最近对大规模变换器的研究主要集中在最大化模型参数存储信息的效率上。然而，传统方法，主要是单模态的，已经研究了知识检索和随后的答案预测，引发了关于检索到的知识的质量和使用隐式和显式知识进行推理过程的整合的问题。为了解决这些问题，我们引入了知识增强变换器（KAT），它通过结合GPT3的隐式知识和来自网站的显式知识，在2022年OK-VQA开放领域多模态任务上比其他模型高出6%。KAT使用编码器-解码器结构，允许在答案生成期间同时使用这两种知识类型进行推理。此外，整合显式知识增强了模型预测的可解释性。代码和预训练模型可在<https://github.com/guilk/KAT上找到。>

视觉-语言变换器智能体。接下来，我们介绍了“从字幕训练视觉-语言变换器”（VLC）模型（Gui等人，2022b），这是一个仅使用图像-字幕对进行预训练的变换器。尽管仅使用简单的线性投影层进行图像嵌入，VLC在各种视觉-语言任务中取得了与其他依赖于对象检测器或监督CNN/ViT网络的方法相媲美的竞争力结果。

通过广泛分析，我们探索了VLC作为视觉-语言变换器智能体的潜力。例如，我们展示了VLC的视觉表示在ImageNet-1K分类中非常有效，我们的可视化确认了VLC可以准确地将图像补丁与相应的文本标记匹配。随着更多训练数据的性能可扩展性，突显了开发大规模、弱监督、开放领域视觉-语言模型的有前景的潜力。

6.5 视频-语言实验

为了理解将预训练的图像-LLMs转换为视频理解的实用性，我们对InstructBLIP（Dai等人，2023）进行了时间扩展和微调，用于视频字幕。具体来说，我们使用与Frozen in Time（Bain等人，2021）相同的分割时空注意力方案扩展了InstructBLIP的视觉编码器（EVA-CLIP-G（Sun等人，2023b）），并在字幕训练期间保持Q-former和LLM（Flan-T5-XL（Chung等人，2022））冻结。我们冻结了视觉编码器的所有空间层，同时在字幕训练期间保持时间层未冻结。这允许我们的模型将图像和视频作为输入（与InstructBLIP的图像级性能匹配）。我们在WebVid10M（Bain等人，2021）的500万个视频字幕子集上进行训练。我们在图25中可视化了两个示例输出。然而，现有的智能体未能完全理解视频内容中精确、细粒度的视觉细节。视觉指令调整方法也存在类似的局限性，它们缺乏多模态模型和智能体需要解决的一般人类水平的感知能力。

指令调整模型在准确总结视频中可见动作方面显示出前景，并在图25中有效地识别了“人坐在长椅上”等动作。然而，它们有时会添加错误的细节，如“人对着相机微笑”，这揭示了在捕捉对话主题或视频的氛围方面的不足，这些元素对人类观察者来说是显而易见的。这一不足突显了另一个关键局限性：省略了音频和语音模态，这些模态可以通过上下文丰富视频理解，帮助更准确地解释并防止这种误解。弥合这一差距需要整体整合可用的模态，允许多模态智能体达到类似于人类感知的理解水平，并确保采用完全多模态的视频解释方法。

6.6 用于NLP的智能体

6.6.1 LLM智能体

识别任务指令并采取行动是交互式AI和自然语言处理数十年来的基本挑战。随着深度学习的最新进展，人们越来越有兴趣联合研究这些领域，以改善人类-智能体协作。我们确定了三个具体方向，以提高语言基础智能体的能力：

工具使用和知识库查询。这个方向强调将外部知识库、网络搜索或其他有用工具整合到AI智能体的推理过程中的重要性。通过利用来自各种来源的结构化和非结构化数据，智能体可以增强它们的理解并提供更准确和上下文感知的响应。此外，它培养了智能体在面对不熟悉的场景或查询时主动寻找信息的能力。示例包括Toolformer（Schick等人，2023）和Retrieve What You Need（Wang等人，2023g）。

改进智能体推理和规划。增强智能体的推理和规划能力对于有效的人类-智能体协作至关重要。这涉及开发能够理解复杂指令、推断用户意图和预测潜在未来场景的模型。这可以通过要求智能体反思过去的行为和失败来实现，如ReAct（Yao等人，2023a），或者通过将智能体的思维过程结构化为一种搜索（Yao等人，2023b）。通过模拟不同的结果并评估各种行动的后果，智能体可以做出更明智的上下文感知决策。

整合系统和人类反馈。AI智能体通常在两种主要环境中运行：提供关于它们行动有效性的明确信号的环境（系统反馈）和它们与可以提供口头批评的人类合作的环境（人类反馈）。这个方向强调了需要自适应学习机制，允许智能体根据多样化的反馈来源完善它们的策略并纠正错误，如AutoGen（Wu等人，2023）。能够不断从不同的反馈源学习和适应，确保智能体保持有用并对用户需求保持一致。

6.6.2 通用LLM智能体

识别和理解智能体内容和自然语言是交互式AI和自然语言处理数十年来的基本挑战。随着深度学习的最新进展，人们越来越有兴趣联合研究这两个领域，以深入理解代理规划或人类反馈用于知识推理和自然语言生成。这些是许多人类-机器交互智能体的关键组成部分，如“AutoGen”（Wu等人，2023）和“Retrieve What You Need”（Wang等人，2023g）。

6.6.3 遵循指令的LLM智能体

此外，创建能够有效遵循人类指令的LLM智能体已成为一个重要的研究领域。最初的模型使用人类反馈来训练代理奖励模型，以模拟人类偏好，通过一种称为强化学习与人类反馈（RLHF）的过程（Ouyang等人，2022）。这个过程产生了InstructGPT和ChatGPT等模型。为了在不需要人类标签的情况下更有效地训练遵循指令的LLM智能体，研究人员开发了一种更有效的指令调整方法，直接在指令/响应对上训练LLM智能体，这些对要么由人类生成，如Dolly 2.0 6，要么由LLMs如Alpaca（Taori等人，2023）自动生成。我们在图28中展示了Alpaca的整体训练流程。

6.6.4 实验和结果

尽管对话和自我反馈系统的采用日益增加，但这些形式的AI在从其隐含知识中生成事实上正确的响应方面仍然表现不佳，因此通常在推理时使用外部工具，如网络搜索和知识检索机制来增强其响应。解决这个问题将有助于在许多现实生活应用中为用户创造更具吸引力的体验。在社交对话（如Instagram和Facebook等社交媒体平台上）或问答网站（如Ask或Quora）中，人们通常通过一系列评论与他人互动，并通过网络搜索与讨论相关的信息和知识。因此，在这个背景下生成对话轮次的任务不是简单地启动传统的NLP模型和任务，而是使用智能体通过反映知识搜索和获取的智能行为来生成对话（Peng等人，2023）。通过这种方式，用于NLP任务的智能体扩展了任务描述，并通过在对话期间添加显式的知识搜索和检索步骤来改进响应的可解释性。将这些网络搜索和检索智能体作为对话期间的反馈，将有助于进一步深入人类与智能体之间的社交互动（Wang等人，2023e）。如图29所示，我们为变换器语言模型引入了一种新的建模范式，该范式检测和提取输入文本中的重要逻辑结构和信息，然后通过精心设计的多层层次逻辑投影将它们整合到输入嵌入中，将逻辑结构注入预训练的语言模型中，作为一种NLP智能体。（Wang等人，2023e）提出了一种新方法，通过结合逻辑检测、逻辑映射和层次逻辑投影来构建变换器语言模型的逻辑感知输入嵌入，然后开发了一种新的建模范式，可以将所有现有的变换器语言模型升级为逻辑变换器，以持续提升它们的性能。所提出的逻辑变换器智能体通过更深入地理解文本的逻辑结构，始终如一地实现了比其基线变换器模型更优越的性能。对人类用户来说，通常正是这些方面对于通过智能体协调对话和信息检索来提供有意义和有趣的对话更为重要。

开放域问答（QA）系统通常遵循检索-然后-阅读范式，在这种范式中，检索器用于从大型语料库中检索相关段落，然后阅读器基于检索到的段落和原始问题生成答案。在（Wang等人，2023g）中，我们提出了一个简单而新颖的互学习框架，通过一个名为知识选择器代理的中间模块来提高检索-然后-阅读风格模型的性能，我们使用强化学习对其进行训练。将细粒度知识选择器引入检索-阅读范式，其目标是构建一个小型的段落子集，这些段落保留了与问题相关的信息。如图30所示，知识选择器代理作为我们新颖的互学习框架的组成部分进行训练，该框架迭代地训练知识选择器和阅读器。我们采用了一种简单而新颖的方法，使用策略梯度来优化知识选择器代理，使用来自阅读器的反馈来训练它选择一个小型且信息丰富的段落集合。这种方法避免了蛮力搜索或手动设计的启发式方法，不需要任何注释的查询-文档对进行监督。我们展示了迭代训练阅读器和知识选择器代理可以提高一些公共开放域问答基准测试的预测性能。

7 跨模态、跨领域和跨现实的智能体

7.1 跨模态理解的智能体

多模态理解对于创建通用智能体是一个重大挑战，因为缺乏包含视觉、语言和智能体行为的大规模数据集。更普遍地，AI智能体的训练数据通常是特定于模态的。这导致大多数现代多模态系统使用一组冻结的子模块。一些著名的例子是Flamingo（Alayrac等人，2022）、BLIP-2（Li等人，2023c）和LLaVA（Liu等人，2023c），它们都使用冻结的LLM和冻结的视觉编码器。这些子模块在单独的数据集上分别训练，然后训练适应层将视觉编码器编码到LLM嵌入空间中。为了在AI智能体的跨模态理解方面取得进一步进展，很可能需要改变使用冻结的LLM和视觉编码器的策略。事实上，RT-2，一个最近的视觉-语言模型，能够在机器人领域的域内采取行动，当视觉编码器和LLM一起调整用于机器人和视觉-语言任务时，显示出了显著提高的性能（Brohan等人，2023）。

7.2 跨领域理解的智能体

创建通用智能体的一个关键挑战是不同领域之间独特的视觉外观和不同的动作空间。人类具有解释来自各种来源的图像和视频的能力，包括真实世界、视频游戏和专业领域，如机器人技术和医疗保健，一旦他们熟悉了这些领域的具体细节。然而，现有的LLMs和VLMs在它们训练的数据和它们应用的多样化领域之间常常表现出显著差异。值得注意的是，当试图开发一个能够跨领域有效学习多个控制系统的单一策略时，训练智能体模型预测特定动作是一个相当大的挑战。通常，现代作品在将系统应用于特定领域时所采取的方法是从一个预训练的基础模型开始，然后为每个特定领域微调一个单独的模型。这没有捕捉到领域之间的任何共同点，而是导致用于训练的总数据集更小，而不是利用每个领域的数据。

7.3 跨模态和跨现实的交互智能体

开发能够成功理解和跨不同现实执行任务的AI智能体是一个持续的挑战，在图像和场景生成方面取得了一些最近的成功（Huang等人，2023a）。特别是，由于它们的视觉差异和独立的环境物理特性，智能体同时理解真实世界和虚拟现实环境是具有挑战性的。在跨现实背景下，当使用模拟训练的策略用于真实世界数据时，模拟到现实转移是一个特别重要的问题，我们将在下一节中讨论。

7.4 模拟到现实转移

使模型能够在模拟中训练并部署在现实世界中的技术。具身智能体，特别是基于RL策略的智能体，通常在模拟环境中训练。这些模拟并没有完全复制现实世界的特征（例如，干扰、光线、重力和其他物理属性）。由于模拟和现实之间的差异，模拟中训练的模型在应用于现实世界时常常难以表现良好。这个问题被称为“模拟到现实”问题。为了解决这个问题，可以采取几种方法：

领域随机化：领域随机化是一种在模拟环境中训练模型时随机变化参数的技术（例如，对象外观、传感器噪声和光学属性），以预期现实世界的不确定性和变化（Tobin等人，2017）。例如，在基于RL的抓取技能训练的背景下，引入对象形状的随机性可以导致一个策略，该策略能够适应形状略有不同的对象（Saito等人，2022）。

领域适应：领域适应，或领域转移是一种技术，通过使用大量模拟图像和较小的真实世界图像训练模型，以弥合模拟和真实世界领域之间的差距。在实际设置中，由于准备跨领域的成对图像的困难，通常使用成对图像到图像翻译方法，如CycleGAN（Zhu等人，2017b）。有几种增强版本适用于强化学习，包括RL-CycleGAN（Rao等人，2020），以及模仿学习，如RetinaGAN（Ho等人，2021）。

模拟改进：现实感模拟是模拟到现实转移的关键。这部分工作通过系统识别技术（Zhu等人，2017c；Allevaato等人，2020）实现，该技术旨在识别模拟参数以模仿真实世界环境。此外，使用逼真的模拟器将有效地用于基于图像的强化学习（Martinez-Gonzalez等人，2020；Müller等人，2018；Shah等人，2018；Sasabuchi等人，2023）。

模拟到现实转移仍然是具身智能体研究的核心挑战，因为方法不断发展。理论和实证研究对于进一步推进这些技术至关重要。

8 智能体AI的持续自我改进

目前，基于基础模型的AI智能体具有从多个不同数据源学习的能力，这为训练提供了更灵活的数据来源。这有两个主要后果（1）用户和基于人类交互的数据可以用来进一步完善和改进智能体（2）现有的基础模型和模型制品可以用来生成训练数据。我们在接下来的章节中更详细地讨论这些问题，但我们注意到，由于当前的AI智能体在很大程度上与现有的预训练基础模型绑定，它们通常不会从与环境的持续交互中学习。我们认为这是一个令人兴奋的未来方向，Bousmalis等人的初步工作表明，自我改进的智能体可以通过环境交互在没有监督的情况下持续学习和改进（Bousmalis等人，2023）。

8.1 基于人类的交互数据

使用基于人类的交互数据的核心思想是利用大量的智能体-人类交互来训练和改进智能体的未来迭代。有几种策略用于从人类-智能体交互中改进智能体。

额外的训练数据：使用人类-智能体交互作为未来智能体迭代的训练数据可能是最简单的用法。这通常需要过滤策略来区分成功的智能体示例和不成功的交互示例。过滤可以基于规则（例如，达到某个期望的最终目标状态）、基于模型（例如，将成功与不成功的交互分类）或在事后检查和/或修改交互示例后手动选择。

人类偏好学习：在与用户交互期间，智能体系统可以向用户提供几种不同的模型输出，并允许用户选择最符合他们偏好的输出。这通常由像ChatGPT和GPT-4这样的LLMs使用，用户可以从几个选项中选择一个最符合他们偏好的输出。

安全训练（红队）：在智能体AI的背景下，红队指的是有专门的对手团队（无论是人类还是计算机）寻求利用和暴露智能体AI系统中的弱点和漏洞。尽管本质上是对抗性的，红队通常用作了解如何改进AI安全措施和减少有害输出发生的手段。核心原则是发现一致的方法来诱导不需要的智能体输出，以便模型可以在明确纠正这种行为的数据上进行训练。

8.2 基础模型生成的数据

随着学术界和工业界产生的强大的基础模型制品的出现，已经开发了各种方法，使用各种提示和数据配对技术从这些制品中提取和生成有意义的训练数据。

LLM指令调整：从LLM生成指令遵循训练数据的方法允许根据较大专有LLM的输出对较小的开源模型进行微调（Wang等人，2022b）。例如，Alpaca（Taori等人，2023）和Vicuna（Zheng等人，2023）是基于开源LLaMA家族（Touvron等人，2023）的LLMs，它们已经在ChatGPT和人类参与者的各种输出上进行了调整。这种指令调整方法可以被视为一种知识蒸馏的形式，其中较大的LLM作为教师模型对学生模型进行教学。重要的是，尽管LLM指令调整已被证明可以将教师模型的写作风格和一些指令遵循能力转移到学生模型上，但在教师和学生模型的事实性和能力之间仍然存在显著差距（Gudibande等人，2023）。

视觉-语言对：最近的工作通过自动为视觉内容生成字幕和其他文本，寻求增加视觉-语言模型可用的预训练数据的多样性。例如，LLaVA（Liu等人，2023c）使用了150,000个主要由LLM生成的文本和视觉输入的指令遵循行为示例。其他研究表明，使用VLMs重新标注图像可以改善训练数据和随后的图像生成模型的质量（Segalis等人，2023）。在视频理解领域，使用VLMs和LLMs重新标注视频已被证明可以改善在重新标注视频上训练的VLMs的性能和质量（Wang等人，2023f；Zhao等人，2022）。

9 智能体数据集和排行榜

为了加速这一领域的研究，我们提出了两个基准，分别用于多智能体游戏和智能视觉语言任务。我们将发布两个新数据集 - “CuisineWorld”和“VideoAnalytica” - 和一组基线模型，鼓励参与者探索新的模型、系统，并在我们的排行榜测试集上提交他们的结果。

9.1 “CuisineWorld”多智能体游戏数据集

CuisineWorld是一个类似于Overcooked!的基于文本的游戏，为AI驱动的智能体提供了一个合作和协同游戏的平台。该数据集将测试多智能体系统的协作效率，提供洞察LLMs和其他系统如何在动态场景中协同工作的能力。特别是，数据集将重点关注智能体理解目标的程度，以及智能体之间如何协调。该数据集支持两种模式：集中式调度器模式和分散模式。参与者可以选择游戏模式，并向我们的排行榜提交。

9.1.1 基准

对于我们的比赛，我们将发布一个基准，即CuisineWorld基准，其中包括一个文本界面，包括可扩展的任务定义文件，以及多智能体交互和人机交互的接口。我们引入了游戏交互任务，目标是生成相关、适当的多智能体协作策略，以最大化协作效率。我们使用提出的评估指标CoS评估协作效率。

“CuisineWorld”数据集由微软、加州大学洛杉矶分校和斯坦福大学收集。比赛的目标是探索不同现有和新型基础LLM和交互技术在这一基准上的表现，并为多智能体游戏基础设施任务建立强大的基线。

CuisineWorld数据集包括：

一系列定义良好的多智能体协作任务。

一个API系统，以促进智能体之间的交互。

一个自动评估系统。

（数据集的下载链接将很快提供，本文将在包含链接后更新。）

9.1.2 任务

我们提供了一个名为Microsoft MindAgent的数据集和相关基准，并相应地发布了一个名为“CuisineWorld”的数据集给研究社区。

我们将提供基准，以评估和排名提交的“MindAgent”算法。我们还将提供使用流行的基础设施生成的基线结果。

9.1.3 指标和评判

多智能体协作效率的质量由新的“cos”自动度量标准（来自MindAgent（Gong等人，2023a））确定。我们指标的最终评分是作为多智能体系统在所有任务上评估的协作效率度量标准的平均值计算的。人类评估员将被要求对单个响应进行评分，并提供对用户与智能体交互的参与度、广度和整体质量的主观判断。

9.1.4 评估

自动化评估。我们计划在发布日期（TBA）发布排行榜，注册参与者将被要求提交与“CuisineWorld”数据集相关的任务的结果（我们公开发布的排行榜数据集）。结果提交将在结束日期（TBA）关闭。每个团队都需要在测试集上提交他们生成的结果，以自动评估“cos”度量标准。

排行榜上的人类评估。排行榜参与者需要提供由评估脚本本地生成的提交文件。我们将使用evalAI系统检查提交文件，并为顶级挑战者可选地重新运行代码。因此，团队还必须提交他们的代码以及一个Readme文件，说明如何运行他们的代码。人类评估将由组织团队执行。

获胜者公告。我们将宣布获胜者，并在我们的排行榜上发布提交的最终评分。

9.2 音视频-语言预训练数据集

我们介绍了VideoAnalytica：一项新的基准测试，用于分析视频演示理解。VideoAnalytica专注于利用视频演示作为辅助，以更好地理解嵌入在长篇教学视频中的复杂、高级推理。目标是评估视频语言模型的认知推理能力，推动它们超越简单的识别任务和基本理解，朝着更复杂和微妙的视频理解发展。至关重要的是，VideoAnalytica强调整合多种模态，如音频、视频和语言，以及模型应用特定领域知识的能力，以情境化和解释视频中呈现的信息。具体来说，VideoAnalytica涉及两个主要任务：

视频文本检索：这项任务涉及从教学视频中准确检索相关文本。挑战在于区分相关信息和无关信息，因此需要对视频内容有深入的理解，并分析演示以检索正确的查询。为了进一步增加这些任务的复杂性，我们在数据集中引入了由大型语言模型生成的硬负例。我们对生成的负例进行了人类验证，并删除了使任务无效和不公平的实例（例如，负例是有效的）。

视频辅助信息性问答：这项任务要求模型基于从视频中提取的信息回答问题。重点是需要分析性推理和对视频演示的透彻理解的复杂问题。

为了促进音频-视频-语言代理分析视频理解的发展，我们为VideoAnalytica的两个任务引入了基准排行榜。

排行榜参与者需要提交他们的解决方案进行评估。评估将基于模型在两项任务上的表现，结果将显示在排行榜上。参与者需要提交他们的代码，并附有详细说明他们的方法和方法论。

伦理考虑：排行榜侧重于理解和解释视频内容，这可能潜在地用于监控或其他侵犯隐私的应用。因此，考虑技术的伦理影响和潜在滥用至关重要。我们鼓励参与者在提交中考虑这些方面，并促进AI的道德使用。
