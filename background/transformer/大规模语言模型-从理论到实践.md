# 大规模语言模型：从理论到实践

> 张奇、桂韬、郑锐、黄萱菁

## 语言模型

语言模型（Language Model，LM）的目标是建模自然语言的概率分布。词汇表 V 上的语言模型，由函数$P(w_1w_2...w_m)$表示，可以形式化地构建为词序列$(w_1w_2...w_m)$的概率分布，表示词序列$(w_1w_2...w_m)$作为一个句子出现的可能性大小。

为了减少$P(w_1w_2...w_m)$模型的参数空间，可以利用句子序列通常情况下从左至右的生成过程进行分解，使用链式法则得到：
$$
P(w_1w_2...w_m) = P(w_1)P(w_2|w_1)P(w_3|w_1w_2) \dots P(w_m|w_1w_2 \dots w_{m−1})=\prod_{i=1}^{m}P(w_i|w1w2\dots w_{i−1})
$$
为了进一步降低模型的参数空间，可以进一步假设任意单词$w_i$出现的概率只与过去 $n − 1$ 个词相关，即：
$$
\begin{align}
& P(w_i|w_1w_2...w_{i−1}) = P(w_i|w_{i−(n−1)}w_{i−(n−2)}...w_{i−1}) \\
& P(w_i|w^{i−1}_1)=P(w_i|w^{i−1}_{i−n+1})
\end{align}
$$
满足上述条件的模型被称为*n* 元语法或***n* 元文法(*n*-gram)** 模型。其中 *n*-gram 表示由 *n* 个连续单词构成的单元，也被称为*n* 语法单元。

再庞大的训练语料也无法覆盖所有的 n-gram，而训练语料中的零频率并不代表零概率。因此，需要使用平滑技术（Smoothing）来解决这一问题，对所有可能出现的字符串都分配一个非零的概率值，从而避免零概率问题。平滑是指为了产生更合理的概率，对最大似然估计进行调整的一类方法，也称为**数据平滑（Data Smoothing）**。

平滑处理的基本思想是提高低概率，降低高概率，使整体的概率分布趋于均匀。这类方法通常称为**统计语言模型（Statistical Language models，SLM）**。

n 元语言模型从整体上来看与训练语料规模和模型的阶数有较大的关系，不同的平滑算法在不同情况下的表现有较大的差距。平滑算法虽然较好的解决了零概率问题，但是基于稀疏表示的n 元语言模型仍然有三个较为明显的缺点：

1. 无法建模长度超过 n 的上下文；
1. 依赖人工设计规则的平滑技术；
1. 当 n 增大时，数据的稀疏性随之增大，模型的参数量更是指数级增加，并且模型受到数据稀疏问题的影响，其参数难以被准确的学习。

此外，n 元文法中单词的离散表示也忽略了单词之间的相似性。因此，基于分布式表示和神经网络的语言模型逐渐成为了研究热点。

Bengio 等人在 2000 年提出了使用前馈神经网络对$P(w_i|w_1w_2...w_{i−1})$进行估计的语言模型。词的独热编码被映射为一个低维稠密的实数向量，称为**词向量（Word Embedding）**。此后，循环神经网络、卷积神经网络、端到端记忆网络等神经网络方法都成功应用于语言模型建模。相较于 n 元语言模型，神经网络方法可以在一定程度上避免数据稀疏问题，有些模型还可以避免对历史长度的限制，从而更好的建模长距离依赖关系。这类方法通常称为**神经语言模型（Neural Language Models，NLM）**。

深度神经网络需要采用有监督方法，使用标注数据进行训练，因此，语言模型的训练过程也不
可避免需要构造训练语料。但是由于训练目标可以通过无标注文本直接获得，从而使得模型的训
练仅需要大规模无标注文本即可。语言模型也成为了典型的自监督学习（Self-supervised Learning）任务 。受到计算机视觉领域采用 ImageNet对模型进行一次预训练，使得模型可以通过海量图像充分学习如何提取特征，然后再根据任务目标进行模型精调的预训练范式影响，自然语言处理领域基于预训练语言模型的方法也逐渐成为主流。以 **ELMo**为代表的动态词向量模型开启了语言模型预训练的大门，此后以 **GPT** 和 **BERT** 为代表的基于 **Transformer** 模型 的大规模预训练语言模型的出现，使得自然语言处理全面进入了预训练微调范式新时代。将预训练模型应用于下游任务时，不需要了解太多的任务细节，不需要设计特定的神经网络结构，只需要“微调”预训练模型，使用具体任务的标注数据在预训练语言模型上进行监督训练，就可以取得显著的性能提升。这类方法通常称为**预训练语言模型（Pre-trained Language Models，PLM）**。

2020 年 Open AI 发布了由包含 1750 亿参数的神经网络构成的生成式大规模预训练语言模型GPT-3（Generative Pre-trained Transformer 3）。开启了大规模语言模型的新时代。由于大规模语言模型的参数量巨大，如果在不同任务上都进行微调需要消耗大量的计算资源，因此预训练微调范式不再适用于大规模语言模型。但是研究人员发现，通过**语境学习（Incontext Learning，ICL）**等方法，直接使用大规模语言模型就可以在很多任务的少样本场景下取得很好的效果。此后，研究人员们提出了面向大规模语言模型的**提示词（Prompt）学习**方法、**模型即服务范式（Model as a Service，MaaS）**、**指令微调（Instruction Tuning）**等方法，在不同任务上都取得了很好的效果。

根据 OpenAI 联合创始人 Andrej Karpathy 在微软 Build 2023 大会上所公开的信息，OpenAI 所使用的大规模语言模型构建流程主要包含四个阶段：预训练（Pretraining）、有监督微调（Supervised Finetuning）/ 指令微调（Instruction Tuning）、奖励建模（Reward Modeling）、强化学习（Reinforcement Learning）。

## Transformer 模型

Transformer 模型 是由谷歌在 2017 年提出并首先应用于机器翻译的神经网络模型结构。机器翻译的目标是从源语言（Source Language）转换到目标语言（Target Language）。Transformer 结构完全通过注意力机制完成对源语言序列和目标语言序列全局依赖的建模。

### 1 嵌入表示层

对于输入文本序列，首先通过输入嵌入层（Input Embedding）将每个单词转换为其相对应的向量表示。通常直接对每个单词创建一个向量表示。由于 Transfomer 模型不再使用基于循环的方式建模文本输入，序列中不再有任何信息能够提示模型单词之间的相对位置关系。在送入编码器端建模其上下文语义之前，一个非常重要的操作是在词嵌入中加入**位置编码（Positional Encoding）**这一特征。

为了得到不同位置对应的编码，Transformer 模型使用不同频率的正余弦函数如下所示：

$$
\begin{align}
& PE(pos,2i) = \sin(\frac{pos}{10000^{2i/d}}) \\
& PE(pos, 2i + 1) = \cos(\frac{pos}{10000^{2i/d}})
\end{align}
$$

其中，`pos`表示单词所在的<u>位置</u>，`2i` 和 `2i+ 1` 表示位置编码向量中的对应<u>维度</u>，`d`则对应位置编码的<u>总维度</u>。通过上面这种方式计算位置编码有这样几个好处：首先，正余弦函数的范围是在 [-1,+1]，导出的位置编码与原词嵌入相加不会使得结果偏离过远而破坏原有单词的语义信息。其次，依据三角函数的基本性质，可以得知第 `pos + k` 个位置的编码是第 pos 个位置的编码的线性组合，这就意味着位置编码中蕴含着单词之间的距离信息。

### 2 注意力层

**自注意力（Self-Attention）**操作是基于 Transformer 的机器翻译模型的基本操作，在源语言的编码和目标语言的生成中频繁地被使用以建模源语言、目标语言任意两个单词之间的依赖关系。给定由单词语义嵌入及其位置编码叠加得到的输入表示 $\{x_i \in \mathbb{R}^d\}_{i=1}^{t}$，为了实现对上下文语义依赖的建模，进一步引入在**自注意力机制**中涉及到的三个元素：查询 $q_i$（Query），键 $k_i$（Key），值 $v_i$（Value）。在编码输入序列中每一个单词的表示的过程中，这三个元素用于计算上下文单词所对应的**权重得分**。直观地说，这些权重反映了在编码当前单词的表示时，对于上下文不同部分所需要的**关注程度**。通过三个线性变换 $W^Q \in \mathbb{R}^{d \times d_q}$，$W^K \in \mathbb{R}^{d \times d_k}$，$W^V \in \mathbb{R}^{d \times d_v}$ 将输入序列中的每一个单词表示$x_i$ 转换为其对应的 $q_i \in \mathbb{R}^{d_q}$，$k_i \in \mathbb{R}^{d_k}$，$v_i \in \mathbb{R}^{d_v}$ 向量。

为了防止过大的匹配分数在后续 Softmax 计算过程中导致的梯度爆炸以及收敛效率差的问题，这些得分会除放缩因子 $\sqrt{d}$以稳定优化。放缩后的得分经过 Softmax 归一化为概率之后，与其他位置的值向量相乘来聚合希望关注的上下文信息，并最小化不相关信息的干扰。上述计算过程可以被形式化地表述如下：

$$
Z =
Attention(Q,K,V) = Softmax(\frac{QK^T}{\sqrt{d}})V
$$
Attention公式

为了进一步增强自注意力机制聚合上下文信息的能力，提出了**多头自注意力（Multi-head Attention）**的机制，以关注上下文的不同侧面。多头自注意力整合上下文语义，它使得序列中任意两个单词之间的依赖关系可以直接被建模而不基于传统的循环结构，从而更好地解决文本的长程依赖。
具体来说，上下文中每一个单词的表示 $x_i$ 经过多组线性 $\{W_j^QW_j^KW_j^V\}_{j=1}^N$映射到不同的表示子空间中。Attention公式会在不同的子空间中分别计算并得到不同的上下文相关的单词序列表示$\{Z_j\}_{j=1}^N$。最终，线性变换 $W^O \in \mathbb{R}(Nd_v) \times d$ 用于综合不同子空间中的上下文表示并形成自注意力层最终的输出 $\{x_i \in \mathbb{R}^d\}_{i=1}^t$。

### 3 位置感知前馈层（Position-wise FFN）

前馈层接受自注意力子层的输出作为输入，并通过一个带有 **Relu 激活函数**的两层全连接网络对输入进行更加复杂的非线性变换。实验证明，这一非线性变换会对模型最终的性能产生十分重要的影响。
$$
FFN(x) = Relu(xW_1 + b_1)W_2 + b_2
$$

其中 $W_1$,$b_1$,$W_2$,$b_2$ 表示前馈子层的参数。实验结果表明，增大前馈子层隐状态的维度有利于提升最终翻译结果的质量，因此，前馈子层隐状态的维度一般比自注意力子层要大。

### 4 残差连接与层归一化

残差连接(Add 部分)是一条分别作用在上述两个子层当中的直连通路，被用于连接它们的输入与输出。从而使得信息流动更加高效，有利于模型的优化。层归一化(Norm 部分)。作用于上述两个子层的输出表示序列中，对表示序列进行层归一化操作，同样起到稳定优化的作用。

具体来说，残差连接主要是指使用一条直连通道直接将对应子层的输入连接到输出上去，从而避免由于网络过深在优化过程中潜在的梯度消失问题：
$$
x^{l+1} = f(x^l) + x^l
$$
其中 $x^l$ 表示第 l 层的输入，`f(·)` 表示一个映射函数。

此外，为了进一步使得每一层的输入输出范围稳定在一个合理的范围内，层归一化技术被进一步引入每个 Transformer 块的当中：
$$
LN(x) = α · \frnc{x − µ}{σ} + b
$$

其中 µ 和 σ 分别表示均值和方差，用于将数据平移缩放到均值为 0，方差为 1 的标准分布，α 和 b
是可学习的参数。层归一化技术可以有效地缓解优化过程中潜在的不稳定、收敛速度慢等问题。

### 5 编码器和解码器结构

解码器的每个 Transformer 块的第一个自注意力子层额外增加了注意力掩码(掩码多头注意力（Masked Multi-Head Attention）部分)。这主要是因为在翻译的过程中，编码器端主要用于编码源语言序列的信息，而这个序列是完全已知的，因而编码器仅需要考虑如何融合上下文语义信息即可。而解码端则负责生成目标语言序列，这一生成过程是自回归的，即对于每一个单词的生成过程，仅有当前单词之前的目标语言序列是可以被观测的，因此这一额外增加的掩码是用来掩盖后续的文本信息，以防模型在训练阶段直接看到后续的文本序列进而无法得到有效地训练。

此外，解码器端还额外增加了一个多头注意力（Multi-Head Attention）模块，使用交叉注意
力（Cross-attention）方法，同时接收来自编码器端的输出以及当前 Transformer 块的前一个掩码注意力层的输出。查询是通过解码器前一层的输出进行投影的，而键和值是使用编码器的输出进行
投影的。它的作用是在翻译的过程当中，为了生成合理的目标语言序列需要观测待翻译的源语言
序列是什么。基于上述的编码器和解码器结构，待翻译的源语言文本，首先经过编码器端的每个
Transformer 块对其上下文语义的层层抽象，最终输出每一个源语言单词上下文相关的表示。解码
器端以自回归的方式生成目标语言文本，即在每个时间步 t，根据编码器端输出的源语言文本表
示，以及前 t − 1 个时刻生成的目标语言文本，生成当前时刻的目标语言单词。

##

生成式预训练语言模型（Generative Pre-Training，GPT）

LangChain 的提供了以下 6 种标准化、可扩展的接口并且可以外部集成的核心模块：

1. **模型输入/输出（Model I/O）**与语言模型交互的接口；
2. **数据连接（Data connection）**与特定应用程序的数据进行交互的接口；
3. **链（Chains）**用于复杂的应用的调用序列；
4. **智能体（Agents）**语言模型作为推理器决定要执行的动作序列；
5. **记忆（Memory）**用于链的多次运行之间持久化应用程序状态；
6. **回调（Callbacks）**记录和流式传输任何链式组装的中间步骤。

多模态大语言模型的任务类型

| 任务类型 | Task Type | 任务描述 |
| :--- | :----- | :---- |
|图文检索 |Image-Text Retrieval|包含图像到文本的检测，文本到图像的检索|
|图像描述 |Image Captioning |根据给定图像生成描述性文本|
|视觉问答|Visual Question Answering |回答与给定图像相关的问题|
|视觉推理 |Visual Reasoning |根据给定图像进行逻辑推理|
|图像生成 |Image Generating |根据文本描述生成图像|
